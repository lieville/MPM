<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12 神经网络与深度学习基础 – 现代预测建模：从回归到机器学习</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/part-4-introduction.html" rel="next">
<link href="../chapters/11 支持向量机.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-70a47bd5681a7291082a5b9f83d58762.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="science-textbook.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-3-introduction.html">III 进阶——超越线性的机器学习</a></li><li class="breadcrumb-item"><a href="../chapters/12 神经网络与深度学习基础.html"><span class="chapter-title">12 神经网络与深度学习基础</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="搜索" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">现代预测建模：从回归到机器学习</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="搜索"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">前言</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">index.html</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">I 基础-线性回归模型</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-1-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">part-1-introduction.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1 预测模型与评估.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">1 预测模型与评估</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2 线性回归.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">2 线性回归</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3 模型诊断.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">3 模型诊断</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4 时间序列分析初步.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">4 时间序列分析初步</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">II 扩展——线性分析方法</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-2-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">part-2-introduction.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5 降维.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">5 降维</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/6 正则化.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">6 正则化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/7 广义线性模型.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">7 广义线性模型</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/8 线性分类模型.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">8 线性分类模型</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/9 非线性回归与样条回归.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">9 非线性回归与样条回归</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">III 进阶——超越线性的机器学习</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-3-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">part-3-introduction.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10 决策树与集成学习.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">10 决策树与集成学习</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11 支持向量机.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">11 支持向量机</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12 神经网络与深度学习基础.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">12 神经网络与深度学习基础</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">IV 实践——综合案例分析</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-4-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">part-4-introduction.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13 回归任务与基准测试.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">13 回归任务与基准测试</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/14 分类任务.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">14 分类任务</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15 案例综合分析.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">15 案例综合分析</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#本章导读" id="toc-本章导读" class="nav-link active" data-scroll-target="#本章导读">本章导读</a></li>
  <li><a href="#神经网络回归与分类的统一框架" id="toc-神经网络回归与分类的统一框架" class="nav-link" data-scroll-target="#神经网络回归与分类的统一框架">12.1 神经网络：回归与分类的统一框架</a>
  <ul class="collapse">
  <li><a href="#从线性模型到神经网络" id="toc-从线性模型到神经网络" class="nav-link" data-scroll-target="#从线性模型到神经网络">12.1.1 从线性模型到神经网络</a></li>
  <li><a href="#为什么需要神经网络" id="toc-为什么需要神经网络" class="nav-link" data-scroll-target="#为什么需要神经网络">12.1.2 为什么需要神经网络？</a></li>
  </ul></li>
  <li><a href="#网络架构设计" id="toc-网络架构设计" class="nav-link" data-scroll-target="#网络架构设计">12.2 网络架构设计</a>
  <ul class="collapse">
  <li><a href="#输出层设计" id="toc-输出层设计" class="nav-link" data-scroll-target="#输出层设计">12.2.1 输出层设计</a></li>
  <li><a href="#隐藏层设计" id="toc-隐藏层设计" class="nav-link" data-scroll-target="#隐藏层设计">12.2.2 隐藏层设计</a></li>
  </ul></li>
  <li><a href="#激活函数与损失函数" id="toc-激活函数与损失函数" class="nav-link" data-scroll-target="#激活函数与损失函数">12.3 激活函数与损失函数</a>
  <ul class="collapse">
  <li><a href="#常用激活函数" id="toc-常用激活函数" class="nav-link" data-scroll-target="#常用激活函数">12.3.1 常用激活函数</a></li>
  <li><a href="#损失函数选择" id="toc-损失函数选择" class="nav-link" data-scroll-target="#损失函数选择">12.3.2 损失函数选择</a></li>
  </ul></li>
  <li><a href="#神经网络训练" id="toc-神经网络训练" class="nav-link" data-scroll-target="#神经网络训练">12.4 神经网络训练</a>
  <ul class="collapse">
  <li><a href="#前向传播" id="toc-前向传播" class="nav-link" data-scroll-target="#前向传播">12.4.1 前向传播</a></li>
  <li><a href="#反向传播" id="toc-反向传播" class="nav-link" data-scroll-target="#反向传播">12.4.2 反向传播</a></li>
  <li><a href="#优化算法" id="toc-优化算法" class="nav-link" data-scroll-target="#优化算法">12.4.3 优化算法</a></li>
  </ul></li>
  <li><a href="#过拟合与正则化" id="toc-过拟合与正则化" class="nav-link" data-scroll-target="#过拟合与正则化">12.5 过拟合与正则化</a>
  <ul class="collapse">
  <li><a href="#过拟合问题" id="toc-过拟合问题" class="nav-link" data-scroll-target="#过拟合问题">12.5.1 过拟合问题</a></li>
  <li><a href="#正则化技术" id="toc-正则化技术" class="nav-link" data-scroll-target="#正则化技术">12.5.2 正则化技术</a></li>
  </ul></li>
  <li><a href="#深度学习简介" id="toc-深度学习简介" class="nav-link" data-scroll-target="#深度学习简介">12.6 深度学习简介</a>
  <ul class="collapse">
  <li><a href="#卷积神经网络cnn" id="toc-卷积神经网络cnn" class="nav-link" data-scroll-target="#卷积神经网络cnn">12.6.2 卷积神经网络（CNN）</a></li>
  <li><a href="#循环神经网络rnn" id="toc-循环神经网络rnn" class="nav-link" data-scroll-target="#循环神经网络rnn">12.6.3 循环神经网络（RNN）</a></li>
  <li><a href="#注意力机制" id="toc-注意力机制" class="nav-link" data-scroll-target="#注意力机制">12.6.5 注意力机制</a></li>
  </ul></li>
  <li><a href="#案例分析" id="toc-案例分析" class="nav-link" data-scroll-target="#案例分析">12.7 案例分析</a></li>
  <li><a href="#本章总结" id="toc-本章总结" class="nav-link" data-scroll-target="#本章总结">本章总结</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-3-introduction.html">III 进阶——超越线性的机器学习</a></li><li class="breadcrumb-item"><a href="../chapters/12 神经网络与深度学习基础.html"><span class="chapter-title">12 神经网络与深度学习基础</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">12 神经网络与深度学习基础</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="本章导读" class="level2">
<h2 class="anchored" data-anchor-id="本章导读">本章导读</h2>
<p>神经网络是预测建模领域的重要方法，它通过模拟人脑神经元的工作方式，为回归和分类问题提供了统一的解决方案。本章将从预测建模的本质出发，介绍神经网络的基本原理、网络设计、训练方法，并简要探讨深度学习的概念，帮助理解这一强大工具在回归和分类任务中的应用。</p>
</section>
<section id="神经网络回归与分类的统一框架" class="level2">
<h2 class="anchored" data-anchor-id="神经网络回归与分类的统一框架">12.1 神经网络：回归与分类的统一框架</h2>
<section id="从线性模型到神经网络" class="level3">
<h3 class="anchored" data-anchor-id="从线性模型到神经网络">12.1.1 从线性模型到神经网络</h3>
<p>线性模型的回顾： - 线性回归：<span class="math inline">\(y = w^T x + b\)</span>（连续输出） - 逻辑回归：<span class="math inline">\(P(y=1|x) = \sigma(w^T x + b)\)</span>（概率输出）</p>
<p>神经网络的扩展思路： 单一神经元可以看作一个广义线性模型，通过组合多个神经元并引入非线性激活函数，神经网络能够学习更复杂的模式。</p>
<p>基本神经元模型： <span class="math display">\[
\begin{aligned}
z &amp;= w^T x + b \quad \text{(线性组合)} \\
a &amp;= \sigma(z) \quad \text{(非线性变换)}
\end{aligned}
\]</span></p>
</section>
<section id="为什么需要神经网络" class="level3">
<h3 class="anchored" data-anchor-id="为什么需要神经网络">12.1.2 为什么需要神经网络？</h3>
<p>传统方法的局限性： - 线性模型只能捕捉线性关系 - 多项式回归需要手动设计特征组合 - 对复杂非线性模式建模能力有限</p>
<p>神经网络的优势： - 自动学习特征组合 - 通过层次化结构学习抽象特征 - 统一处理回归和分类问题</p>
</section>
</section>
<section id="网络架构设计" class="level2">
<h2 class="anchored" data-anchor-id="网络架构设计">12.2 网络架构设计</h2>
<section id="输出层设计" class="level3">
<h3 class="anchored" data-anchor-id="输出层设计">12.2.1 输出层设计</h3>
<p>回归问题的输出层： - 神经元数量：1个（单输出）或对应输出维度 - 激活函数：恒等函数（无激活） - 输出解释：连续数值预测</p>
<p>二分类问题的输出层： - 神经元数量：1个 - 激活函数：sigmoid - 输出解释：属于正类的概率</p>
<p>多分类问题的输出层： - 神经元数量：类别数K - 激活函数：softmax - 输出解释：每个类别的概率分布</p>
</section>
<section id="隐藏层设计" class="level3">
<h3 class="anchored" data-anchor-id="隐藏层设计">12.2.2 隐藏层设计</h3>
<p>隐藏层的作用： - 学习输入特征的中间表示 - 通过非线性变换增强模型表达能力 - 自动进行特征工程</p>
<p>网络深度与宽度： - 浅层网络：1-2个隐藏层，适合简单问题 - 深层网络：多个隐藏层，适合复杂模式 - 宽度：每层神经元数，影响模型容量</p>
</section>
</section>
<section id="激活函数与损失函数" class="level2">
<h2 class="anchored" data-anchor-id="激活函数与损失函数">12.3 激活函数与损失函数</h2>
<section id="常用激活函数" class="level3">
<h3 class="anchored" data-anchor-id="常用激活函数">12.3.1 常用激活函数</h3>
<p>Sigmoid函数： <span class="math display">\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]</span> - 将输出压缩到(0,1) - 适合输出层，直观的概率解释 - 梯度消失问题</p>
<p>ReLU函数： <span class="math display">\[
\text{ReLU}(z) = \max(0, z)
\]</span> - 计算简单，训练高效 - 缓解梯度消失 - 现代神经网络的首选</p>
<p>Tanh函数： <span class="math display">\[
\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\]</span> - 输出范围(-1,1)，零中心化 - 比sigmoid有更好的梯度特性</p>
</section>
<section id="损失函数选择" class="level3">
<h3 class="anchored" data-anchor-id="损失函数选择">12.3.2 损失函数选择</h3>
<p>回归任务： 均方误差损失： <span class="math display">\[
L = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
\]</span></p>
<p>二分类任务： 交叉熵损失： <span class="math display">\[
L = -\frac{1}{n} \sum_{i=1}^n [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]
\]</span></p>
<p>多分类任务： 多类交叉熵损失： <span class="math display">\[
L = -\frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K y_{ik} \log(\hat{y}_{ik})
\]</span></p>
</section>
</section>
<section id="神经网络训练" class="level2">
<h2 class="anchored" data-anchor-id="神经网络训练">12.4 神经网络训练</h2>
<section id="前向传播" class="level3">
<h3 class="anchored" data-anchor-id="前向传播">12.4.1 前向传播</h3>
<p>计算过程： 从输入层开始，逐层计算直到输出层： <span class="math display">\[
\begin{aligned}
z^{[l]} &amp;= W^{[l]} a^{[l-1]} + b^{[l]} \\
a^{[l]} &amp;= \sigma^{[l]}(z^{[l]})
\end{aligned}
\]</span></p>
<p>预测输出： 最终层的激活值即为模型预测。</p>
</section>
<section id="反向传播" class="level3">
<h3 class="anchored" data-anchor-id="反向传播">12.4.2 反向传播</h3>
<p>梯度计算： 利用链式法则计算损失函数对每个参数的梯度： <span class="math display">\[
\frac{\partial L}{\partial W^{[l]}} = \frac{\partial L}{\partial z^{[l]}} (a^{[l-1]})^T
\]</span></p>
<p>参数更新： 使用梯度下降算法更新参数： <span class="math display">\[
W^{[l]} := W^{[l]} - \alpha \frac{\partial L}{\partial W^{[l]}}
\]</span></p>
</section>
<section id="优化算法" class="level3">
<h3 class="anchored" data-anchor-id="优化算法">12.4.3 优化算法</h3>
<p>批量梯度下降： 使用全部训练数据计算梯度，收敛稳定但计算量大。</p>
<p>小批量梯度下降： 折中方案，兼顾收敛速度和稳定性。</p>
<p>Adam优化器： 自适应学习率，结合动量项，实践中效果良好。</p>
</section>
</section>
<section id="过拟合与正则化" class="level2">
<h2 class="anchored" data-anchor-id="过拟合与正则化">12.5 过拟合与正则化</h2>
<section id="过拟合问题" class="level3">
<h3 class="anchored" data-anchor-id="过拟合问题">12.5.1 过拟合问题</h3>
<p>神经网络的特点： - 参数众多，模型容量大 - 容易过拟合训练数据 - 需要正则化技术控制复杂度</p>
<p>检测方法： - 训练误差持续下降，验证误差开始上升 - 学习曲线分析 - 早停法</p>
</section>
<section id="正则化技术" class="level3">
<h3 class="anchored" data-anchor-id="正则化技术">12.5.2 正则化技术</h3>
<p>L2正则化： 在损失函数中加入权重惩罚： <span class="math display">\[
L_{\text{reg}} = L + \frac{\lambda}{2} \sum \|W\|^2
\]</span></p>
<p>Dropout： 训练时随机丢弃部分神经元，提高泛化能力。</p>
<p>数据增强： 通过变换生成更多训练样本。</p>
</section>
</section>
<section id="深度学习简介" class="level2">
<h2 class="anchored" data-anchor-id="深度学习简介">12.6 深度学习简介</h2>
<p>深度学习模型可以形式化地定义为：</p>
<p><span class="math display">\[
f(\mathbf{x}; \theta) = f_L(f_{L-1}(\cdots f_1(\mathbf{x}; \theta_1) \cdots; \theta_{L-1}); \theta_L)
\]</span></p>
<p>其中： - <span class="math inline">\(\mathbf{x}\)</span>：输入向量 - <span class="math inline">\(\theta = \{\theta_1, \theta_2, \dots, \theta_L\}\)</span>：模型参数 - <span class="math inline">\(f_l\)</span>：第<span class="math inline">\(l\)</span>层的变换函数 - <span class="math inline">\(L\)</span>：网络总层数（深度）</p>
<p>与浅层学习的对比</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>特征</th>
<th>浅层学习</th>
<th>深度学习</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>层数</strong></td>
<td>1-2层隐藏层</td>
<td>多层（通常&gt;3层）</td>
</tr>
<tr class="even">
<td><strong>特征工程</strong></td>
<td>需要手动设计</td>
<td>自动学习特征</td>
</tr>
<tr class="odd">
<td><strong>数据需求</strong></td>
<td>相对较少</td>
<td>大量数据</td>
</tr>
<tr class="even">
<td><strong>计算需求</strong></td>
<td>相对较低</td>
<td>高计算需求</td>
</tr>
<tr class="odd">
<td><strong>可解释性</strong></td>
<td>较好</td>
<td>较差（黑箱问题）</td>
</tr>
</tbody>
</table>
<section id="卷积神经网络cnn" class="level3">
<h3 class="anchored" data-anchor-id="卷积神经网络cnn">12.6.2 卷积神经网络（CNN）</h3>
<p>CNN的基本思想</p>
<p>卷积神经网络专门处理具有网格结构的数据（如图像），通过局部连接和权值共享大幅减少参数数量。</p>
<p>卷积操作</p>
<p>二维离散卷积： <span class="math display">\[
S(i,j) = (I * K)(i,j) = \sum_m \sum_n I(i+m, j+n)K(m,n)
\]</span></p>
<p>其中<span class="math inline">\(I\)</span>为输入图像，<span class="math inline">\(K\)</span>为卷积核。</p>
<p>卷积层特性</p>
<ol type="1">
<li><strong>局部连接</strong>：每个神经元只连接输入图像的局部区域</li>
<li><strong>权值共享</strong>：同一卷积核在输入的不同位置使用相同权重</li>
<li><strong>平移不变性</strong>：能够检测输入任何位置的特征</li>
</ol>
<p>CNN的基本组件</p>
<p>卷积层</p>
<p>输出特征图大小计算： <span class="math display">\[
\text{输出高度} = \frac{H - F_H + 2P}{S} + 1
\]</span> <span class="math display">\[
\text{输出宽度} = \frac{W - F_W + 2P}{S} + 1
\]</span></p>
<p>其中： - <span class="math inline">\(H, W\)</span>：输入高度和宽度 - <span class="math inline">\(F_H, F_W\)</span>：卷积核高度和宽度 - <span class="math inline">\(P\)</span>：填充（padding）大小 - <span class="math inline">\(S\)</span>：步长（stride）</p>
<p>池化层</p>
<ol type="1">
<li><p><strong>最大池化</strong>： <span class="math display">\[
\text{output} = \max(\text{window})
\]</span></p></li>
<li><p><strong>平均池化</strong>： <span class="math display">\[
\text{output} = \text{mean}(\text{window})
\]</span></p></li>
</ol>
<p>池化作用：降维、减少过拟合、增加平移不变性。</p>
<p>全连接层</p>
<p>在CNN末端，将特征图展平后连接全连接层进行分类。</p>
<p>经典CNN架构</p>
<p>LeNet-5（1998）</p>
<ul>
<li>输入：32×32灰度图像</li>
<li>结构：2个卷积层 + 2个池化层 + 3个全连接层</li>
<li>应用：手写数字识别</li>
</ul>
<p>AlexNet（2012）</p>
<ul>
<li>创新：ReLU激活函数、Dropout、数据增强</li>
<li>结构：5个卷积层 + 3个池化层 + 3个全连接层</li>
<li>成就：ImageNet竞赛冠军</li>
</ul>
<p>VGGNet（2014）</p>
<ul>
<li>特点：使用小卷积核（3×3），增加网络深度</li>
<li>VGG16：13个卷积层 + 3个全连接层</li>
<li>VGG19：16个卷积层 + 3个全连接层</li>
</ul>
<p>ResNet（2015）</p>
<ul>
<li>创新：残差连接，解决梯度消失问题</li>
<li>残差块： <span class="math display">\[
\mathbf{y} = \mathcal{F}(\mathbf{x}, \{W_i\}) + \mathbf{x}
\]</span></li>
<li>深度：ResNet-50, ResNet-101, ResNet-152</li>
</ul>
<hr>
</section>
<section id="循环神经网络rnn" class="level3">
<h3 class="anchored" data-anchor-id="循环神经网络rnn">12.6.3 循环神经网络（RNN）</h3>
<p>序列数据处理</p>
<p>循环神经网络用于处理序列数据，具有时间维度上的记忆能力。</p>
<p>RNN基本结构</p>
<p><span class="math display">\[
\mathbf{h}_t = \phi(\mathbf{W}_{hh}\mathbf{h}_{t-1} + \mathbf{W}_{xh}\mathbf{x}_t + \mathbf{b}_h)
\]</span> <span class="math display">\[
\mathbf{y}_t = \psi(\mathbf{W}_{hy}\mathbf{h}_t + \mathbf{b}_y)
\]</span></p>
<p>其中： - <span class="math inline">\(\mathbf{h}_t\)</span>：时刻<span class="math inline">\(t\)</span>的隐藏状态 - <span class="math inline">\(\mathbf{x}_t\)</span>：时刻<span class="math inline">\(t\)</span>的输入 - <span class="math inline">\(\mathbf{y}_t\)</span>：时刻<span class="math inline">\(t\)</span>的输出</p>
<p>不同类型的RNN</p>
<ol type="1">
<li><strong>一对一</strong>：标准神经网络</li>
<li><strong>一对多</strong>：图像描述生成</li>
<li><strong>多对一</strong>：情感分析</li>
<li><strong>多对多（等长）</strong>：词性标注</li>
<li><strong>多对多（不等长）</strong>：机器翻译</li>
</ol>
<p><strong>长短期记忆网络（LSTM）</strong></p>
<p>LSTM通过门控机制解决长期依赖问题。</p>
<p>LSTM单元结构</p>
<ol type="1">
<li><p><strong>遗忘门</strong>： <span class="math display">\[
\mathbf{f}_t = \sigma(\mathbf{W}_f[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_f)
\]</span></p></li>
<li><p><strong>输入门</strong>： <span class="math display">\[
\mathbf{i}_t = \sigma(\mathbf{W}_i[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_i)
\]</span> <span class="math display">\[
\tilde{\mathbf{C}}_t = \tanh(\mathbf{W}_C[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_C)
\]</span></p></li>
<li><p><strong>细胞状态更新</strong>： <span class="math display">\[
\mathbf{C}_t = \mathbf{f}_t \odot \mathbf{C}_{t-1} + \mathbf{i}_t \odot \tilde{\mathbf{C}}_t
\]</span></p></li>
<li><p><strong>输出门</strong>： <span class="math display">\[
\mathbf{o}_t = \sigma(\mathbf{W}_o[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_o)
\]</span> <span class="math display">\[
\mathbf{h}_t = \mathbf{o}_t \odot \tanh(\mathbf{C}_t)
\]</span></p></li>
</ol>
<p>门控循环单元（GRU）</p>
<p>GRU是LSTM的简化版本，合并遗忘门和输入门： <span class="math display">\[
\mathbf{z}_t = \sigma(\mathbf{W}_z[\mathbf{h}_{t-1}, \mathbf{x}_t])
\]</span> <span class="math display">\[
\mathbf{r}_t = \sigma(\mathbf{W}_r[\mathbf{h}_{t-1}, \mathbf{x}_t])
\]</span> <span class="math display">\[
\tilde{\mathbf{h}}_t = \tanh(\mathbf{W}[\mathbf{r}_t \odot \mathbf{h}_{t-1}, \mathbf{x}_t])
\]</span> <span class="math display">\[
\mathbf{h}_t = (1 - \mathbf{z}_t) \odot \mathbf{h}_{t-1} + \mathbf{z}_t \odot \tilde{\mathbf{h}}_t
\]</span></p>
</section>
<section id="注意力机制" class="level3">
<h3 class="anchored" data-anchor-id="注意力机制">12.6.5 注意力机制</h3>
<p>缩放点积注意力</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V
\]</span></p>
<p>其中： - <span class="math inline">\(Q\)</span>：查询矩阵 - <span class="math inline">\(K\)</span>：键矩阵 - <span class="math inline">\(V\)</span>：值矩阵 - <span class="math inline">\(d_k\)</span>：键的维度</p>
<p>多头注意力</p>
<p><span class="math display">\[
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h)W^O
\]</span> <span class="math display">\[
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
\]</span></p>
<p><strong>Transformer架构</strong></p>
<p>编码器-解码器结构</p>
<p><strong>编码器</strong>（<span class="math inline">\(N\)</span>层）： 1. 多头自注意力 2. 前馈神经网络 3. 残差连接 + 层归一化</p>
<p><strong>解码器</strong>（<span class="math inline">\(N\)</span>层）： 1. 掩码多头自注意力（防止看到未来信息） 2. 多头编码器-解码器注意力 3. 前馈神经网络 4. 残差连接 + 层归一化</p>
<p>位置编码</p>
<p>为序列添加位置信息： <span class="math display">\[
PE_{(pos, 2i)} = \sin(pos/10000^{2i/d})
\]</span> <span class="math display">\[
PE_{(pos, 2i+1)} = \cos(pos/10000^{2i/d})
\]</span></p>
<p><strong>BERT与GPT</strong></p>
<p>BERT（双向编码器表示）</p>
<ul>
<li>预训练任务：掩码语言模型 + 下一句预测</li>
<li>特点：双向上下文理解</li>
<li>应用：文本分类、问答、命名实体识别</li>
</ul>
<p>GPT（生成式预训练Transformer）</p>
<ul>
<li>架构：仅解码器的Transformer</li>
<li>预训练：自回归语言建模</li>
<li>特点：强大的生成能力</li>
</ul>
</section>
</section>
<section id="案例分析" class="level2">
<h2 class="anchored" data-anchor-id="案例分析">12.7 案例分析</h2>
</section>
<section id="本章总结" class="level2">
<h2 class="anchored" data-anchor-id="本章总结">本章总结</h2>
<p>核心概念回顾</p>
<ol type="1">
<li>统一框架：神经网络为回归和分类提供统一建模框架</li>
<li>架构设计：根据问题类型设计输出层，回归用线性输出，分类用sigmoid/softmax输出</li>
<li>激活函数：ReLU适合隐藏层，根据任务选择输出层激活函数</li>
<li>训练原理：前向传播计算预测，反向传播计算梯度，梯度下降更新参数</li>
<li>正则化：使用L2正则化、Dropout等技术防止过拟合</li>
</ol>
<p>实践应用指南</p>
<p>数据预处理要求： - 特征标准化：加速收敛，提高数值稳定性 - 数据量要求：神经网络通常需要较多训练数据 - 计算资源：深层网络需要较强的计算能力</p>
<p>与传统方法的选择：</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>考虑因素</th>
<th>选择传统方法</th>
<th>选择神经网络</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>数据量</td>
<td>小样本</td>
<td>大样本</td>
</tr>
<tr class="even">
<td>问题复杂度</td>
<td>简单线性关系</td>
<td>复杂非线性关系</td>
</tr>
<tr class="odd">
<td>可解释性</td>
<td>要求高</td>
<td>要求低</td>
</tr>
<tr class="even">
<td>计算资源</td>
<td>有限</td>
<td>充足</td>
</tr>
<tr class="odd">
<td>特征工程</td>
<td>手动设计</td>
<td>自动学习</td>
</tr>
</tbody>
</table>
<p>深度学习扩展</p>
<p>成功应用领域： - 计算机视觉：图像分类、目标检测 - 自然语言处理：文本分类、机器翻译 - 语音识别：语音转文本、声纹识别 - 推荐系统：个性化推荐</p>
<p>实践建议： 1. 从基础开始：先掌握浅层神经网络，再学习深度学习 2. 理解原理：不仅要会使用，更要理解背后的数学原理 3. 项目驱动：通过实际项目加深理解 4. 持续学习：深度学习领域发展迅速，需要持续跟进</p>
<p>与前面章节的联系</p>
<p>神经网络不是孤立的方法，而是前面学习内容的自然延伸：</p>
<ul>
<li>单层神经网络 = 广义线性模型</li>
<li>多层神经网络 = 多个广义线性模型的堆叠+非线性变换</li>
<li>深度学习 = 更深层次的特征学习</li>
</ul>
<p>通过本教材的学习，希望读者能够建立从传统统计方法到现代机器学习的完整知识体系，在实际问题中选择合适的建模方法。</p>
<p><em>全书总结：从线性回归到神经网络，我们建立了一套完整的预测建模方法体系。每种方法都有其适用场景和局限性，在实际工作中需要根据具体问题选择合适的方法，理解其假设和限制，才能构建出有效的预测模型。</em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "已复制");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "已复制");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/11 支持向量机.html" class="pagination-link" aria-label="11 支持向量机">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">11 支持向量机</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/part-4-introduction.html" class="pagination-link" aria-label="part-4-introduction.html">
        <span class="nav-page-text"><span class="chapter-title">part-4-introduction.html</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>