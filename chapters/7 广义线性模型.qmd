---
title: "7 广义线性模型"
format: html
editor: source
---

## 本章导读

在实际应用中，响应变量并不总是连续型的。当面临分类问题或计数数据时，传统线性回归模型的局限性凸显。本章将系统介绍广义线性模型的统一框架，重点讲解逻辑斯谛回归、Probit回归和线性判别分析等经典分类方法，为您提供处理分类问题的完整理论体系和实用工具。

## 7.1 虚拟变量

### 7.1.1 虚拟变量的本质与构建

虚拟变量（Dummy Variables），又称指示变量（Indicator Variables），是将分类自变量转化为数值变量的基本技术。其核心思想是用二进制编码表示类别成员身份。

### 7.1.2 虚拟变量的构建原则

对于一个具有$k$个类别的分类变量，通常需要$k-1$个虚拟变量，以避免**虚拟变量陷阱**（完全多重共线性）。这种编码方式称为**参照组编码**或**基线编码**。

$$
D_1 = \begin{cases} 
1 & \text{如果观测属于类别1} \\
0 & \text{否则}
\end{cases},\quad
D_2 = \begin{cases} 
1 & \text{如果观测属于类别2} \\
0 & \text{否则}
\end{cases},\quad
\cdots,\quad
D_{k-1} = \begin{cases} 
1 & \text{如果观测属于类别$k-1$} \\
0 & \text{否则}
\end{cases}
$$

第$k$个类别作为参照组，当所有$D_i=0$时表示属于参照组。

### 7.1.3  包含虚拟变量的回归模型

考虑一个简单的回归模型，包含一个连续自变量$X$和一个具有三个类别的分类变量$C$：

$$
Y = \beta_0 + \beta_1 X + \beta_2 D_1 + \beta_3 D_2 + \beta_4 (X \times D_1) + \beta_5 (X \times D_2) + \varepsilon
$$

其中： - $\beta_0$：参照组的截距 - $\beta_1$：参照组中$X$对$Y$的效应 - $\beta_2, \beta_3$：类别1和类别2相对于参照组的截距差异 - $\beta_4, \beta_5$：类别1和类别2中$X$效应的差异（交互作用）

### 7.1.4 虚拟变量的统计检验

- 单个虚拟变量的t检验：检验特定类别与参照组是否存在显著差异
-  联合F检验：检验所有虚拟变量（即整个分类变量）是否显著 
$$
    F = \frac{(SSR_{\text{完整}} - SSR_{\text{简化}})/(k-1)}{SSR_{\text{完整}}/(n-k-p)}
$$ 其中$p$为其他自变量的数量



多项式虚拟变量

对于有序分类变量，可以检验线性、二次等趋势： 
$$
Y = \beta_0 + \beta_1 X + \gamma_1 L + \gamma_2 Q + \varepsilon
$$ 
其中$L$和$Q$分别表示线性项和二次项编码。

虚拟变量与结构变化检验

虚拟变量可用于检验不同子样本（如不同时期、不同群体）的模型结构是否相同，这是Chow检验的基础。

## 7.2 广义线性模型理论

### 7.2.1 指数族分布

指数族的概率密度函数： $$
f(y|\theta,\phi) = \exp\left\{\frac{y\theta - b(\theta)}{a(\phi)} + c(y,\phi)\right\}
$$

其中：

-   $\theta$：自然参数（典则参数）

-   $\phi$：离散参数

-   $a(\cdot), b(\cdot), c(\cdot)$已知函数

常见分布的指数族形式：

| 分布 | $\theta$ | $\phi$ | $b(\theta)$ | $a(\phi)$ |
|---------------|---------------|---------------|---------------|---------------|
| 正态 | $\mu$ | $\sigma^2$ | $\frac{\theta^2}{2}$ | $\phi$ |
| 泊松 | $\ln\mu$ | 1 | $e^\theta$ | 1 |
| 二项 | $\ln\left(\frac{\pi}{1-\pi}\right)$ | 1 | $\ln(1+e^\theta)$ | 1 |
| Gamma | $-\frac{1}{\mu}$ | $\nu$ | $-\ln(-\theta)$ | $\frac{1}{\nu}$ |

### 7.2.2 GLM的三组成部分

随机成分： 响应变量 $Y$ 来自指数族分布： $$
Y \sim f(y|\theta,\phi)
$$

系统成分： 线性预测器： $$
\eta = \beta_0 + \beta_1X_1 + \cdots + \beta_pX_p = \mathbf{X}\pmb{\beta}
$$

连接函数： 连接随机成分和系统成分： $$
g(\mu) = \eta
$$ 其中 $\mu = E(Y) = b'(\theta)$

### 7.2.3 典则连接函数

定义： 当 $g(\mu) = \theta$ 时，称为典则连接函数。

性质： - 简化计算和理论推导 - 保证 $\mathbf{X}'\mathbf{y}$ 是充分统计量 - 在多数情况下具有良好的统计性质

## 7.3 逻辑斯谛回归

### 7.3.1 二项分布的GLM框架

伯努利分布： $$
P(Y=1) = \pi, \quad P(Y=0) = 1-\pi
$$

典则连接函数（logit函数）： $$
\eta = \ln\left(\frac{\pi}{1-\pi}\right) = \mathbf{X}\pmb{\beta}
$$

逆连接函数（sigmoid函数）： $$
\pi = \frac{e^{\mathbf{X}\pmb{\beta}}}{1 + e^{\mathbf{X}\pmb{\beta}}} = \frac{1}{1 + e^{-\mathbf{X}\pmb{\beta}}}
$$

### 7.3.2 参数估计：极大似然法

似然函数： $$
L(\pmb{\beta}) = \prod_{i=1}^n \pi_i^{y_i}(1-\pi_i)^{1-y_i}
$$

对数似然函数： $$
\ell(\pmb{\beta}) = \sum_{i=1}^n \left[y_i\ln\pi_i + (1-y_i)\ln(1-\pi_i)\right]
$$

得分函数： $$
\frac{\partial \ell}{\partial \pmb{\beta}} = \sum_{i=1}^n (y_i - \pi_i)\mathbf{x}_i = \mathbf{0}
$$

### 7.3.3 迭代加权最小二乘算法

权重矩阵： $$
\mathbf{W} = \text{diag}\left[\pi_i(1-\pi_i)\right]
$$

工作响应变量： $$
z_i = \mathbf{x}_i'\pmb{\beta} + \frac{y_i - \pi_i}{\pi_i(1-\pi_i)}
$$

迭代更新： $$
\pmb{\beta}^{(t+1)} = (\mathbf{X}'\mathbf{W}^{(t)}\mathbf{X})^{-1}\mathbf{X}'\mathbf{W}^{(t)}\mathbf{z}^{(t)}
$$

### 7.3.4 统计推断与解释

优势比解释： 对于二值自变量 $X_j$： $$
\text{OR}_j = e^{\beta_j} = \frac{\pi|X_j=1/(1-\pi|X_j=1)}{\pi|X_j=0/(1-\pi|X_j=0)}
$$

Wald检验： $$
z_j = \frac{\hat{\beta}_j}{SE(\hat{\beta}_j)} \sim N(0,1)
$$

似然比检验： $$
G = 2[\ell(\hat{\pmb{\beta}}) - \ell(\hat{\pmb{\beta}}_0)] \sim \chi^2(p-p_0)
$$

### 7.3.5 多项逻辑斯谛回归

基线类别Logit模型

对于$J$个类别的响应变量，以第$J$类为参照： $$
\log\left(\frac{P(Y_i=j|\mathbf{x}_i)}{P(Y_i=J|\mathbf{x}_i)}\right) = \beta_{j0} + \beta_{j1}x_{i1} + \cdots + \beta_{jp}x_{ip}, \quad j=1,\ldots,J-1
$$

类别概率计算

$$
P(Y_i=j|\mathbf{x}_i) = \frac{\exp(\eta_{ij})}{1 + \sum_{m=1}^{J-1} \exp(\eta_{im})}, \quad j=1,\ldots,J-1
$$

$$
P(Y_i=J|\mathbf{x}_i) = \frac{1}{1 + \sum_{m=1}^{J-1} \exp(\eta_{im})}
$$

其中$\eta_{ij} = \beta_{j0} + \beta_{j1}x_{i1} + \cdots + \beta_{jp}x_{ip}$。

### 7.3.6 有序逻辑斯谛回归

对于有序响应变量，使用比例优势模型： 
$$
\log\left(\frac{P(Y_i \leq j|\mathbf{x}_i)}{P(Y_i > j|\mathbf{x}_i)}\right) = \alpha_j - (\beta_1 x_{i1} + \cdots + \beta_p x_{ip}), \quad j=1,\ldots,J-1
$$

其中$\alpha_1 < \alpha_2 < \cdots < \alpha_{J-1}$为切点参数，负号使得$\beta$的正值表示更可能属于更高类别。

## 7.4 Probit回归

### 7.4.1 Probit模型设定

Probit连接函数： $$
\Phi^{-1}(\pi) = \mathbf{X}\pmb{\beta}
$$

其中 $\Phi(\cdot)$ 是标准正态分布的累积分布函数。

概率形式： $$
\pi = \Phi(\mathbf{X}\pmb{\beta})
$$

### 7.4.2 潜在变量解释

潜变量模型： 假设存在连续潜变量 $Y^*$： 
$$
Y^* = \mathbf{X}\pmb{\beta} + \varepsilon, \quad \varepsilon \sim N(0,1)
$$

观测响应： 
$$
Y = \begin{cases}
1 & \text{if } Y^* > 0 \\
0 & \text{otherwise}
\end{cases}
$$

概率推导： 
$$
P(Y=1|\mathbf{X}) = P(Y^* > 0) = P(\varepsilon > -\mathbf{X}\pmb{\beta}) = \Phi(\mathbf{X}\pmb{\beta})
$$

### 7.4.3 与Logit模型的比较

连接函数形状： - Logit：$g(p) = \ln\left(\frac{p}{1-p}\right)$ - Probit：$g(p) = \Phi^{-1}(p)$

尾部行为： - Logit函数有更重的尾部 - 在实践中两者通常给出相似的结果

系数转换： $$
\beta_{\text{logit}} \approx 1.6 \times \beta_{\text{probit}}
$$

## 7.5 模型比较与选择

### 7.5.1 分类性能评估

混淆矩阵：

|          | 预测正类 | 预测负类 |
|----------|----------|----------|
| 实际正类 | TP       | FN       |
| 实际负类 | FP       | TN       |

常用指标： - 准确率：$\frac{TP+TN}{n}$ - 精确率：$\frac{TP}{TP+FP}$ - 召回率：$\frac{TP}{TP+FN}$ - F1分数：$\frac{2\times\text{精确率}\times\text{召回率}}{\text{精确率}+\text{召回率}}$

### 7.5.2 ROC曲线与AUC

ROC曲线： 以假正率为横轴，真正率为纵轴的曲线。

AUC解释： - AUC = 0.5：随机猜测 - AUC = 1.0：完美分类 - AUC \> 0.8：通常认为模型表现良好

### 7.5.3 方法比较

| 方法 | 类型 | 假设 | 优点 | 局限性 |
|---------------|---------------|---------------|---------------|---------------|
| 逻辑回归 | 判别式 | 线性决策边界 | 概率输出，可解释性强 | 对特征相关性敏感 |
| Probit回归 | 判别式 | 线性决策边界 | 有潜在变量解释 | 计算稍复杂 |
| LDA | 生成式 | 正态分布，等协方差 | 小样本表现好，多分类自然 | 假设较强 |

### 7.5.4 模型诊断

离群值检测： - Pearson残差：$r_i = \frac{y_i - \hat{\pi}_i}{\sqrt{\hat{\pi}_i(1-\hat{\pi}_i)}}$ - Deviance残差：$d_i = \text{sign}(y_i - \hat{\pi}_i)\sqrt{-2[y_i\ln\hat{\pi}_i + (1-y_i)\ln(1-\hat{\pi}_i)]}$

拟合优度检验： - Hosmer-Lemeshow检验 - 皮尔逊卡方检验

过度离散检验： $$
\frac{\sum_{i=1}^n (y_i - \hat{\pi}_i)^2}{\hat{\pi}_i(1-\hat{\pi}_i)} \sim \chi^2(n-p-1)
$$

## 7.6 案例分析

## 本章总结

核心公式回顾

1.  GLM连接函数：$g(\mu) = \mathbf{X}\pmb{\beta}$
2.  Logit模型：$\ln\left(\frac{\pi}{1-\pi}\right) = \mathbf{X}\pmb{\beta}$
3.  Probit模型：$\Phi^{-1}(\pi) = \mathbf{X}\pmb{\beta}$
4.  LDA判别函数：$\delta_k(\mathbf{x}) = \mathbf{x}'\pmb{\Sigma}^{-1}\pmb{\mu}_k - \frac{1}{2}\pmb{\mu}_k'\pmb{\Sigma}^{-1}\pmb{\mu}_k + \ln\pi_k$
5.  IWLS更新：$\pmb{\beta}^{(t+1)} = (\mathbf{X}'\mathbf{W}^{(t)}\mathbf{X})^{-1}\mathbf{X}'\mathbf{W}^{(t)}\mathbf{z}^{(t)}$

方法选择指南

| 问题场景     | 推荐方法             | 理由                 |
|--------------|----------------------|----------------------|
| 需要概率输出 | 逻辑回归、Probit回归 | 直接建模条件概率     |
| 小样本问题   | LDA                  | 参数更少，估计更稳定 |
| 多分类问题   | LDA、多项逻辑回归    | 天然处理多类别       |
| 可解释性重要 | 逻辑回归             | 优势比有明确解释     |
| 理论一致性   | Probit回归           | 有潜在变量理论基础   |

实践建议

1.  数据预处理：检查类别平衡性，必要时重采样
2.  特征工程：考虑交互项和非线性变换
3.  模型验证：使用交叉验证评估泛化能力
4.  结果解释：结合领域知识理解系数含义
5.  稳健性分析：尝试不同方法，比较结果一致性

广义线性模型为处理非正态响应变量提供了统一的框架，而线性分类方法则是机器学习中最基础且重要的工具。掌握这些方法为进一步学习更复杂的非线性模型奠定了坚实基础。