---
title: "14 分类任务"
format: html
editor: visual
---

```{r echo=FALSE,include=FALSE,results='hide'}
# 在 R 中直接指定 Anaconda 路径
library(reticulate)
# 查看已安装的 conda 环境
conda_list()

# 查看 conda 可执行文件路径
conda_binary()

# 查看 conda 版本
conda_version()
# 指定 Python 可执行文件路径
use_python("C:/Data/Anaconda/python.exe")  

# 使用 Conda 环境
use_condaenv("base")  # 使用基础环境
```

## 分类问题导读

分类问题是机器学习中最常见的任务之一，广泛应用于物种分类、医疗诊断、客户分类等领域。本章将通过鸢尾花分类案例，完整展示多分类问题的解决方案，涵盖数据探索、特征工程、多种分类算法比较、模型评估等关键环节。

## 14.1 Benchmark

mlr3提供了强大的Benchmark功能，可以系统性地比较多个学习器在多个任务上的性能。

```{r}
library(mlr3)
library(mlr3verse)
library(mlr3pipelines)
library(mlr3tuning)
library(data.table)
library(ggplot2)
library(corrplot)
library(gridExtra)
library(patchwork)
library(paradox)
# 查看mlr包支持的学习算法
mlr_learners
```

加载数据，建立任务

```{r}
# 创建多个任务（不同特征子集）
data("Ionosphere", package = "mlbench")
Ionosphere_data <- as.data.table(Ionosphere)
Ionosphere_data=Ionosphere_data[, -c(1, 2)]
str(Ionosphere_data )
cat("\n缺失值检查:\n")
missing_counts <- colSums(is.na(Ionosphere_data))
print(missing_counts)

data("Sonar", package = "mlbench")
sonar_data <- as.data.table(Sonar)
cat("\n缺失值检查:\n")
missing_sonar <- colSums(is.na(sonar_data)) 
print(missing_sonar)
str(sonar_data)

task_Ionosphere <- as_task_classif(Ionosphere_data, target = "Class", id = "Ionosphere")

task_sonar <- as_task_classif(sonar_data, target = "Class", id = "sonar")

tasks = list(task_Ionosphere, task_sonar)
```

```{r}
# 定义学习器
learners_extended <- list(
  lrn("classif.ranger", id = "random_forest", predict_type = "prob"),
  lrn("classif.xgboost", id = "xgboost", predict_type = "prob"),
  lrn("classif.svm", id = "svm", predict_type = "prob"),
  lrn("classif.kknn", id = "knn", predict_type = "prob"),
  lrn("classif.naive_bayes", id = "naive_bayes", predict_type = "prob"),
  lrn("classif.rpart", id = "decision_tree", predict_type = "prob")
)

# 设置不同的重采样策略
resamplings <- list(
  cv5 = rsmp("cv", folds = 5),
  cv10 = rsmp("cv", folds = 10),
  holdout = rsmp("holdout", ratio = 0.7),
  bootstrap = rsmp("bootstrap", repeats = 5)
)

# 创建Benchmark设计
design_extended <- benchmark_grid(
  tasks = tasks,
  learners = learners_extended,
  resamplings = resamplings[1]  # 使用5折交叉验证以节省时间
)

# 执行Benchmark
cat("开始扩展Benchmark分析...\n")
bmr_extended <- benchmark(design_extended, store_models = TRUE)

# 性能汇总
cat("\n=== Benchmark性能汇总 ===\n")
measures_all <- msrs(c("classif.acc", "classif.auc", "classif.bacc", "classif.ce"))
bmr_results <- bmr_extended$aggregate(measures_all)

# 格式化结果
results_detailed <- bmr_results[, .(
  Task = task_id,
  Model = learner_id,
  Resampling = resampling_id,
  Accuracy = classif.acc,
  AUC = classif.auc,
  Balanced_Accuracy = classif.bacc,
  LogLoss = classif.ce
)]

print(results_detailed[order(Task, -Accuracy)])

# 按任务分组统计
cat("\n=== 按任务分组的性能统计 ===\n")
task_stats <- results_detailed[, .(
  Mean_Accuracy = mean(Accuracy),
  Std_Accuracy = sd(Accuracy),
  Best_Model = .SD[which.max(Accuracy)]$Model,
  Best_Accuracy = max(Accuracy)
), by = Task]

print(task_stats)
```

Benchmark结果可视化

```{r}
# Benchmark结果可视化

# 1. 按任务和模型的准确率热图
accuracy_matrix <- dcast(results_detailed, Model ~ Task, value.var = "Accuracy")
print("准确率矩阵:")
print(accuracy_matrix)

# 可视化热图
heatmap_data <- as.matrix(accuracy_matrix[, -1])
rownames(heatmap_data) <- accuracy_matrix$Model

library(reshape2)
heatmap_df <- melt(accuracy_matrix, id.vars = "Model", 
                   variable.name = "Task", value.name = "Accuracy")

p1 <- ggplot(heatmap_df, aes(x = Task, y = Model, fill = Accuracy)) +
  geom_tile(color = "white") +
  geom_text(aes(label = round(Accuracy, 3)), color = "black", size = 3) +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue", midpoint = 0.9) +
  labs(title = "模型在不同任务上的准确率热图", 
       x = "任务", y = "模型") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# 2. 模型性能比较箱线图
p2 <- ggplot(results_detailed, aes(x = reorder(Model, Accuracy), y = Accuracy, fill = Model)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  labs(title = "模型性能分布", x = "模型", y = "准确率") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  coord_flip()

# 3. 任务性能比较
p3 <- ggplot(results_detailed, aes(x = Task, y = Accuracy, fill = Task)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "不同任务的性能比较", x = "任务", y = "准确率") +
  theme_minimal() +
  theme(legend.position = "none")

# 组合图形
library(patchwork)
(p1) / (p2 | p3)
```

统计显著性检验

```{r}
# 统计显著性检验

# 提取所有resample结果的预测
predictions_all <- bmr_extended$score()

# 查看提取的结果结构
str(predictions_all, max.level = 1)

# 提取具体的预测对象
predictions_list <- predictions_all$prediction

# Friedman检验 - 比较多个模型的性能
if (requireNamespace("scmamp", quietly = TRUE)) {
  library(scmamp)
  
  # 准备数据用于Friedman检验
  accuracy_matrix <- dcast(results_detailed, Task ~ Model, value.var = "Accuracy")
  accuracy_data <- as.matrix(accuracy_matrix[, -1])
  
  cat("\n=== Friedman检验 ===\n")
  friedman_test <- friedmanTest(accuracy_data)
  print(friedman_test)
  
  if (friedman_test$p.value < 0.05) {
    cat("模型间存在显著差异，进行事后检验...\n")
    
    # Nemenyi事后检验
    nemenyi_test <- nemenyiTest(accuracy_data)
    print(nemenyi_test)
    
    # 可视化CD图
    plotCD(accuracy_data, alpha = 0.05)
  } else {
    cat("模型间无显著差异\n")
  }
} else {
  cat("scmamp包未安装，跳过统计检验\n")
}

# 简单的成对t检验
cat("\n=== 最佳模型 vs 其他模型的成对t检验 ===\n")
best_model <- results_detailed[which.max(Accuracy)]$Model
best_accuracies <- results_detailed[Model == best_model]$Accuracy

for (model in unique(results_detailed$Model)) {
  if (model != best_model) {
    model_accuracies <- results_detailed[Model == model]$Accuracy
    t_test <- t.test(best_accuracies, model_accuracies, paired = TRUE)
    cat(sprintf("%s vs %s: p-value = %.4f\n", best_model, model, t_test$p.value))
  }
}
```

## 14.2 Benchmark分析总结

mlr3 Benchmark优势

统一的接口：`benchmark()`函数提供统一的Benchmark接口 灵活的设计：支持多个任务、学习器、重采样策略的组合 内置存储：可以存储模型和预测结果用于后续分析 丰富的结果：自动计算多个评估指标 统计检验：内置Friedman检验等统计方法

最佳实践建议

系统化比较：在项目初期进行全面的Benchmark分析 多维度评估：考虑准确率、训练时间、可解释性等多个维度 统计验证：使用统计检验验证性能差异的显著性 业务导向：根据具体业务需求选择最适合的模型 可重复性：设置随机种子确保结果可重复

这样的Benchmark分析为模型选择提供了科学依据，确保选择的模型不仅在测试集上表现好，而且具有统计显著性。

## 14.4 R语言--多分类

数据集说明 本案例使用经典的鸢尾花数据集（Iris Dataset），包含三种鸢尾花的萼片和花瓣测量数据。 **目标**：预测鸢尾花的种类（Species）\
**任务类型**：多分类问题（3个类别）\
**业务价值**：植物分类、物种识别

数据加载与探索

```{r}
# 综合案例：鸢尾花分类 - R语言实现 (mlr3框架)

# 加载必要的包
library(mlr3)
library(mlr3verse)
library(mlr3pipelines)
library(mlr3tuning)
library(data.table)
library(ggplot2)
library(corrplot)
library(gridExtra)
library(patchwork)

# 加载鸢尾花数据集
data("iris", package = "datasets")
iris_data <- as.data.table(iris)

# 数据基本信息
str(iris_data)

# 检查缺失值
cat("\n缺失值检查:\n")
print(colSums(is.na(iris_data)))
```

数据可视化分析

```{r}
# 数据可视化分析 - R语言

# 类别分布
p1 <- ggplot(iris_data, aes(x = Species, fill = Species)) +
  geom_bar(alpha = 0.7) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "类别分布", x = "鸢尾花种类", y = "数量") +
  theme_minimal() +
  theme(legend.position = "none")

# 花萼长度与宽度的关系
p2 <- ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "花萼长度 vs 宽度", x = "花萼长度", y = "花萼宽度") +
  theme_minimal()

# 花瓣长度与宽度的关系
p3 <- ggplot(iris_data, aes(x = Petal.Length, y = Petal.Width, color = Species)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "花瓣长度 vs 宽度", x = "花瓣长度", y = "花瓣宽度") +
  theme_minimal()

# 特征分布箱线图
p4 <- ggplot(iris_data, aes(x = Species, y = Petal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "花瓣长度分布", x = "鸢尾花种类", y = "花瓣长度") +
  theme_minimal() +
  theme(legend.position = "none")

# 组合图形
(p1 + p2) / (p3 + p4)
```

创建mlr3任务和数据预处理

```{r}
# 创建mlr3任务和数据预处理

# 创建分类任务
task_iris <- as_task_classif(iris_data, target = "Species", id = "iris",store_backends=TRUE)

# 查看任务信息
cat("任务信息:\n")
print(task_iris)

# 数据预处理管道
preprocess_pipeline <- po("scale") %>>% 
  po("encode") %>>%
  po("colapply", applicator = as.numeric)

# 应用预处理
task_preprocessed <- preprocess_pipeline$train(task_iris)[[1]]

cat("\n预处理后的任务信息:\n")
print(task_preprocessed)
```

模型训练与比较

```{r}
# 模型训练与比较 - mlr3

# 定义学习器
learners <- list(
  lrn("classif.ranger", id = "random_forest", predict_type = "prob"),
  lrn("classif.xgboost", id = "xgboost", predict_type = "prob"),
  lrn("classif.svm", id = "svm", predict_type = "prob"),
  lrn("classif.kknn", id = "knn", predict_type = "prob")
)

# 设置交叉验证和评估指标
resampling <- rsmp("cv", folds = 5)
measures <- msrs(c("classif.acc", "classif.auc", "classif.bacc", "classif.ce"))

# 基准测试
design <- benchmark_grid(
  tasks = task_preprocessed,
  learners = learners,
  resamplings = resampling
)

bmr <- benchmark(design,store_backends=TRUE)

# 性能评估
cat("模型性能比较:\n")
bmr_aggregated <- bmr$aggregate(measures)

# 格式化输出结果
results_r <- bmr_aggregated[, .(
  Model = learner_id,
  Accuracy = classif.acc,
  AUC = classif.auc,
  Balanced_Accuracy = classif.bacc,
  LogLoss = classif.ce
)]

print(results_r[order(-Accuracy)])

# 性能可视化
ggplot(results_r, aes(x = reorder(Model, Accuracy), y = Accuracy)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  labs(title = "模型性能比较 (准确率) - R/mlr3", x = "模型", y = "准确率") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(0, 1)
```

超参数调优

```{r}
#| cache: FALSE  # 禁用缓存
# 超参数调优示例 - 随机森林
library(mlr3)           # 核心
library(mlr3learners)   # 学习器
library(mlr3tuning)     # 参数调优（包含 tnr()）
library(paradox)        # 参数空间
library(mlr3viz)        # 可视化
# 定义随机森林学习器
learner_rf_tune <- lrn("classif.ranger", predict_type = "prob", num.trees = 100)

# 定义超参数空间
param_set <- ps(
  mtry = p_int(lower = 1, upper = ncol(iris_data) - 1),
  min.node.size = p_int(lower = 1, upper = 10),
  sample.fraction = p_dbl(lower = 0.6, upper = 0.9)
)

# 定义调优器
tuner <- tnr("grid_search", resolution = 5)
terminator <- trm("evals", n_evals = 10)

# 自动调优
at <- auto_tuner(
  tuner = tuner,
  learner = learner_rf_tune,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  search_space = param_set,
  terminator = terminator
)

# 在数据上演示调优
set.seed(123)
at$train(task_preprocessed)

cat("最佳参数:\n")
print(at$tuning_result)

# 使用调优后的模型进行预测
predictions_tuned <- at$predict(task_preprocessed)
cat("调优完成\n")
cat("调优后模型准确率:", predictions_tuned$score(msr("classif.acc")), "\n")
```

模型解释

```{r}
#| cache: FALSE  # 禁用缓存
# 模型解释 - 特征重要性
library(ggplot2)
# 训练最佳模型（随机森林）
set.seed(123)
learner_best <- lrn("classif.ranger", predict_type = "prob", importance = "permutation")
learner_best$train(task_preprocessed)

# 特征重要性
if (!is.null(learner_best$importance)) {
  feature_importance <- learner_best$importance()
  importance_df <- data.frame(
    Feature = names(feature_importance),
    Importance = as.numeric(feature_importance)
  )
  importance_df <- importance_df[order(-importance_df$Importance), ]
  
  cat("特征重要性排序:\n")
  print(importance_df)
  
  # 可视化特征重要性
  ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
    geom_bar(stat = "identity", fill = "darkorange", alpha = 0.7) +
    labs(title = "特征重要性 - 随机森林", x = "特征", y = "重要性") +
    coord_flip() +
    theme_minimal()
} else {
  cat("该学习器不支持特征重要性计算\n")
}
```

模型评估与混淆矩阵

```{r}
# 模型评估与混淆矩阵

# 使用最佳模型进行预测
predictions <- learner_best$predict(task_preprocessed)

# 混淆矩阵
cat("混淆矩阵:\n")
print(predictions$confusion)

```

## 14.5 Python--多分类

数据加载与探索

```{python}
# 综合案例：鸢尾花分类 - Python语言实现 (sklearn框架)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                           roc_auc_score, confusion_matrix, classification_report, 
                           roc_curve, auc)
from sklearn.inspection import permutation_importance
import warnings
warnings.filterwarnings('ignore')

# 设置图形样式
plt.style.use('default')
sns.set_palette("husl")

# 加载鸢尾花数据集
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='species')
iris_data = pd.concat([X, y], axis=1)

# 映射数字标签到类别名称
target_names = iris.target_names
iris_data['species_name'] = iris_data['species'].map(lambda x: target_names[x])

print("数据集基本信息:")
print(f"样本数: {iris_data.shape[0]}")
print(f"变量数: {iris_data.shape[1]}")
print("\n变量名称:")
print(iris_data.columns.tolist())

# 类别分布
print("\n类别分布:")
class_dist = iris_data['species_name'].value_counts()
print(class_dist)
print("\n类别比例:")
print(class_dist / class_dist.sum())

print("\n数据概览:")
print(iris_data.describe())

print("\n缺失值检查:")
print(iris_data.isnull().sum())
```

数据可视化分析

```{python}
# 数据可视化分析 - Python

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 类别分布
class_counts = iris_data['species_name'].value_counts()
axes[0,0].bar(class_counts.index, class_counts.values, color=['steelblue', 'darkorange', 'darkgreen'], alpha=0.7)
axes[0,0].set_title('类别分布')
axes[0,0].set_ylabel('数量')
axes[0,0].tick_params(axis='x', rotation=45)

# 花萼长度与宽度的关系
species_colors = {'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}
for species in iris_data['species_name'].unique():
    species_data = iris_data[iris_data['species_name'] == species]
    axes[0,1].scatter(species_data['sepal length (cm)'], species_data['sepal width (cm)'], 
                     label=species, alpha=0.7, s=60)
axes[0,1].set_title('花萼长度 vs 宽度')
axes[0,1].set_xlabel('花萼长度 (cm)')
axes[0,1].set_ylabel('花萼宽度 (cm)')
axes[0,1].legend()

# 花瓣长度与宽度的关系
for species in iris_data['species_name'].unique():
    species_data = iris_data[iris_data['species_name'] == species]
    axes[1,0].scatter(species_data['petal length (cm)'], species_data['petal width (cm)'], 
                     label=species, alpha=0.7, s=60)
axes[1,0].set_title('花瓣长度 vs 宽度')
axes[1,0].set_xlabel('花瓣长度 (cm)')
axes[1,0].set_ylabel('花瓣宽度 (cm)')
axes[1,0].legend()

# 特征分布箱线图
feature_data = iris_data.melt(id_vars=['species_name'], 
                             value_vars=['sepal length (cm)', 'sepal width (cm)', 
                                       'petal length (cm)', 'petal width (cm)'])
sns.boxplot(data=feature_data, x='variable', y='value', hue='species_name', ax=axes[1,1])
axes[1,1].set_title('特征分布比较')
axes[1,1].set_xlabel('特征')
axes[1,1].set_ylabel('值')
axes[1,1].tick_params(axis='x', rotation=45)
axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

# 相关性热图
plt.figure(figsize=(10, 8))
corr_matrix = iris_data[['sepal length (cm)', 'sepal width (cm)', 
                        'petal length (cm)', 'petal width (cm)', 'species']].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": 0.8}, fmt='.2f')
plt.title('变量相关性热图 - Python/sklearn')
plt.tight_layout()
plt.show()
```

数据预处理

```{python}
# 数据预处理 - Python

# 准备特征和目标变量
X = iris_data[['sepal length (cm)', 'sepal width (cm)', 
               'petal length (cm)', 'petal width (cm)']]
y = iris_data['species']

# 数据划分（分层抽样保持类别比例）
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"训练集大小: {X_train.shape[0]}")
print(f"测试集大小: {X_test.shape[0]}")
print(f"训练集类别分布:\n{y_train.value_counts().sort_index()}")
print(f"测试集类别分布:\n{y_test.value_counts().sort_index()}")

# 数据标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("数据预处理完成")
```

模型训练与比较

```{python}
# 模型训练与比较 - sklearn

# 定义模型字典
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'K-Neighbors': KNeighborsClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}

# 训练和评估模型
results = []

for name, model in models.items():
    # 训练模型
    model.fit(X_train_scaled, y_train)
    
    # 预测
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)
    
    # 计算评估指标
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    # 多类AUC（One-vs-Rest）
    try:
        auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
    except:
        auc_score = np.nan
    
    # 交叉验证
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')
    cv_accuracy_mean = cv_scores.mean()
    
    results.append({
        'Model': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1_Score': f1,
        'AUC': auc_score,
        'CV_Accuracy': cv_accuracy_mean
    })

# 创建结果DataFrame
results_python = pd.DataFrame(results)
print("模型性能比较 - Python/sklearn:")
print(results_python.sort_values('Accuracy', ascending=False))

# 可视化模型比较
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 准确率比较
models_sorted_acc = results_python.sort_values('Accuracy')
axes[0,0].barh(models_sorted_acc['Model'], models_sorted_acc['Accuracy'], color='steelblue')
axes[0,0].set_xlabel('准确率')
axes[0,0].set_title('模型准确率比较 - Python/sklearn')
axes[0,0].set_xlim(0.8, 1.0)
axes[0,0].grid(axis='x', alpha=0.3)

# F1分数比较
models_sorted_f1 = results_python.sort_values('F1_Score')
axes[0,1].barh(models_sorted_f1['Model'], models_sorted_f1['F1_Score'], color='darkorange')
axes[0,1].set_xlabel('F1分数')
axes[0,1].set_title('模型F1分数比较 - Python/sklearn')
axes[0,1].set_xlim(0.8, 1.0)
axes[0,1].grid(axis='x', alpha=0.3)

# AUC比较
models_sorted_auc = results_python.sort_values('AUC')
axes[1,0].barh(models_sorted_auc['Model'], models_sorted_auc['AUC'], color='darkgreen')
axes[1,0].set_xlabel('AUC')
axes[1,0].set_title('模型AUC比较 - Python/sklearn')
axes[1,0].set_xlim(0.8, 1.0)
axes[1,0].grid(axis='x', alpha=0.3)

# 交叉验证准确率比较
models_sorted_cv = results_python.sort_values('CV_Accuracy')
axes[1,1].barh(models_sorted_cv['Model'], models_sorted_cv['CV_Accuracy'], color='darkred')
axes[1,1].set_xlabel('交叉验证准确率')
axes[1,1].set_title('交叉验证准确率比较 - Python/sklearn')
axes[1,1].set_xlim(0.8, 1.0)
axes[1,1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
```

详细模型评估

```{python}
# 详细模型评估 - 最佳模型

# 选择最佳模型（基于准确率）
best_model_name = results_python.loc[results_python['Accuracy'].idxmax(), 'Model']
best_model = models[best_model_name]

print(f"最佳模型: {best_model_name}")

# 重新训练最佳模型
best_model.fit(X_train_scaled, y_train)

# 预测
y_pred_best = best_model.predict(X_test_scaled)
y_pred_proba_best = best_model.predict_proba(X_test_scaled)

# 混淆矩阵
cm = confusion_matrix(y_test, y_pred_best)
print("\n混淆矩阵:")
print(cm)

# 分类报告
print("\n分类报告:")
print(classification_report(y_test, y_pred_best, target_names=target_names))

# 可视化混淆矩阵
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=target_names, yticklabels=target_names)
plt.title(f'混淆矩阵 - {best_model_name}')
plt.xlabel('预测标签')
plt.ylabel('真实标签')
plt.tight_layout()
plt.show()
```

特征重要性分析

```{python}
# 特征重要性分析 - Python

if hasattr(best_model, 'feature_importances_'):
    feature_importance = best_model.feature_importances_
    feature_names = X.columns
    
    # 创建特征重要性DataFrame
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': feature_importance
    }).sort_values('Importance', ascending=False)
    
    print("特征重要性排序 - Python/sklearn:")
    print(importance_df)
    
    # 可视化特征重要性
    plt.figure(figsize=(10, 6))
    sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')
    plt.title(f'特征重要性 - {best_model_name} (Python/sklearn)')
    plt.xlabel('重要性')
    plt.tight_layout()
    plt.show()

else:
    print(f"{best_model_name} 不支持特征重要性计算")
    
    # 使用排列重要性作为替代
    perm_importance = permutation_importance(
        best_model, X_test_scaled, y_test, n_repeats=10, random_state=42
    )
    
    perm_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': perm_importance.importances_mean
    }).sort_values('Importance', ascending=False)
    
    print("\n排列特征重要性:")
    print(perm_importance_df)
    
    # 可视化排列重要性
    plt.figure(figsize=(10, 6))
    sns.barplot(data=perm_importance_df, x='Importance', y='Feature', palette='rocket')
    plt.title(f'排列特征重要性 - {best_model_name} (Python/sklearn)')
    plt.xlabel('重要性')
    plt.tight_layout()
    plt.show()
```

## 14.6 多分类案例总结

关键发现

```{r}
# 案例总结 - R语言
cat("=== 鸢尾花分类案例总结 ===\n")
cat("1. 数据特征:\n")
cat("   - 数据集包含", nrow(iris_data), "个样本，", ncol(iris_data)-1, "个特征\n")
cat("   - 目标变量: 鸢尾花种类(3个类别)\n")
cat("   - 类别分布均衡\n")
cat("   - 最重要的特征: 花瓣长度和宽度\n\n")

cat("2. 模型性能比较:\n")
print(results_r[order(-Accuracy)])

cat("\n3. 分类问题最佳实践:\n")
cat("   - 树模型和SVM在分类问题上表现优异\n")
cat("   - 特征标准化对距离-based模型很重要\n")
cat("   - 多分类问题需要考虑合适的评估指标\n")
cat("   - 特征重要性分析有助于理解模型决策\n")
```

```{python}
# 案例总结 - Python
print("=== 鸢尾花分类案例总结 ===")
print("1. 数据特征:")
print(f"   - 数据集包含 {iris_data.shape[0]} 个样本，{iris_data.shape[1]-1} 个特征")
print("   - 目标变量: 鸢尾花种类(3个类别)")
print("   - 类别分布均衡")
print("   - 最重要的特征: 花瓣长度和宽度\n")

print("2. 模型性能比较:")
print(results_python[['Model', 'Accuracy', 'F1_Score', 'AUC']].sort_values('Accuracy', ascending=False).to_string(index=False))

print("\n3. 分类问题最佳实践:")
print("   - 集成学习方法在分类问题上表现稳定")
print("   - 数据预处理对模型性能影响显著")
print("   - 交叉验证提供更可靠的性能估计")
print("   - 混淆矩阵和分类报告提供详细性能分析")
```

技术要点回顾

**数据预处理**： - 特征标准化：确保不同尺度的特征具有可比性 - 类别编码：将文本标签转换为数值 - 数据划分：使用分层抽样保持类别比例

**模型选择**： - 逻辑回归：可解释性强，适合线性可分数据 - 树模型：自动处理非线性关系，提供特征重要性 - SVM：在高维空间中表现优异 - KNN：基于距离的简单有效方法

**模型评估**： - 准确率：整体分类正确率 - 精确率、召回率、F1分数：更细致的性能评估 - AUC：模型区分能力的综合指标 - 混淆矩阵：详细分析各类别的分类情况

**模型优化**： - 超参数调优：提升模型性能 - 特征选择：基于重要性筛选特征 - 交叉验证：稳健的性能估计

业务应用建议

-   物种识别：扩展到其他植物或动物的分类识别

-   质量检测：应用于工业产品质量分类

-   医疗诊断：用于疾病分类和诊断辅助

-   客户细分：用于市场营销中的客户分类