---
title: "分类任务"
format: html
editor: visual
---

## 分类问题导读

分类问题是机器学习中最常见的任务之一，广泛应用于物种分类、医疗诊断、客户分类等领域。本章将通过鸢尾花分类案例，完整展示多分类问题的解决方案，涵盖数据探索、特征工程、多种分类算法比较、模型评估等关键环节。

数据集说明 本案例使用经典的鸢尾花数据集（Iris Dataset），包含三种鸢尾花的萼片和花瓣测量数据。

问题定义 **目标**：预测鸢尾花的种类（Species）\
**任务类型**：多分类问题（3个类别）\
**业务价值**：植物分类、物种识别

## 13.1 R语言实现 (mlr3框架)--分类

数据加载与探索

```{r}
# 综合案例：鸢尾花分类 - R语言实现 (mlr3框架)

# 加载必要的包
library(mlr3)
library(mlr3verse)
library(mlr3pipelines)
library(mlr3tuning)
library(data.table)
library(ggplot2)
library(corrplot)
library(gridExtra)
library(patchwork)

# 加载鸢尾花数据集
data("iris", package = "datasets")
iris_data <- as.data.table(iris)

# 数据基本信息
cat("数据集基本信息:\n")
cat("样本数:", nrow(iris_data), "\n")
cat("变量数:", ncol(iris_data), "\n")
cat("\n变量名称:\n")
print(names(iris_data))

# 类别分布
cat("\n类别分布:\n")
class_dist <- table(iris_data$Species)
print(class_dist)
cat("类别比例:\n")
print(prop.table(class_dist))

# 数据概览
cat("\n数据概览:\n")
print(summary(iris_data))

# 检查缺失值
cat("\n缺失值检查:\n")
print(colSums(is.na(iris_data)))
```

数据可视化分析

```{r}
# 数据可视化分析 - R语言

# 类别分布
p1 <- ggplot(iris_data, aes(x = Species, fill = Species)) +
  geom_bar(alpha = 0.7) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "类别分布", x = "鸢尾花种类", y = "数量") +
  theme_minimal() +
  theme(legend.position = "none")

# 花萼长度与宽度的关系
p2 <- ggplot(iris_data, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "花萼长度 vs 宽度", x = "花萼长度", y = "花萼宽度") +
  theme_minimal()

# 花瓣长度与宽度的关系
p3 <- ggplot(iris_data, aes(x = Petal.Length, y = Petal.Width, color = Species)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "花瓣长度 vs 宽度", x = "花瓣长度", y = "花瓣宽度") +
  theme_minimal()

# 特征分布箱线图
p4 <- ggplot(iris_data, aes(x = Species, y = Petal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "花瓣长度分布", x = "鸢尾花种类", y = "花瓣长度") +
  theme_minimal() +
  theme(legend.position = "none")

# 组合图形
(p1 + p2) / (p3 + p4)
```

创建mlr3任务和数据预处理

```{r}
# 创建mlr3任务和数据预处理

# 创建分类任务
task_iris <- as_task_classif(iris_data, target = "Species", id = "iris")

# 查看任务信息
cat("任务信息:\n")
print(task_iris)

# 数据预处理管道
preprocess_pipeline <- po("scale") %>>% 
  po("encode") %>>%
  po("colapply", applicator = as.numeric)

# 应用预处理
task_preprocessed <- preprocess_pipeline$train(task_iris)[[1]]

cat("\n预处理后的任务信息:\n")
print(task_preprocessed)
```

模型训练与比较

```{r}
# 模型训练与比较 - mlr3

# 定义学习器
learners <- list(
  lrn("classif.ranger", id = "random_forest", predict_type = "prob"),
  lrn("classif.xgboost", id = "xgboost", predict_type = "prob"),
  lrn("classif.svm", id = "svm", predict_type = "prob"),
  lrn("classif.kknn", id = "knn", predict_type = "prob")
)

# 设置交叉验证和评估指标
resampling <- rsmp("cv", folds = 5)
measures <- msrs(c("classif.acc", "classif.auc", "classif.bacc", "classif.ce"))

# 基准测试
design <- benchmark_grid(
  tasks = task_preprocessed,
  learners = learners,
  resamplings = resampling
)

bmr <- benchmark(design)

# 性能评估
cat("模型性能比较:\n")
bmr_aggregated <- bmr$aggregate(measures)

# 格式化输出结果
results_r <- bmr_aggregated[, .(
  Model = learner_id,
  Accuracy = classif.acc,
  AUC = classif.auc,
  Balanced_Accuracy = classif.bacc,
  LogLoss = classif.ce
)]

print(results_r[order(-Accuracy)])

# 性能可视化
ggplot(results_r, aes(x = reorder(Model, Accuracy), y = Accuracy)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  labs(title = "模型性能比较 (准确率) - R/mlr3", x = "模型", y = "准确率") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(0, 1)
```

超参数调优

```{r}
# 超参数调优示例 - 随机森林

# 定义随机森林学习器
learner_rf_tune <- lrn("classif.ranger", predict_type = "prob", num.trees = 100)

# 定义超参数空间
param_set <- ps(
  mtry = p_int(lower = 1, upper = ncol(iris_data) - 1),
  min.node.size = p_int(lower = 1, upper = 10),
  sample.fraction = p_dbl(lower = 0.6, upper = 0.9)
)

# 定义调优器
tuner <- tnr("grid_search", resolution = 5)
terminator <- trm("evals", n_evals = 10)

# 自动调优
at <- auto_tuner(
  tuner = tuner,
  learner = learner_rf_tune,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  search_space = param_set,
  terminator = terminator
)

# 在数据上演示调优
set.seed(123)
at$train(task_preprocessed)

cat("最佳参数:\n")
print(at$tuning_result)

# 使用调优后的模型进行预测
predictions_tuned <- at$predict(task_preprocessed)
cat("调优完成\n")
cat("调优后模型准确率:", predictions_tuned$score(msr("classif.acc")), "\n")
```

模型解释

```{r}
# 模型解释 - 特征重要性

# 训练最佳模型（随机森林）
set.seed(123)
learner_best <- lrn("classif.ranger", predict_type = "prob", importance = "permutation")
learner_best$train(task_preprocessed)

# 特征重要性
if (!is.null(learner_best$importance)) {
  feature_importance <- learner_best$importance()
  importance_df <- data.frame(
    Feature = names(feature_importance),
    Importance = as.numeric(feature_importance)
  )
  importance_df <- importance_df[order(-importance_df$Importance), ]
  
  cat("特征重要性排序:\n")
  print(importance_df)
  
  # 可视化特征重要性
  ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
    geom_bar(stat = "identity", fill = "darkorange", alpha = 0.7) +
    labs(title = "特征重要性 - 随机森林", x = "特征", y = "重要性") +
    coord_flip() +
    theme_minimal()
} else {
  cat("该学习器不支持特征重要性计算\n")
}
```

模型评估与混淆矩阵

```{r}
# 模型评估与混淆矩阵

# 使用最佳模型进行预测
predictions <- learner_best$predict(task_preprocessed)

# 混淆矩阵
cat("混淆矩阵:\n")
print(predictions$confusion)

```

## 13.2 Python语言实现 (sklearn框架)--分类

数据加载与探索

```{python}
# 综合案例：鸢尾花分类 - Python语言实现 (sklearn框架)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                           roc_auc_score, confusion_matrix, classification_report, 
                           roc_curve, auc)
from sklearn.inspection import permutation_importance
import warnings
warnings.filterwarnings('ignore')

# 设置图形样式
plt.style.use('default')
sns.set_palette("husl")

# 加载鸢尾花数据集
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='species')
iris_data = pd.concat([X, y], axis=1)

# 映射数字标签到类别名称
target_names = iris.target_names
iris_data['species_name'] = iris_data['species'].map(lambda x: target_names[x])

print("数据集基本信息:")
print(f"样本数: {iris_data.shape[0]}")
print(f"变量数: {iris_data.shape[1]}")
print("\n变量名称:")
print(iris_data.columns.tolist())

# 类别分布
print("\n类别分布:")
class_dist = iris_data['species_name'].value_counts()
print(class_dist)
print("\n类别比例:")
print(class_dist / class_dist.sum())

print("\n数据概览:")
print(iris_data.describe())

print("\n缺失值检查:")
print(iris_data.isnull().sum())
```

数据可视化分析

```{python}
# 数据可视化分析 - Python

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 类别分布
class_counts = iris_data['species_name'].value_counts()
axes[0,0].bar(class_counts.index, class_counts.values, color=['steelblue', 'darkorange', 'darkgreen'], alpha=0.7)
axes[0,0].set_title('类别分布')
axes[0,0].set_ylabel('数量')
axes[0,0].tick_params(axis='x', rotation=45)

# 花萼长度与宽度的关系
species_colors = {'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}
for species in iris_data['species_name'].unique():
    species_data = iris_data[iris_data['species_name'] == species]
    axes[0,1].scatter(species_data['sepal length (cm)'], species_data['sepal width (cm)'], 
                     label=species, alpha=0.7, s=60)
axes[0,1].set_title('花萼长度 vs 宽度')
axes[0,1].set_xlabel('花萼长度 (cm)')
axes[0,1].set_ylabel('花萼宽度 (cm)')
axes[0,1].legend()

# 花瓣长度与宽度的关系
for species in iris_data['species_name'].unique():
    species_data = iris_data[iris_data['species_name'] == species]
    axes[1,0].scatter(species_data['petal length (cm)'], species_data['petal width (cm)'], 
                     label=species, alpha=0.7, s=60)
axes[1,0].set_title('花瓣长度 vs 宽度')
axes[1,0].set_xlabel('花瓣长度 (cm)')
axes[1,0].set_ylabel('花瓣宽度 (cm)')
axes[1,0].legend()

# 特征分布箱线图
feature_data = iris_data.melt(id_vars=['species_name'], 
                             value_vars=['sepal length (cm)', 'sepal width (cm)', 
                                       'petal length (cm)', 'petal width (cm)'])
sns.boxplot(data=feature_data, x='variable', y='value', hue='species_name', ax=axes[1,1])
axes[1,1].set_title('特征分布比较')
axes[1,1].set_xlabel('特征')
axes[1,1].set_ylabel('值')
axes[1,1].tick_params(axis='x', rotation=45)
axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

# 相关性热图
plt.figure(figsize=(10, 8))
corr_matrix = iris_data[['sepal length (cm)', 'sepal width (cm)', 
                        'petal length (cm)', 'petal width (cm)', 'species']].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": 0.8}, fmt='.2f')
plt.title('变量相关性热图 - Python/sklearn')
plt.tight_layout()
plt.show()
```

数据预处理

```{python}
# 数据预处理 - Python

# 准备特征和目标变量
X = iris_data[['sepal length (cm)', 'sepal width (cm)', 
               'petal length (cm)', 'petal width (cm)']]
y = iris_data['species']

# 数据划分（分层抽样保持类别比例）
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"训练集大小: {X_train.shape[0]}")
print(f"测试集大小: {X_test.shape[0]}")
print(f"训练集类别分布:\n{y_train.value_counts().sort_index()}")
print(f"测试集类别分布:\n{y_test.value_counts().sort_index()}")

# 数据标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("数据预处理完成")
```

模型训练与比较

```{python}
# 模型训练与比较 - sklearn

# 定义模型字典
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'K-Neighbors': KNeighborsClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}

# 训练和评估模型
results = []

for name, model in models.items():
    # 训练模型
    model.fit(X_train_scaled, y_train)
    
    # 预测
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)
    
    # 计算评估指标
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    # 多类AUC（One-vs-Rest）
    try:
        auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
    except:
        auc_score = np.nan
    
    # 交叉验证
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')
    cv_accuracy_mean = cv_scores.mean()
    
    results.append({
        'Model': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1_Score': f1,
        'AUC': auc_score,
        'CV_Accuracy': cv_accuracy_mean
    })

# 创建结果DataFrame
results_python = pd.DataFrame(results)
print("模型性能比较 - Python/sklearn:")
print(results_python.sort_values('Accuracy', ascending=False))

# 可视化模型比较
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 准确率比较
models_sorted_acc = results_python.sort_values('Accuracy')
axes[0,0].barh(models_sorted_acc['Model'], models_sorted_acc['Accuracy'], color='steelblue')
axes[0,0].set_xlabel('准确率')
axes[0,0].set_title('模型准确率比较 - Python/sklearn')
axes[0,0].set_xlim(0.8, 1.0)
axes[0,0].grid(axis='x', alpha=0.3)

# F1分数比较
models_sorted_f1 = results_python.sort_values('F1_Score')
axes[0,1].barh(models_sorted_f1['Model'], models_sorted_f1['F1_Score'], color='darkorange')
axes[0,1].set_xlabel('F1分数')
axes[0,1].set_title('模型F1分数比较 - Python/sklearn')
axes[0,1].set_xlim(0.8, 1.0)
axes[0,1].grid(axis='x', alpha=0.3)

# AUC比较
models_sorted_auc = results_python.sort_values('AUC')
axes[1,0].barh(models_sorted_auc['Model'], models_sorted_auc['AUC'], color='darkgreen')
axes[1,0].set_xlabel('AUC')
axes[1,0].set_title('模型AUC比较 - Python/sklearn')
axes[1,0].set_xlim(0.8, 1.0)
axes[1,0].grid(axis='x', alpha=0.3)

# 交叉验证准确率比较
models_sorted_cv = results_python.sort_values('CV_Accuracy')
axes[1,1].barh(models_sorted_cv['Model'], models_sorted_cv['CV_Accuracy'], color='darkred')
axes[1,1].set_xlabel('交叉验证准确率')
axes[1,1].set_title('交叉验证准确率比较 - Python/sklearn')
axes[1,1].set_xlim(0.8, 1.0)
axes[1,1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
```

详细模型评估

```{python}
# 详细模型评估 - 最佳模型

# 选择最佳模型（基于准确率）
best_model_name = results_python.loc[results_python['Accuracy'].idxmax(), 'Model']
best_model = models[best_model_name]

print(f"最佳模型: {best_model_name}")

# 重新训练最佳模型
best_model.fit(X_train_scaled, y_train)

# 预测
y_pred_best = best_model.predict(X_test_scaled)
y_pred_proba_best = best_model.predict_proba(X_test_scaled)

# 混淆矩阵
cm = confusion_matrix(y_test, y_pred_best)
print("\n混淆矩阵:")
print(cm)

# 分类报告
print("\n分类报告:")
print(classification_report(y_test, y_pred_best, target_names=target_names))

# 可视化混淆矩阵
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=target_names, yticklabels=target_names)
plt.title(f'混淆矩阵 - {best_model_name}')
plt.xlabel('预测标签')
plt.ylabel('真实标签')
plt.tight_layout()
plt.show()
```

特征重要性分析

```{python}
# 特征重要性分析 - Python

if hasattr(best_model, 'feature_importances_'):
    feature_importance = best_model.feature_importances_
    feature_names = X.columns
    
    # 创建特征重要性DataFrame
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': feature_importance
    }).sort_values('Importance', ascending=False)
    
    print("特征重要性排序 - Python/sklearn:")
    print(importance_df)
    
    # 可视化特征重要性
    plt.figure(figsize=(10, 6))
    sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')
    plt.title(f'特征重要性 - {best_model_name} (Python/sklearn)')
    plt.xlabel('重要性')
    plt.tight_layout()
    plt.show()

else:
    print(f"{best_model_name} 不支持特征重要性计算")
    
    # 使用排列重要性作为替代
    perm_importance = permutation_importance(
        best_model, X_test_scaled, y_test, n_repeats=10, random_state=42
    )
    
    perm_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': perm_importance.importances_mean
    }).sort_values('Importance', ascending=False)
    
    print("\n排列特征重要性:")
    print(perm_importance_df)
    
    # 可视化排列重要性
    plt.figure(figsize=(10, 6))
    sns.barplot(data=perm_importance_df, x='Importance', y='Feature', palette='rocket')
    plt.title(f'排列特征重要性 - {best_model_name} (Python/sklearn)')
    plt.xlabel('重要性')
    plt.tight_layout()
    plt.show()
```

## 13.3 案例总结与最佳实践

关键发现

```{r}
# 案例总结 - R语言
cat("=== 鸢尾花分类案例总结 ===\n")
cat("1. 数据特征:\n")
cat("   - 数据集包含", nrow(iris_data), "个样本，", ncol(iris_data)-1, "个特征\n")
cat("   - 目标变量: 鸢尾花种类(3个类别)\n")
cat("   - 类别分布均衡\n")
cat("   - 最重要的特征: 花瓣长度和宽度\n\n")

cat("2. 模型性能比较:\n")
print(results_r[order(-Accuracy)])

cat("\n3. 分类问题最佳实践:\n")
cat("   - 树模型和SVM在分类问题上表现优异\n")
cat("   - 特征标准化对距离-based模型很重要\n")
cat("   - 多分类问题需要考虑合适的评估指标\n")
cat("   - 特征重要性分析有助于理解模型决策\n")
```

```{python}
# 案例总结 - Python
print("=== 鸢尾花分类案例总结 ===")
print("1. 数据特征:")
print(f"   - 数据集包含 {iris_data.shape[0]} 个样本，{iris_data.shape[1]-1} 个特征")
print("   - 目标变量: 鸢尾花种类(3个类别)")
print("   - 类别分布均衡")
print("   - 最重要的特征: 花瓣长度和宽度\n")

print("2. 模型性能比较:")
print(results_python[['Model', 'Accuracy', 'F1_Score', 'AUC']].sort_values('Accuracy', ascending=False).to_string(index=False))

print("\n3. 分类问题最佳实践:")
print("   - 集成学习方法在分类问题上表现稳定")
print("   - 数据预处理对模型性能影响显著")
print("   - 交叉验证提供更可靠的性能估计")
print("   - 混淆矩阵和分类报告提供详细性能分析")
```

技术要点回顾

**数据预处理**： - 特征标准化：确保不同尺度的特征具有可比性 - 类别编码：将文本标签转换为数值 - 数据划分：使用分层抽样保持类别比例

**模型选择**： - 逻辑回归：可解释性强，适合线性可分数据 - 树模型：自动处理非线性关系，提供特征重要性 - SVM：在高维空间中表现优异 - KNN：基于距离的简单有效方法

**模型评估**： - 准确率：整体分类正确率 - 精确率、召回率、F1分数：更细致的性能评估 - AUC：模型区分能力的综合指标 - 混淆矩阵：详细分析各类别的分类情况

**模型优化**： - 超参数调优：提升模型性能 - 特征选择：基于重要性筛选特征 - 交叉验证：稳健的性能估计

业务应用建议

1.  **物种识别**：扩展到其他植物或动物的分类识别
2.  **质量检测**：应用于工业产品质量分类
3.  **医疗诊断**：用于疾病分类和诊断辅助
4.  **客户细分**：用于市场营销中的客户分类

这个分类模型案例的特点：

1.  **使用共享数据集**：鸢尾花数据集在R和Python中都内置可用
2.  **完整分类流程**：从数据探索到模型解释的完整流程
3.  **多分类问题**：展示3个类别的分类解决方案
4.  **现代框架**：R使用mlr3，Python使用sklearn
5.  **丰富可视化**：包含多种数据可视化和模型评估图表
6.  **实用性强**：包含特征重要性分析、混淆矩阵等实用功能

通过本分类案例，我们展示了从数据探索到模型部署的完整分类问题解决方案，为读者在实际工作中应用机器学习方法提供了完整的参考框架。
