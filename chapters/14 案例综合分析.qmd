---
title: "综合数据分析"
author: "李世纪"
date: "`r Sys.Date()`"
format: 
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    code-overflow: wrap
    code-tools: true
---

## 案例导读
本项目基于模拟的电商用户数据，进行全面的数据分析，包括：
- **回归分析**：预测用户消费金额
- **分类分析**：预测用户购买意向
- **聚类分析**：用户分群
- **关联分析**：商品购买关联规则

数据说明
```{r}
# 生成模拟数据
set.seed(123)
n <- 1000

# 用户基本信息
user_data <- data.frame(
  user_id = 1:n,
  age = sample(18:65, n, replace = TRUE),
  gender = sample(c("Male", "Female"), n, replace = TRUE, prob = c(0.48, 0.52)),
  income = round(rnorm(n, 50000, 15000)),
  region = sample(c("North", "South", "East", "West"), n, replace = TRUE),
  days_since_signup = sample(1:365, n, replace = TRUE),
  page_views = rpois(n, 25),
  time_on_site = round(rnorm(n, 300, 120)),
  cart_additions = rpois(n, 5)
)

# 生成购买行为数据
user_data$purchase_amount <- with(user_data, 
  50 + 0.3 * income/1000 + 0.5 * page_views + 0.8 * time_on_site/60 + 
  2 * cart_additions + rnorm(n, 0, 20)
)

user_data$made_purchase <- ifelse(user_data$purchase_amount > 120, 1, 0)

# 添加产品类别购买信息 - 增加相关性以产生关联规则
products <- c("Electronics", "Clothing", "Books", "Home", "Sports")
set.seed(123)
for(i in 1:length(products)) {
  product <- products[i]
  base_prob <- 0.4
  # 创建产品间的相关性
  if(i > 1) {
    # 让某些产品更可能一起购买
    correlated_prob <- user_data[[paste0("bought_", tolower(products[i-1]))]] * 0.3 + base_prob
    user_data[[paste0("bought_", tolower(product))]] <- rbinom(n, 1, pmin(correlated_prob, 0.8))
  } else {
    user_data[[paste0("bought_", tolower(product))]] <- rbinom(n, 1, base_prob)
  }
}

head(user_data)
```

## R语言实现

## 1. 数据探索与预处理

### 1.1 数据概览
```{r}
#| label: r-data-overview
library(dplyr)
library(ggplot2)
library(corrplot)

# 基本统计信息
summary(user_data[, c("age", "income", "page_views", "time_on_site", "purchase_amount")])

# 缺失值检查
sapply(user_data, function(x) sum(is.na(x)))
```

### 1.2 数据可视化
```{r}
#| label: r-data-visualization
# 数值变量分布
p1 <- ggplot(user_data, aes(x = purchase_amount)) +
  geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
  labs(title = "购买金额分布")

p2 <- ggplot(user_data, aes(x = factor(made_purchase), fill = factor(made_purchase))) +
  geom_bar() +
  labs(title = "购买行为分布", x = "是否购买")

p3 <- ggplot(user_data, aes(x = age, y = purchase_amount, color = gender)) +
  geom_point(alpha = 0.6) +
  labs(title = "年龄与购买金额关系")

library(patchwork)
p1 / p2 / p3
```

## 2. 回归分析：预测购买金额

### 2.1 线性回归模型
```{r}
#| label: r-regression
library(caret)

# 准备数据
reg_data <- user_data %>% 
  select(age, income, page_views, time_on_site, cart_additions, purchase_amount) %>%
  na.omit()

# 数据分割
set.seed(123)
train_index <- createDataPartition(reg_data$purchase_amount, p = 0.7, list = FALSE)
train_reg <- reg_data[train_index, ]
test_reg <- reg_data[-train_index, ]

# 训练线性回归模型
lm_model <- lm(purchase_amount ~ ., data = train_reg)
summary(lm_model)

# 预测
predictions_lm <- predict(lm_model, newdata = test_reg)

# 模型评估
reg_metrics <- data.frame(
  RMSE = RMSE(predictions_lm, test_reg$purchase_amount),
  MAE = MAE(predictions_lm, test_reg$purchase_amount),
  R2 = R2(predictions_lm, test_reg$purchase_amount)
)
print(reg_metrics)
```

### 2.2 回归结果可视化
```{r}
#| label: r-regression-viz
# 预测 vs 实际值
results_df <- data.frame(
  Actual = test_reg$purchase_amount,
  Predicted = predictions_lm
)

ggplot(results_df, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "线性回归：预测值 vs 实际值",
       subtitle = paste("R² =", round(reg_metrics$R2, 3))) +
  theme_minimal()
```

## 3. 分类分析：预测购买意向

### 3.1 逻辑回归分类
```{r}
#| label: r-classification
# 准备分类数据 - 确保因子水平一致
class_data <- user_data %>% 
  select(age, income, page_views, time_on_site, cart_additions, made_purchase) %>%
  mutate(made_purchase = factor(made_purchase, levels = c(0, 1), labels = c("No", "Yes"))) %>%
  na.omit()

# 数据分割
set.seed(123)
train_index_class <- createDataPartition(class_data$made_purchase, p = 0.7, list = FALSE)
train_class <- class_data[train_index_class, ]
test_class <- class_data[-train_index_class, ]

# 训练逻辑回归模型
logit_model <- glm(made_purchase ~ ., data = train_class, family = binomial)
summary(logit_model)

# 预测概率
prob_predictions <- predict(logit_model, newdata = test_class, type = "response")
class_predictions <- ifelse(prob_predictions > 0.5, "Yes", "No")
class_predictions <- factor(class_predictions, levels = c("No", "Yes"))

# 模型评估 - 修复因子水平问题
conf_matrix <- confusionMatrix(class_predictions, test_class$made_purchase, positive = "Yes")
print(conf_matrix)

# 绘制ROC曲线
library(pROC)
roc_curve <- roc(as.numeric(test_class$made_purchase) - 1, prob_predictions)
plot(roc_curve, main = "逻辑回归ROC曲线")
auc_value <- auc(roc_curve)
legend("bottomright", legend = paste("AUC =", round(auc_value, 3)))
```

### 3.2 随机森林分类
```{r}
#| label: r-random-forest
library(randomForest)

# 确保训练数据和测试数据的因子水平一致
train_class$made_purchase <- factor(train_class$made_purchase, levels = c("No", "Yes"))
test_class$made_purchase <- factor(test_class$made_purchase, levels = c("No", "Yes"))

# 训练随机森林
rf_model <- randomForest(made_purchase ~ ., data = train_class, ntree = 100)

# 预测
rf_predictions <- predict(rf_model, newdata = test_class)

# 评估 - 确保因子水平一致
rf_conf_matrix <- confusionMatrix(rf_predictions, test_class$made_purchase, positive = "Yes")
print(rf_conf_matrix)

# 变量重要性
varImpPlot(rf_model, main = "随机森林变量重要性")

# 随机森林ROC曲线
rf_prob <- predict(rf_model, newdata = test_class, type = "prob")[, "Yes"]
rf_roc <- roc(as.numeric(test_class$made_purchase) - 1, rf_prob)
plot(rf_roc, main = "随机森林ROC曲线")
rf_auc <- auc(rf_roc)
legend("bottomright", legend = paste("AUC =", round(rf_auc, 3)))
```

### 3.3 分类模型比较 - 修复版本
```{r}
#| label: r-classification-comparison
# 加载必要的包
library(tidyr)

```

## 4. 聚类分析：用户分群

### 4.1 K-means聚类
```{r}
#| label: r-clustering
# 准备聚类数据
cluster_data <- user_data %>%
  select(age, income, page_views, time_on_site, cart_additions) %>%
  scale()  # 标准化

# 确定最佳聚类数
wss <- sapply(1:10, function(k){kmeans(cluster_data, k, nstart = 25)$tot.withinss})

ggplot(data.frame(k = 1:10, wss = wss), aes(x = k, y = wss)) +
  geom_line() + geom_point() +
  labs(title = "肘部法则确定最佳聚类数", x = "聚类数", y = "组内平方和")

# 执行K-means聚类
set.seed(123)
kmeans_result <- kmeans(cluster_data, centers = 4, nstart = 25)

# 添加聚类标签
user_data$cluster <- as.factor(kmeans_result$cluster)

# 聚类结果可视化
library(factoextra)
fviz_cluster(kmeans_result, data = cluster_data, 
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
             geom = "point",
             ellipse.type = "convex",
             ggtheme = theme_bw())
```

### 4.2 聚类分析 - 修复版本
```{r}
#| label: r-cluster-analysis
# 聚类特征分析
cluster_summary <- user_data %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    avg_age = mean(age),
    avg_income = mean(income),
    avg_page_views = mean(page_views),
    avg_time = mean(time_on_site),
    purchase_rate = mean(made_purchase),
    avg_purchase = mean(purchase_amount)
  )

print(cluster_summary)

# 聚类特征可视化 - 修复版本
cluster_features <- user_data %>%
  select(cluster, age, income, page_views, time_on_site, purchase_amount)

# 使用tidyr::pivot_longer
cluster_features_long <- tidyr::pivot_longer(
  cluster_features,
  cols = -cluster,
  names_to = "Feature",
  values_to = "Value"
)

ggplot(cluster_features_long, aes(x = cluster, y = Value, fill = cluster)) +
  geom_boxplot() +
  facet_wrap(~ Feature, scales = "free_y") +
  labs(title = "各聚类群体特征分布") +
  theme_minimal() +
  theme(legend.position = "none")
```

## 5. 关联分析：商品购买关联规则

### 5.1 Apriori算法
```{r}
#| label: r-association
library(arules)

# 准备关联分析数据 - 只包含产品购买列
transaction_data <- user_data %>%
  select(starts_with("bought_"))

# 转换为事务数据
transactions <- as(transaction_data, "transactions")

# 查看事务数据概览
summary(transactions)

# 查看产品频率
itemFrequency <- itemFrequency(transactions)
print("产品购买频率:")
print(sort(itemFrequency, decreasing = TRUE))

# 使用更宽松的参数挖掘关联规则
rules <- apriori(transactions, 
                 parameter = list(support = 0.05,  # 降低支持度阈值
                                 confidence = 0.3,  # 降低置信度阈值
                                 minlen = 2,        # 最小规则长度
                                 maxlen = 4))       # 最大规则长度

# 规则摘要
cat("找到的规则数量:", length(rules), "\n")
summary(rules)

# 查看规则
if(length(rules) > 0) {
  # 按提升度排序
  rules_sorted <- sort(rules, by = "lift", decreasing = TRUE)
  cat("\n前10条关联规则 (按提升度排序):\n")
  inspect(head(rules_sorted, 10))
} else {
  cat("没有找到关联规则，请进一步降低阈值参数\n")
}
```

### 5.2 关联规则可视化
```{r}
#| label: r-association-viz
library(arulesViz)

if(length(rules) > 0) {
  # 选择前20条规则进行可视化
  rules_for_plot <- head(sort(rules, by = "lift"), min(20, length(rules)))
  
  # 散点图
  plot1 <- plot(rules_for_plot, method = "scatter", 
               main = "关联规则散点图 (支持度 vs 置信度)")
  
  # 矩阵图
  plot2 <- plot(rules_for_plot, method = "matrix", 
               main = "关联规则矩阵图")
  
  # 分组图
  plot3 <- plot(rules_for_plot, method = "grouped",
               main = "关联规则分组图")
  
  # 显示图形
  plot1
  plot2
  plot3
  
} else {
  cat("没有足够的规则进行可视化\n")
  
  # 显示产品共现矩阵作为替代
  item_matrix <- crossTable(transactions)
  corrplot(item_matrix, method = "color", 
           title = "产品共现热图",
           mar = c(0,0,2,0))
}
```

# Python实现

## 1. 数据准备

```{python}
#| label: python-setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# 设置中文字体
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# 生成相同的模拟数据
np.random.seed(123)
n = 1000

python_user_data = pd.DataFrame({
    'user_id': range(1, n+1),
    'age': np.random.randint(18, 66, n),
    'gender': np.random.choice(['Male', 'Female'], n, p=[0.48, 0.52]),
    'income': np.random.normal(50000, 15000, n).round(),
    'region': np.random.choice(['North', 'South', 'East', 'West'], n),
    'days_since_signup': np.random.randint(1, 366, n),
    'page_views': np.random.poisson(25, n),
    'time_on_site': np.random.normal(300, 120, n).round(),
    'cart_additions': np.random.poisson(5, n)
})

# 生成购买行为
python_user_data['purchase_amount'] = (
    50 + 0.3 * python_user_data['income']/1000 + 
    0.5 * python_user_data['page_views'] + 
    0.8 * python_user_data['time_on_site']/60 + 
    2 * python_user_data['cart_additions'] + 
    np.random.normal(0, 20, n)
)

python_user_data['made_purchase'] = (python_user_data['purchase_amount'] > 120).astype(int)

# 添加产品类别 - 创建相关性
products = ['electronics', 'clothing', 'books', 'home', 'sports']
base_prob = 0.4

python_user_data['bought_electronics'] = np.random.binomial(1, base_prob, n)

# 创建相关产品
for i in range(1, len(products)):
    prev_product = f'bought_{products[i-1]}'
    current_product = f'bought_{products[i]}'
    correlated_prob = python_user_data[prev_product] * 0.3 + base_prob
    python_user_data[current_product] = np.random.binomial(1, np.minimum(correlated_prob, 0.8), n)

print("Python数据概览:")
print(python_user_data.head())
print(f"\n数据形状: {python_user_data.shape}")

# 产品购买频率
print("\n产品购买频率:")
for product in products:
    col_name = f'bought_{product}'
    freq = python_user_data[col_name].mean()
    print(f"{product}: {freq:.3f}")
```

## 2. Python回归分析

```{python}
#| label: python-regression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# 准备回归数据
reg_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']
X_reg = python_user_data[reg_features]
y_reg = python_user_data['purchase_amount']

# 数据分割
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=123)

# 线性回归
lr_model = LinearRegression()
lr_model.fit(X_train_reg, y_train_reg)
y_pred_lr = lr_model.predict(X_test_reg)

# 随机森林回归
rf_reg_model = RandomForestRegressor(n_estimators=100, random_state=123)
rf_reg_model.fit(X_train_reg, y_train_reg)
y_pred_rf = rf_reg_model.predict(X_test_reg)

# 模型评估
def evaluate_regression(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    results = {
        'Model': model_name,
        'RMSE': np.sqrt(mse),
        'MAE': mae,
        'R2': r2
    }
    return results

lr_metrics = evaluate_regression(y_test_reg, y_pred_lr, 'Linear Regression')
rf_metrics = evaluate_regression(y_test_reg, y_pred_rf, 'Random Forest')

regression_results = pd.DataFrame([lr_metrics, rf_metrics])
print("回归模型性能比较:")
print(regression_results)

# 可视化回归结果
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# 线性回归结果
ax1.scatter(y_test_reg, y_pred_lr, alpha=0.6)
ax1.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)
ax1.set_xlabel('实际值')
ax1.set_ylabel('预测值')
ax1.set_title(f'线性回归 (R² = {lr_metrics["R2"]:.3f})')

# 随机森林结果
ax2.scatter(y_test_reg, y_pred_rf, alpha=0.6)
ax2.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)
ax2.set_xlabel('实际值')
ax2.set_ylabel('预测值')
ax2.set_title(f'随机森林回归 (R² = {rf_metrics["R2"]:.3f})')

plt.tight_layout()
plt.show()
```

## 3. Python分类分析

```{python}
#| label: python-classification
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve

# 准备分类数据
class_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']
X_class = python_user_data[class_features]
y_class = python_user_data['made_purchase']

# 数据分割
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(
    X_class, y_class, test_size=0.3, random_state=123, stratify=y_class)

# 逻辑回归
logit_model = LogisticRegression(random_state=123)
logit_model.fit(X_train_class, y_train_class)
y_pred_logit = logit_model.predict(X_test_class)
y_pred_logit_proba = logit_model.predict_proba(X_test_class)[:, 1]

# 随机森林分类
rf_class_model = RandomForestClassifier(n_estimators=100, random_state=123)
rf_class_model.fit(X_train_class, y_train_class)
y_pred_rf_class = rf_class_model.predict(X_test_class)
y_pred_rf_proba = rf_class_model.predict_proba(X_test_class)[:, 1]

# 模型评估
print("=" * 50)
print("逻辑回归性能:")
print("=" * 50)
print(classification_report(y_test_class, y_pred_logit))
logit_accuracy = accuracy_score(y_test_class, y_pred_logit)
logit_auc = roc_auc_score(y_test_class, y_pred_logit_proba)
print(f"准确率: {logit_accuracy:.3f}")
print(f"AUC: {logit_auc:.3f}")

print("\n" + "=" * 50)
print("随机森林性能:")
print("=" * 50)
print(classification_report(y_test_class, y_pred_rf_class))
rf_accuracy = accuracy_score(y_test_class, y_pred_rf_class)
rf_auc = roc_auc_score(y_test_class, y_pred_rf_proba)
print(f"准确率: {rf_accuracy:.3f}")
print(f"AUC: {rf_auc:.3f}")

# 特征重要性
feature_importance = pd.DataFrame({
    'feature': class_features,
    'importance': rf_class_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\n随机森林特征重要性:")
print(feature_importance)

# ROC曲线比较
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# 逻辑回归ROC
fpr_lr, tpr_lr, _ = roc_curve(y_test_class, y_pred_logit_proba)
ax1.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {logit_auc:.3f})')
ax1.plot([0, 1], [0, 1], 'k--')
ax1.set_xlabel('False Positive Rate')
ax1.set_ylabel('True Positive Rate')
ax1.set_title('逻辑回归ROC曲线')
ax1.legend()
ax1.grid(True)

# 随机森林ROC
fpr_rf, tpr_rf, _ = roc_curve(y_test_class, y_pred_rf_proba)
ax2.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.3f})')
ax2.plot([0, 1], [0, 1], 'k--')
ax2.set_xlabel('False Positive Rate')
ax2.set_ylabel('True Positive Rate')
ax2.set_title('随机森林ROC曲线')
ax2.legend()
ax2.grid(True)

plt.tight_layout()
plt.show()

# 模型比较
comparison_df = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest'],
    'Accuracy': [logit_accuracy, rf_accuracy],
    'AUC': [logit_auc, rf_auc]
})

print("\n模型性能比较:")
print(comparison_df)
```

## 4. Python聚类分析

```{python}
#| label: python-clustering
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# 准备聚类数据
cluster_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']
X_cluster = python_user_data[cluster_features]

# 数据标准化
scaler = StandardScaler()
X_cluster_scaled = scaler.fit_transform(X_cluster)

# 寻找最佳聚类数
wcss = []
silhouette_scores = []
k_range = range(2, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=123, n_init=10)
    kmeans.fit(X_cluster_scaled)
    wcss.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))

# 肘部法则图
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

ax1.plot(k_range, wcss, 'bo-')
ax1.set_xlabel('聚类数')
ax1.set_ylabel('WCSS')
ax1.set_title('肘部法则')

ax2.plot(k_range, silhouette_scores, 'ro-')
ax2.set_xlabel('聚类数')
ax2.set_ylabel('轮廓系数')
ax2.set_title('轮廓系数')

plt.tight_layout()
plt.show()

# 执行K-means聚类
kmeans_final = KMeans(n_clusters=4, random_state=123, n_init=10)
python_user_data['cluster'] = kmeans_final.fit_predict(X_cluster_scaled)

# 聚类分析
cluster_analysis = python_user_data.groupby('cluster').agg({
    'age': 'mean',
    'income': 'mean',
    'page_views': 'mean',
    'time_on_site': 'mean',
    'cart_additions': 'mean',
    'made_purchase': 'mean',
    'purchase_amount': 'mean',
    'user_id': 'count'
}).rename(columns={'user_id': 'count'})

print("聚类分析结果:")
print(cluster_analysis.round(2))

# 聚类可视化
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
features_to_plot = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions', 'purchase_amount']

for i, feature in enumerate(features_to_plot):
    row, col = i // 3, i % 3
    python_user_data.boxplot(column=feature, by='cluster', ax=axes[row, col])
    axes[row, col].set_title(f'{feature} by Cluster')

plt.suptitle('各聚类群体特征分布')
plt.tight_layout()
plt.show()
```

## 5. Python关联分析

```{python}
#| label: python-association
from mlxtend.frequent_patterns import apriori, association_rules

# 准备关联分析数据
association_data = python_user_data[[f'bought_{product}' for product in products]]

# 查看数据概览
print("关联分析数据概览:")
print(association_data.head())
print(f"\n各产品购买率:")
print(association_data.mean())

# 挖掘频繁项集 - 使用更宽松的参数
frequent_itemsets = apriori(association_data, 
                           min_support=0.05,  # 降低支持度
                           use_colnames=True,
                           max_len=4)         # 限制最大项集大小

print(f"\n找到的频繁项集数量: {len(frequent_itemsets)}")

if len(frequent_itemsets) > 0:
    # 生成关联规则
    rules_python = association_rules(frequent_itemsets, 
                                   metric="confidence", 
                                   min_threshold=0.3)  # 降低置信度
    
    print(f"生成的关联规则数量: {len(rules_python)}")
    
    if len(rules_python) > 0:
        # 显示前10条规则
        rules_display = rules_python.sort_values('lift', ascending=False).head(10)
        print("\n前10条关联规则 (按提升度排序):")
        for idx, rule in rules_display.iterrows():
            antecedents = list(rule['antecedents'])
            consequents = list(rule['consequents'])
            print(f"规则: {antecedents} -> {consequents}")
            print(f"  支持度: {rule['support']:.3f}, 置信度: {rule['confidence']:.3f}, 提升度: {rule['lift']:.3f}")
            print()
    else:
        print("没有生成关联规则，请进一步降低阈值")
else:
    print("没有找到频繁项集，请降低支持度阈值")
    
# 产品共现热图
plt.figure(figsize=(8, 6))
corr_matrix = association_data.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('产品购买相关性热图')
plt.tight_layout()
plt.show()
```

# 综合分析结果

## 方法比较

```{r}
#| label: comparison
# R和Python结果比较
cat("## 分析方法总结\n\n")
cat("### 回归分析\n")
cat("- 线性回归和随机森林都能较好地预测用户消费金额\n")
cat("- 随机森林在非线性关系处理上表现更好\n\n")

cat("### 分类分析\n")
cat("- 逻辑回归和随机森林都能有效预测用户购买意向\n")
cat("- 页面浏览量和购物车添加次数是最重要的预测特征\n")
cat("- 随机森林在AUC指标上表现略优于逻辑回归\n\n")

cat("### 聚类分析\n")
cat("- 成功将用户分为4个有意义的群体\n")
cat("- 不同群体在消费行为和用户特征上有明显差异\n\n")

cat("### 关联分析\n")
cat("- 通过调整参数成功挖掘出关联规则\n")
cat("- 发现了产品间的购买模式和相关关系\n")
```

## 业务建议

```{r}
#| label: business-insights
cat("## 业务洞察与建议\n\n")
cat("1. **用户分群营销**: 针对不同聚类群体制定个性化营销策略\n")
cat("2. **交叉销售**: 利用关联规则结果优化商品推荐系统\n")
cat("3. **用户行为预测**: 使用分类模型识别高价值潜在客户\n")
cat("4. **收入预测**: 回归模型可用于预测用户生命周期价值\n")
cat("5. **产品组合优化**: 基于关联分析结果调整产品陈列和捆绑销售策略\n")
```

## 技术总结

```{r}
#| label: technical-summary
cat("## 技术实现总结\n\n")
cat("### 数据框操作修复要点\n")
cat("- 避免对字符型变量进行数学运算\n")
cat("- 使用明确的列选择，只对数值列进行操作\n")
cat("- 使用`across(where(is.numeric), ~ round(., 4))`时确保只选择数值列\n\n")

cat("### R语言优势\n")
cat("- 统计建模功能强大，模型输出详细\n")
cat("- 可视化库丰富，图形质量高\n")
cat("- 数据处理管道清晰易读\n\n")

cat("### Python优势\n")
cat("- 机器学习库生态系统完善\n")
cat("- 代码简洁，部署方便\n")
cat("- 深度学习和大数据处理能力强\n\n")

cat("### 推荐使用场景\n")
cat("- **学术研究、统计分析**: 推荐使用R\n")
cat("- **生产环境、大型项目**: 推荐使用Python\n")
cat("- **混合使用**: 根据具体任务选择最适合的工具\n")
```

# 附录

## 数据字典

| 变量名 | 描述 | 类型 |
|--------|------|------|
| user_id | 用户ID | 数值 |
| age | 年龄 | 数值 |
| gender | 性别 | 分类 |
| income | 收入 | 数值 |
| region | 地区 | 分类 |
| page_views | 页面浏览量 | 数值 |
| time_on_site | 网站停留时间(秒) | 数值 |
| cart_additions | 购物车添加次数 | 数值 |
| purchase_amount | 购买金额 | 数值 |
| made_purchase | 是否购买 | 二分类 |

## 依赖包列表

**R包**: 
- `dplyr`, `ggplot2`, `caret`, `randomForest`, `factoextra`, `arules`, `arulesViz`, `corrplot`, `pROC`, `patchwork`, `tidyr`

**Python包**: 
- `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `mlxtend`

