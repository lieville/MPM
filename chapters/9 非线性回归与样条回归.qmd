---
title: "9 非线性回归与样条回归"
format: html
editor: visual
---

## 本章导读

在实际科学研究与数据分析中，变量间的关系往往并非简单的直线形式。经济增长的S型轨迹、药物反应的剂量-效应曲线、温度对化学反应的加速效应——这些现象都揭示了一个基本事实：现实世界的关系本质上是非线性的。线性回归模型虽然简洁优雅，但当它面对这些复杂的曲线关系时，便会显得力不从心。

本章将带领读者从线性回归的舒适区走向非线性模型的广阔天地。我们将首先认识到线性模型的局限性，然后系统学习四种主流的非线性建模方法：可线性化的变换模型、灵活的多项式回归、高维的多元非线性模型，以及平滑灵活的样条回归。每种方法都有其独特的数学原理、适用场景和解释方式。

特别值得关注的是，非线性模型的参数估计不再有闭合解，我们需要借助数值优化方法。本章将深入浅出地介绍非线性最小二乘法和梯度下降法的原理与实现逻辑，帮助读者理解计算机是如何"学习"这些复杂模型参数的。

通过本章的学习，读者将掌握从识别非线性模式、选择合适模型、估计模型参数到解释模型结果的全流程能力。非线性回归不仅是统计方法的扩展，更是认识复杂世界的有力工具。让我们开始这段探索曲线关系的旅程。

## 9.1 非线性的定义

线性回归模型假设因变量与自变量之间的关系是线性的： $$
Y = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p + \varepsilon
$$

然而在实际应用中，许多关系本质上是非线性的： - 经济增长的S型曲线 - 药物浓度与反应的饱和曲线 - 温度与化学反应速率的指数关系

定义：非线性回归模型是指参数相对于自变量是非线性的模型： $$
Y = f(\mathbf{X}, \pmb{\beta}) + \varepsilon
$$ 其中 $f$ 是关于参数 $\pmb{\beta}$ 的非线性函数。

非线性模型的分类

| 类型           | 特点                   | 示例                          |
|----------------|------------------------|-------------------------------|
| 可线性化模型   | 通过变换可转为线性模型 | $Y = \beta_0 e^{\beta_1 X}$   |
| 本质非线性模型 | 无法通过变换线性化     | $Y = \beta_0 + e^{\beta_1 X}$ |
| 分段回归模型   | 不同区间用不同模型     | 样条回归、阈值模型            |

## 9.2 可线性化的非线性模型

指数模型

模型形式： $$
Y = \beta_0 e^{\beta_1 X} \varepsilon
$$ 其中 $\varepsilon$ 为乘法误差项，通常假设 $\ln \varepsilon \sim N(0, \sigma^2)$。

线性化方法：取自然对数 $$
\ln Y = \ln \beta_0 + \beta_1 X + \ln \varepsilon
$$ 令 $Y' = \ln Y$，$\beta_0' = \ln \beta_0$，$\varepsilon' = \ln \varepsilon$，得： $$
Y' = \beta_0' + \beta_1 X + \varepsilon'
$$

幂函数模型

模型形式： $$
Y = \beta_0 X^{\beta_1} \varepsilon
$$

线性化方法：两边取对数 $$
\ln Y = \ln \beta_0 + \beta_1 \ln X + \ln \varepsilon
$$ 令 $Y' = \ln Y$，$X' = \ln X$，$\beta_0' = \ln \beta_0$，得： $$
Y' = \beta_0' + \beta_1 X' + \varepsilon'
$$

对数模型

模型形式： $$
Y = \beta_0 + \beta_1 \ln X + \varepsilon
$$

该模型直接是线性的形式，只需对自变量进行对数变换。

双曲线模型

模型形式： $$
\frac{1}{Y} = \beta_0 + \beta_1 \frac{1}{X} + \varepsilon
$$

令 $Y' = 1/Y$，$X' = 1/X$，得线性形式： $$
Y' = \beta_0 + \beta_1 X' + \varepsilon
$$

可线性化方法的局限

1.  误差结构的改变：变换可能改变误差项的分布假设
2.  可解释性：变换后参数的解释与原始模型不同
3.  预测的逆变换偏倚：对变换后的预测值进行逆变换可能产生系统偏倚

## 9.3 多项式回归

### 9.3.1 一元多项式回归

模型形式： $$
Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \cdots + \beta_p X^p + \varepsilon
$$

矩阵形式： $$
\mathbf{Y} = \mathbf{X}\pmb{\beta} + \pmb{\varepsilon}
$$ 其中设计矩阵 $\mathbf{X} = [\mathbf{1}, \mathbf{X}, \mathbf{X}^2, \cdots, \mathbf{X}^p]$。

正交多项式：为减少多重共线性，可使用正交多项式： $$
Y = \alpha_0 + \alpha_1 \phi_1(X) + \alpha_2 \phi_2(X) + \cdots + \alpha_p \phi_p(X) + \varepsilon
$$ 其中 $\phi_j(X)$ 是 $j$ 次正交多项式。

阶数选择

1.  逐步回归法：向前选择、向后删除
2.  信息准则：AIC、BIC $$
    \text{AIC} = n\ln(\text{RSS}/n) + 2(p+1)
    $$ $$
    \text{BIC} = n\ln(\text{RSS}/n) + (p+1)\ln n
    $$
3.  交叉验证：k折交叉验证的均方误差最小化

### 9.3.2 多元多项式回归

二次模型（含交互项）： $$
Y = \beta_0 + \sum_{i=1}^k \beta_i X_i + \sum_{i=1}^k \sum_{j \geq i}^k \beta_{ij} X_i X_j + \varepsilon
$$

完整二次模型： $$
Y = \beta_0 + \sum_{i=1}^k \beta_i X_i + \sum_{i=1}^k \beta_{ii} X_i^2 + \sum_{i=1}^{k-1} \sum_{j=i+1}^k \beta_{ij} X_i X_j + \varepsilon
$$

多项式回归的注意事项

过拟合风险：高阶多项式可能过度拟合噪声 外推不可靠：多项式在外推时可能产生不合理预测 多重共线性：高次项之间高度相关

## 9.4 样条回归

### 9.4.1 分段多项式回归

将定义域划分为 $K+1$ 个区间，每个区间使用不同的多项式： $$
f(X) = 
\begin{cases}
\beta_{00} + \beta_{10}X + \cdots + \beta_{p0}X^p & \text{if } X \leq \xi_1 \\
\beta_{01} + \beta_{11}X + \cdots + \beta_{p1}X^p & \text{if } \xi_1 < X \leq \xi_2 \\
\vdots & \vdots \\
\beta_{0K} + \beta_{1K}X + \cdots + \beta_{pK}X^p & \text{if } X > \xi_K
\end{cases}
$$ 其中 $\xi_1, \xi_2, \ldots, \xi_K$ 为节点。

### 9.4.2 回归样条

为保证分段多项式在节点处光滑，添加连续性约束。$m$ 次样条要求在节点处函数值及前 $m-1$ 阶导数连续。

三次样条（最常用）：在每个区间内为三次多项式，在节点处函数值、一阶导数、二阶导数连续。

基函数表示：三次样条可表示为： $$
f(X) = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \sum_{k=1}^K \theta_k (X - \xi_k)_+^3
$$ 其中 $(X - \xi_k)_+^3 = \max(0, X - \xi_k)^3$。

### 9.4.3 自然样条

在边界节点外添加线性约束，使函数在边界区域更稳定： $$
f''(X) = 0 \quad \text{当 } X \leq \xi_1 \text{ 或 } X \geq \xi_K
$$

### 9.4.4 光滑样条

通过惩罚复杂度来寻找最优拟合函数： $$
\min_f \left\{ \sum_{i=1}^n [Y_i - f(X_i)]^2 + \lambda \int [f''(t)]^2 dt \right\}
$$ 其中 $\lambda$ 为光滑参数，控制拟合优度与光滑度的权衡。

## 9.5 非线性回归的估计方法

### 9.5.1 非线性最小二乘法

目标函数： $$
\min_{\pmb{\beta}} S(\pmb{\beta}) = \sum_{i=1}^n [Y_i - f(\mathbf{X}_i, \pmb{\beta})]^2
$$

高斯-牛顿法：迭代求解，在每次迭代处对 $f$ 进行一阶泰勒展开： $$
f(\mathbf{X}_i, \pmb{\beta}) \approx f(\mathbf{X}_i, \pmb{\beta}^{(t)}) + \mathbf{J}_i(\pmb{\beta}^{(t)})(\pmb{\beta} - \pmb{\beta}^{(t)})
$$ 其中 $\mathbf{J}_i(\pmb{\beta}) = \frac{\partial f(\mathbf{X}_i, \pmb{\beta})}{\partial \pmb{\beta}}$ 为雅可比矩阵。

迭代更新公式： $$
\pmb{\beta}^{(t+1)} = \pmb{\beta}^{(t)} + (\mathbf{J}^\top \mathbf{J})^{-1} \mathbf{J}^\top (\mathbf{Y} - \mathbf{f}(\pmb{\beta}^{(t)}))
$$

### 9.5.2 梯度下降法

基本思想：沿目标函数梯度反方向迭代更新参数。

更新公式： $$
\pmb{\beta}^{(t+1)} = \pmb{\beta}^{(t)} - \eta \nabla S(\pmb{\beta}^{(t)})
$$ 其中 $\eta$ 为学习率，$\nabla S(\pmb{\beta})$ 为梯度向量。

梯度计算： $$
\frac{\partial S}{\partial \beta_j} = -2 \sum_{i=1}^n [Y_i - f(\mathbf{X}_i, \pmb{\beta})] \frac{\partial f(\mathbf{X}_i, \pmb{\beta})}{\partial \beta_j}
$$

变体： 批量梯度下降：使用全部样本计算梯度 随机梯度下降：每次随机使用一个样本 小批量梯度下降：每次使用一小批样本

### 9.5.3 牛顿法与拟牛顿法

牛顿法： $$
\pmb{\beta}^{(t+1)} = \pmb{\beta}^{(t)} - \mathbf{H}^{-1}(\pmb{\beta}^{(t)}) \nabla S(\pmb{\beta}^{(t)})
$$ 其中 $\mathbf{H}$ 为海森矩阵（二阶导数矩阵）。

拟牛顿法（BFGS）：用近似矩阵代替海森矩阵，减少计算量。

### 9.5.4 参数初始值与收敛准则

初始值选择： 1. 基于物理意义或先验知识 2. 网格搜索法 3. 线性化模型的估计值

收敛准则： 1. 参数变化量：$\|\pmb{\beta}^{(t+1)} - \pmb{\beta}^{(t)}\| < \epsilon$ 2. 目标函数变化量：$|S(\pmb{\beta}^{(t+1)}) - S(\pmb{\beta}^{(t)})| < \epsilon$ 3. 梯度范数：$\|\nabla S(\pmb{\beta}^{(t)})\| < \epsilon$

## 9.6 模型比较与诊断

### 9.6.1 拟合优度度量

残差平方和： $$
\text{RSS} = \sum_{i=1}^n [Y_i - \hat{f}(\mathbf{X}_i)]^2
$$

调整后R²： $$
R^2_{\text{adj}} = 1 - \frac{\text{RSS}/(n-p)}{\text{TSS}/(n-1)}
$$

信息准则： $$
\text{AIC} = n\ln(\text{RSS}/n) + 2p
$$ $$
\text{BIC} = n\ln(\text{RSS}/n) + p\ln n
$$

### 9.6.2 残差分析

标准化残差： $$
r_i = \frac{Y_i - \hat{f}(\mathbf{X}_i)}{\hat{\sigma}}
$$

诊断图形：

-   残差与拟合值图：检查方差齐性

-   残差与自变量图：检查模型设定

-   正态Q-Q图：检查正态性假设

## 9.7 变量变换方法

### 9.7.1 Box-Cox变换

Box-Cox变换通过对响应变量进行幂变换，使其更接近正态分布并稳定方差。

变换族定义： $$
y^{(\lambda)} = \begin{cases}
\dfrac{y^\lambda - 1}{\lambda} & \lambda \neq 0 \\
\ln y & \lambda = 0
\end{cases}
$$

参数选择： 通过最大化轮廓似然函数选择 $\lambda$： $$
L_{\text{max}}(\lambda) = -\frac{n}{2} \ln(RSS(\lambda)/n) + (\lambda-1)\sum_{i=1}^n \ln y_i
$$

### 9.7.2 其他常用变换

对数变换： 适用于右偏分布和方差随均值增大的情况： $$
y^* = \ln(y)
$$

平方根变换： 适用于泊松分布的计数数据： $$
y^* = \sqrt{y}
$$

逻辑变换： 适用于比例数据： $$
y^* = \ln\left(\frac{y}{1-y}\right)
$$

## 9.8 案例分析

## 本章总结

非线性回归分析为我们打开了认识复杂世界关系的新窗口。通过本章的学习，我们掌握了从简单变换模型到复杂样条回归的完整方法体系，理解了如何根据数据特征和问题背景选择适当的非线性模型。

首先，对于可以通过数学变换线性化的模型（如指数、幂函数、对数模型），我们获得了简洁的解决方案。这类方法虽然实用，但需要警惕变换对误差结构和参数解释的影响。

多项式回归以其数学简洁性和高度灵活性成为非线性建模的基础工具。通过控制多项式阶数和使用正交多项式，我们可以在拟合能力与模型简洁性之间取得平衡。多元多项式回归进一步扩展了这一思想，能够捕捉变量间的交互效应和曲面关系。

样条回归代表了非线性建模的艺术高度。通过分段多项式和光滑性约束，样条模型既能捕捉局部特征，又能保证整体光滑，特别适用于没有明确函数形式但需要灵活拟合的情形。自然样条和光滑样条更是提供了边界稳定性和自动光滑参数选择的优雅解决方案。

在估计方法层面，我们认识到非线性模型参数估计的本质是数值优化问题。非线性最小二乘法、梯度下降法及其变体构成了求解这类问题的工具箱。每种方法都有其适用场景：高斯-牛顿法在接近最优解时收敛迅速，梯度下降法对初始值不敏感但可能收敛较慢，而拟牛顿法则在计算效率与收敛性之间取得了良好平衡。

最后，模型比较与诊断提醒我们，无论模型多么复杂，都需要严格的统计验证。残差分析、交叉验证、信息准则等工具帮助我们避免过拟合，确保模型的稳健性和泛化能力。

非线性回归不仅是一套统计方法，更是一种建模哲学：它教导我们在尊重数据复杂性的同时，保持模型的简约性；在追求拟合优度的同时，警惕过度参数化的陷阱。掌握这些方法后，读者将能够更自信地面对现实世界中的曲线关系，从数据中提取更深刻的洞察。

核心公式回顾

1.  多项式回归：$y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_d x_i^d + \varepsilon_i$
2.  正交多项式条件：$\sum_{i=1}^n Q_j(x_i)Q_k(x_i) = 0$（$j \neq k$）
3.  Box-Cox变换：$y^{(\lambda)} = \frac{y^\lambda - 1}{\lambda}$（$\lambda \neq 0$）
4.  样条光滑条件：$f_j^{(m)}(\xi_j) = f_{j+1}^{(m)}(\xi_j)$（$m=0,1,2$）
5.  平滑样条目标函数：$\min_f \left\{ \sum (y_i - f(x_i))^2 + \lambda \int [f''(x)]^2 dx \right\}$

方法比较与选择指南

| 方法类型   | 适用场景       | 优势                     | 局限性                 |
|------------------|-------------------|------------------|------------------|
| 多项式回归 | 光滑的全局趋势 | 简单直观，易于解释       | 不够灵活，外推性能差   |
| 正交多项式 | 高阶多项式拟合 | 数值稳定，系数独立       | 需要专门的基函数构造   |
| 样条回归   | 局部变化复杂   | 灵活性高，适应性强       | 需要选择节点位置       |
| 平滑样条   | 自动光滑度控制 | 无需选择节点，理论性质好 | 计算量较大，解释性稍差 |

重要概念体系

1.  基函数展开：用基函数的线性组合逼近复杂函数关系
2.  正交性原理：通过正交化改善数值稳定性和统计性质
3.  分段多项式：在不同区间使用不同的多项式逼近
4.  光滑性条件：在分段连接处施加连续性约束
5.  惩罚回归：通过惩罚项控制模型复杂度
6.  偏差-方差权衡：在模型复杂度和预测精度间寻求平衡

实践指导原则

1.  从简到繁：先尝试低阶多项式，再考虑更复杂的方法
2.  模型验证：使用交叉验证评估模型泛化能力
3.  数值稳定性：高阶多项式务必使用正交多项式形式
4.  领域知识：结合实际问题背景选择合适的方法
5.  可视化诊断：通过残差图和拟合曲线评估模型 adequacy

多项式回归和样条回归为处理非线性关系提供了系统的框架，它们在线性模型的基础上通过基函数扩展来捕捉复杂的数据模式。理解这些方法的原理和适用条件，对于建立有效的预测模型具有重要意义。