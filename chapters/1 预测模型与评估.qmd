---
title: "1 预测模型与评估"
format: html
editor: source
---

```{r setup,echo=FALSE,include=FALSE,results='hide'}
# 在 R 中直接指定 Anaconda 路径
library(reticulate)
# 查看已安装的 conda 环境
conda_list()

# 查看 conda 可执行文件路径
conda_binary()

# 查看 conda 版本
conda_version()
# 指定 Python 可执行文件路径
use_python("C:/Data/Anaconda/python.exe")  

# 使用 Conda 环境
use_condaenv("base")  # 使用基础环境
```

## 本章导读

预测建模是现代数据分析的核心任务，无论是预测连续数值（回归）还是预测类别标签（分类），都需要建立系统的分析和评估框架。本章将介绍预测建模的基本概念，重点讨论过拟合现象及其危害，并建立完整的模型评估体系，，补充了工具软件R、Python的相关使用说明，为后续学习各种预测模型奠定基础。

## 1.1 预测建模的基本概念

### 1.1.1 回归与分类任务

回归分析： 回归任务旨在预测连续型数值变量。例如： - 预测房屋价格（连续金额） - 预测股票收益率（连续百分比） - 预测气温变化（连续温度值） - 预测销售额（连续数量）

数学上，回归模型试图建立从特征变量 $X$ 到连续响应变量 $Y$ 的映射： $$
Y = f(X) + \varepsilon
$$ 其中 $\varepsilon$ 是随机误差项，代表模型无法解释的部分。

分类分析： 分类任务旨在预测离散型类别变量。

例如：

-   判断邮件是否为垃圾邮件（二分类：是/否）

-   诊断患者是否患病（二分类：健康/患病）

-   识别图像中的物体类别（多分类：猫/狗/车等）

-   信用风险评估（多分类：低风险/中风险/高风险）

分类模型建立从特征变量 $X$ 到类别标签 $Y$ 的映射： $$
Y = g(X), \quad Y \in \{C_1, C_2, \ldots, C_K\}
$$

### 1.1.2 特征变量与响应变量

特征变量（自变量）： 用于预测的输入变量

-   可以是数值型、分类型或顺序型

-   表示为 $X = (X_1, X_2, \ldots, X_p)$

特征工程：从原始数据中提取有意义的特征

响应变量（因变量）：

-   需要预测的目标变量

-   回归问题中为连续数值

-   分类问题中为离散类别

-   应该与业务目标紧密相关

示例分析： 以房价预测为例：

-   特征变量：房屋面积、卧室数量、地理位置、房龄等

-   响应变量：房屋价格（连续值）

-   问题类型：回归问题

以垃圾邮件检测为例：

-   特征变量：邮件关键词频率、发件人信誉、邮件长度等

-   响应变量：邮件类型（垃圾邮件/正常邮件）

-   问题类型：二分类问题

### 1.1.3 预测建模的流程

完整工作流：

1.  问题定义：
    -   明确业务目标
    -   确定预测任务类型（回归/分类）
    -   制定成功标准
2.  数据准备：
    -   数据收集与整合
    -   数据清洗与预处理
    -   探索性数据分析
3.  特征工程：
    -   特征选择
    -   特征变换
    -   特征创建
4.  模型选择：
    -   根据问题特点选择算法家族
    -   考虑数据规模和特征类型
    -   评估模型假设的合理性
5.  模型训练：
    -   参数估计
    -   超参数调优
    -   模型验证
6.  模型评估：
    -   性能指标计算
    -   模型比较
    -   误差分析
7.  模型部署：
    -   生产环境集成
    -   性能监控
    -   模型更新

## 1.2 过拟合与模型复杂度

### 1.2.1 过拟合的概念与机制

过拟合的本质： 模型过度适应训练数据中的特定模式（包括噪声），导致在新数据上泛化能力下降。

过拟合的数学描述： 设 $f$ 为真实函数，$\hat{f}$ 为估计函数，则：

-   训练误差：$\text{Err}_{\text{train}} = E[L(Y, \hat{f}(X)) | \text{train}]$

-   测试误差：$\text{Err}_{\text{test}} = E[L(Y, \hat{f}(X)) | \text{test}]$

当 $\text{Err}_{\text{train}} \ll \text{Err}_{\text{test}}$ 时，发生过拟合。

过拟合的视觉示例： 考虑多项式回归： - 适当阶数：平滑曲线，很好拟合真实趋势 - 过高阶数：曲线剧烈波动，拟合每个数据点（包括噪声）

欠拟合： 与过拟合相对，模型过于简单，无法捕捉数据中的基本模式： - $\text{Err}_{\text{train}}$ 很大 - $\text{Err}_{\text{test}}$ 也很大 - 模型能力不足

**编程演示：过拟合现象**

```{r}

# 过拟合现象演示 - 生成数据
# 生成理想的过拟合演示数据
generate_overfitting_demo_data <- function(n = 100) {
  set.seed(123)
  x <- seq(0, 4 * pi, length.out = n)
  # 真实关系：正弦函数 + 噪声
  y_true <- sin(x) + 0.5 * sin(2*x)
  y_observed <- y_true + rnorm(n, 0, 0.2)
  return(data.frame(x = x, y_true = y_true, y_observed = y_observed))
}

# 生成数据
demo_data <- generate_overfitting_demo_data(100)

# 拟合不同复杂度的多项式模型
library(ggplot2)
fit_polynomial_models <- function(data, max_degree = 6) {
  models <- list()
  predictions <- data.frame(x = data$x)
  
  for (degree in 1:max_degree) {
    model <- lm(y_observed ~ poly(x, degree), data = data)
    models[[paste0("degree_", degree)]] <- model
    predictions[[paste0("pred_", degree)]] <- predict(model, newdata = data)
  }
  
  return(list(models = models, predictions = predictions))
}

# 拟合模型
results <- fit_polynomial_models(demo_data)

# 可视化过拟合现象
plot_overfitting_demo <- function(data, predictions) {
  plot_data <- cbind(data, predictions)
  plot_data_long <- reshape2::melt(plot_data, id.vars = c("x", "y_true", "y_observed"), 
                                  variable.name = "model", value.name = "prediction")
  
  ggplot(plot_data_long, aes(x = x)) +
    geom_point(aes(y = y_observed), alpha = 0.6, size = 1) +
    geom_line(aes(y = y_true, color = "真实关系"), size = 1) +
    geom_line(aes(y = prediction, color = model), size = 0.7) +
    facet_wrap(~ model, ncol = 3) +
    labs(title = "过拟合现象演示：不同阶数多项式回归",
         x = "X", y = "Y",
         color = "曲线类型") +
    theme_minimal() +
    scale_color_manual(values = c("真实关系" = "black", 
                                 "pred_1" = "red", "pred_2" = "blue", 
                                 "pred_3" = "green", "pred_4" = "orange",
                                 "pred_5" = "purple", "pred_6" = "brown")) +
    theme(legend.position = "bottom")
}

# 显示图形
plot_overfitting_demo(demo_data, results$predictions)
```

### 1.2.2 偏差-方差权衡的深入分析

回忆《数理统计》里参数估计的评价标准： 无偏性：估计量的期望等于被估计参数。 有效性：在所有无偏估计量中，方差最小。 一致性：随着样本量增加，估计量趋近于被估计参数。 在预测建模中，我们关注的是预测误差的来源。偏差-方差权衡（Bias-Variance Tradeoff）是理解模型复杂度与预测性能关系的关键概念。

期望预测误差的严格分解：

对于回归问题，在平方损失下： $$
\begin{aligned}
E[(Y - \hat{f}(X))^2] &= E[(Y - E[Y|X] + E[Y|X] - \hat{f}(X))^2] \\
&= E[(Y - E[Y|X])^2] + E[(E[Y|X] - \hat{f}(X))^2] \\
&= \text{Var}(Y|X) + \text{Bias}^2(\hat{f}(X)) + \text{Var}(\hat{f}(X))
\end{aligned}
$$

偏差： - $\text{Bias}(\hat{f}(X)) = E[\hat{f}(X)] - f(X)$ - 系统性错误，模型与真实关系的差距 - 高偏差原因：模型过于简单，假设太强

方差： - $\text{Var}(\hat{f}(X)) = E[(\hat{f}(X) - E[\hat{f}(X)])^2]$ - 模型对训练数据变化的敏感性 - 高方差原因：模型过于复杂，对噪声敏感

不可约误差： - $\sigma_\varepsilon^2 = \text{Var}(Y|X)$ - 数据内在的随机性 - 无法通过改进模型减少

**编程演示：偏差-方差权衡**

```{r}

# 1.2.2 偏差-方差权衡演示
demonstrate_bias_variance <- function() {
  set.seed(123)
  n_simulations <- 100
  x <- seq(0, 1, length.out = 50)
  true_function <- function(x) sin(2 * pi * x)
  
  # 生成多个训练集
  generate_training_set <- function() {
    x_train <- runif(20, 0, 1)
    y_train <- true_function(x_train) + rnorm(20, 0, 0.3)
    return(data.frame(x = x_train, y = y_train))
  }
  
  # 拟合不同复杂度的模型
  fit_models <- function(data, degree) {
    if (degree == 1) {
      lm(y ~ x, data = data)
    } else {
      lm(y ~ poly(x, degree), data = data)
    }
  }
  
  # 计算偏差和方差
  results <- list()
  degrees <- c(1, 3, 10)  # 低、中、高复杂度
  
  for (degree in degrees) {
    predictions <- matrix(0, nrow = length(x), ncol = n_simulations)
    
    for (i in 1:n_simulations) {
      train_data <- generate_training_set()
      model <- fit_models(train_data, degree)
      pred <- predict(model, newdata = data.frame(x = x))
      predictions[, i] <- pred
    }
    
    # 计算偏差和方差
    mean_pred <- rowMeans(predictions)
    bias_sq <- mean((mean_pred - true_function(x))^2)
    variance <- mean(apply(predictions, 1, var))
    
    results[[as.character(degree)]] <- list(
      bias_sq = bias_sq,
      variance = variance,
      total_error = bias_sq + variance + 0.3^2,  # 加上噪声方差
      predictions = predictions,
      mean_pred = mean_pred
    )
  }
  
  return(results)
}

# 运行演示
bias_variance_results <- demonstrate_bias_variance()

# 可视化结果
plot_bias_variance <- function(results, x) {
  true_y <- sin(2 * pi * x)
  
  par(mfrow = c(1, 3))
  for (i in 1:3) {
    degree <- c(1, 3, 10)[i]
    res <- results[[as.character(degree)]]
    
    plot(x, true_y, type = "l", lwd = 3, col = "black", 
         ylim = c(-1.5, 1.5), main = paste("多项式阶数:", degree),
         xlab = "X", ylab = "Y")
    
    # 绘制多个拟合曲线
    for (j in 1:20) {
      lines(x, res$predictions[, j], col = rgb(0.7, 0.7, 0.7, 0.3))
    }
    
    # 绘制平均预测和真实函数
    lines(x, res$mean_pred, col = "red", lwd = 2)
    lines(x, true_y, col = "black", lwd = 2)
    
    # 添加图例
    legend("topright", 
           legend = c("真实函数", "平均预测", "单个拟合"),
           col = c("black", "red", "gray"), lwd = c(2, 2, 1), bty = "n")
  }
  par(mfrow = c(1, 1))
}

# 创建x值用于绘图
x_plot <- seq(0, 1, length.out = 50)
plot_bias_variance(bias_variance_results, x_plot)

# 打印偏差-方差分解结果
cat("偏差-方差分解结果:\n")
for (degree in c(1, 3, 10)) {
  res <- bias_variance_results[[as.character(degree)]]
  cat(sprintf("阶数 %d: 偏差²=%.4f, 方差=%.4f, 总误差=%.4f\n", 
              degree, res$bias_sq, res$variance, res$total_error))
}
```

### 1.2.3 模型复杂度的影响分析

复杂度与误差的关系：

| 复杂度状态 | 训练误差 | 测试误差 | 偏差 | 方差 |
|------------|----------|----------|------|------|
| 低复杂度   | 高       | 高       | 高   | 低   |
| 最优复杂度 | 中等     | 最低     | 中等 | 中等 |
| 高复杂度   | 很低     | 高       | 低   | 高   |

学习曲线分析： 绘制训练集大小与误差的关系： - 训练误差：随样本增加而增加（趋于稳定） - 测试误差：随样本增加而减少（趋于稳定） - 两者差距：反映方差大小

实际指导意义： - 高偏差：增加模型复杂度，增加特征 - 高方差：减少模型复杂度，增加数据，正则化

## 1.3 模型评估框架

### 1.3.1 数据划分的详细策略

为什么需要数据划分： - 评估模型泛化能力 - 避免对训练数据的过度优化 - 提供无偏的性能估计

训练集： - 用于模型参数估计 - 应该足够大以学习数据模式 - 通常占60-80%

验证集： - 用于模型选择和超参数调优 - 提供模型比较的基础 - 通常占10-20%

测试集： - 用于最终模型评估 - 在整个建模过程中只能使用一次 - 通常占10-20%

数学表达： 将数据集 $D$ 划分为： $$
D = D_{\text{train}} \cup D_{\text{val}} \cup D_{\text{test}}
$$ 其中：

-   $D_{\text{train}} \cap D_{\text{val}} = \emptyset$

-   $D_{\text{train}} \cap D_{\text{test}} = \emptyset$

-   $D_{\text{val}} \cap D_{\text{test}} = \emptyset$

特殊情况的处理：

-   \- 小样本：使用交叉验证

-   \- 时间序列：按时间顺序划分

-   \- 不平衡数据：分层抽样

**编程演示：数据划分策略**

```{r}
# 1.3.1 数据划分策略演示
demonstrate_data_splitting <- function() {
  set.seed(123)
  n <- 1000
  # 生成回归数据
  x1 <- rnorm(n)
  x2 <- rnorm(n)
  y <- 2*x1 + 3*x2 + rnorm(n, 0, 1)
  data <- data.frame(x1 = x1, x2 = x2, y = y)
  
  # 简单划分（70%训练，30%测试）
  train_idx_simple <- sample(1:n, size = 0.7 * n)
  test_idx_simple <- setdiff(1:n, train_idx_simple)
  
  cat("简单划分结果:\n")
  cat("训练集大小:", length(train_idx_simple), "\n")
  cat("测试集大小:", length(test_idx_simple), "\n")
  
  # 检查分布是否相似
  cat("\n训练集和测试集分布比较:\n")
  cat("训练集y均值:", mean(data$y[train_idx_simple]), "\n")
  cat("测试集y均值:", mean(data$y[test_idx_simple]), "\n")
  
  return(list(
    data = data,
    train_idx = train_idx_simple,
    test_idx = test_idx_simple
  ))
}

# 运行演示
split_results <- demonstrate_data_splitting()
```

### 1.3.2 交叉验证方法

k折交叉验证的完整流程：

1.  数据准备：
    -   随机打乱数据
    -   将数据分为k个大小相等的子集 $D_1, D_2, \ldots, D_k$
2.  交叉验证循环： For $i = 1$ to $k$:
    -   训练集：$D_{\text{train}}^{(i)} = D \setminus D_i$
    -   验证集：$D_{\text{val}}^{(i)} = D_i$
    -   在 $D_{\text{train}}^{(i)}$ 上训练模型
    -   在 $D_{\text{val}}^{(i)}$ 上计算验证误差 $\text{Err}^{(i)}$
3.  结果汇总：
    -   平均验证误差：$CV(k) = \frac{1}{k} \sum_{i=1}^k \text{Err}^{(i)}$
    -   误差标准差：$SE_{CV} = \sqrt{\frac{1}{k-1} \sum_{i=1}^k (\text{Err}^{(i)} - CV(k))^2}$

k值选择：

-   \- $k=5$ 或 $k=10$：常用选择

-   \- $k=n$（留一法）：计算量大，方差可能较高

-   \- 小k值：偏差较小，方差较大 - 大k值：偏差较大，方差较小

分层k折交叉验证： 对于分类问题，保持每个折中类别比例与整体一致。

时间序列交叉验证： 对于时间相关数据，确保验证集时间在训练集之后。

## 1.4 评估指标

### 1.4.1 回归问题评估指标

均方误差： $$
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$ - 优点：数学性质好，便于优化

\- 缺点：对异常值敏感，量纲与原始数据不同

均方根误差： $$
RMSE = \sqrt{MSE}
$$ - 优点：量纲与原始数据相同

-   缺点：仍然对异常值敏感

平均绝对误差： $$
MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
$$ - 优点：对异常值不敏感

\- 缺点：数学性质较差，优化困难

平均绝对百分比误差： $$
MAPE = \frac{100\%}{n} \sum_{i=1}^n \left| \frac{y_i - \hat{y}_i}{y_i} \right|
$$ - 优点：相对误差，易于解释

\- 缺点：$y_i=0$时无法计算，对负值处理困难

决定系数 $R^2$： $$
R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}
$$ - 优点：标准化，易于比较

\- 缺点：随特征增加而增加，可能误导

调整$R^2$： $$
R^2_{\text{adj}} = 1 - \frac{(1-R^2)(n-1)}{n-p-1}
$$ 其中 $p$ 是特征数，惩罚特征过多的模型。

\*\* 演示：回归评估指标\*\*

```{r}
# 1.4.1 回归评估指标演示
demonstrate_regression_metrics <- function() {
  set.seed(123)
  n <- 100
  # 生成数据
  x <- rnorm(n)
  y_true <- 2*x + 1
  y_pred <- y_true + rnorm(n, 0, 0.5)  # 预测值（带有误差）
  y_actual <- y_true + rnorm(n, 0, 0.3)  # 实际观测值（带有噪声）
  
  # 计算各种评估指标
  calculate_regression_metrics <- function(actual, predicted) {
    n <- length(actual)
    residuals <- actual - predicted
    
    mse <- mean(residuals^2)
    rmse <- sqrt(mse)
    mae <- mean(abs(residuals))
    
    # R-squared
    ss_residual <- sum(residuals^2)
    ss_total <- sum((actual - mean(actual))^2)
    r_squared <- 1 - (ss_residual / ss_total)
    
    # 调整R-squared
    p <- 1  # 特征数
    r_squared_adj <- 1 - (1 - r_squared) * (n - 1) / (n - p - 1)
    
    return(list(
      MSE = mse,
      RMSE = rmse,
      MAE = mae,
      R2 = r_squared,
      R2_adj = r_squared_adj
    ))
  }
  
  metrics <- calculate_regression_metrics(y_actual, y_pred)
  
  cat("回归评估指标:\n")
  cat("MSE (均方误差):", round(metrics$MSE, 4), "\n")
  cat("RMSE (均方根误差):", round(metrics$RMSE, 4), "\n")
  cat("MAE (平均绝对误差):", round(metrics$MAE, 4), "\n")
  cat("R² (决定系数):", round(metrics$R2, 4), "\n")
  cat("调整R²:", round(metrics$R2_adj, 4), "\n")
  
  # 可视化预测效果
  plot_data <- data.frame(
    Actual = y_actual,
    Predicted = y_pred,
    Perfect = y_actual  # 完美预测线
  )
  
  library(ggplot2)
  p <- ggplot(plot_data, aes(x = Actual, y = Predicted)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    geom_smooth(method = "lm", se = FALSE, color = "blue") +
    labs(title = "预测值 vs 实际值",
         subtitle = paste("R² =", round(metrics$R2, 4)),
         x = "实际值", y = "预测值") +
    theme_minimal()
  
  print(p)
  
  return(metrics)
}

# 运行回归指标演示
regression_metrics <- demonstrate_regression_metrics()
```

### 1.4.2 分类问题评估指标

混淆矩阵的扩展： 对于多分类问题，混淆矩阵是 $K \times K$ 的表格。

准确率的局限性： - 在不平衡数据中可能误导 - 例：99%负例，全预测负类仍有99%准确率

精确率与召回率的权衡： - 精确率：预测为正的样本中实际为正的比例 - 召回率：实际为正的样本中被预测为正的比例 - 通常存在trade-off关系

Fβ分数： $$
F_\beta = (1+\beta^2) \times \frac{\text{Precision} \times \text{Recall}}{(\beta^2 \times \text{Precision}) + \text{Recall}}
$$ - $\beta > 1$：更重视召回率 - $\beta < 1$：更重视精确率 - $\beta = 1$：平衡（F1分数）

马修斯相关系数： $$
MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}
$$ 适用于不平衡数据的综合指标。

-   编程演示：分类评估指标\*

```{r}
# 1.4.2 分类评估指标演示
demonstrate_classification_metrics <- function() {
  set.seed(123)
  n <- 1000
  # 生成二分类数据
  feature1 <- rnorm(n)
  feature2 <- rnorm(n)
  
  # 生成真实概率
  true_prob <- plogis(0.5 + 1.2 * feature1 - 0.8 * feature2)
  true_labels <- rbinom(n, 1, true_prob)
  
  # 生成预测概率（带有一些误差）
  pred_prob <- true_prob + rnorm(n, 0, 0.1)
  pred_prob <- pmin(pmax(pred_prob, 0), 1)  # 限制在[0,1]范围内
  pred_labels <- ifelse(pred_prob > 0.5, 1, 0)
  
  # 计算混淆矩阵
  calculate_confusion_matrix <- function(actual, predicted) {
    tp <- sum(actual == 1 & predicted == 1)
    tn <- sum(actual == 0 & predicted == 0)
    fp <- sum(actual == 0 & predicted == 1)
    fn <- sum(actual == 1 & predicted == 0)
    
    return(list(TP = tp, TN = tn, FP = fp, FN = fn))
  }
  
  cm <- calculate_confusion_matrix(true_labels, pred_labels)
  
  # 计算各种指标
  accuracy <- (cm$TP + cm$TN) / n
  precision <- cm$TP / (cm$TP + cm$FP)
  recall <- cm$TP / (cm$TP + cm$FN)
  f1_score <- 2 * (precision * recall) / (precision + recall)
  
  # 计算AUC
  calculate_auc <- function(actual, prob) {
    # 简单实现AUC计算
    positive_probs <- prob[actual == 1]
    negative_probs <- prob[actual == 0]
    
    comparisons <- 0
    correct <- 0
    
    # 抽样计算以加快速度
    n_sample <- min(100, length(positive_probs), length(negative_probs))
    pos_sample <- sample(positive_probs, n_sample)
    neg_sample <- sample(negative_probs, n_sample)
    
    for (p in pos_sample) {
      for (n in neg_sample) {
        comparisons <- comparisons + 1
        if (p > n) correct <- correct + 1
        else if (p == n) correct <- correct + 0.5
      }
    }
    
    return(correct / comparisons)
  }
  
  auc_score <- calculate_auc(true_labels, pred_prob)
  
  cat("分类评估指标:\n")
  cat("准确率:", round(accuracy, 4), "\n")
  cat("精确率:", round(precision, 4), "\n")
  cat("召回率:", round(recall, 4), "\n")
  cat("F1分数:", round(f1_score, 4), "\n")
  cat("AUC:", round(auc_score, 4), "\n")
  
  # 打印混淆矩阵
  cat("\n混淆矩阵:\n")
  confusion_df <- data.frame(
    Actual_0 = c(cm$TN, cm$FN),
    Actual_1 = c(cm$FP, cm$TP)
  )
  rownames(confusion_df) <- c("Predicted_0", "Predicted_1")
  print(confusion_df)
  
  # 可视化ROC曲线
  plot_roc_curve <- function(actual, prob) {
    thresholds <- seq(0, 1, 0.01)
    tpr <- numeric(length(thresholds))
    fpr <- numeric(length(thresholds))
    
    for (i in 1:length(thresholds)) {
      pred <- ifelse(prob > thresholds[i], 1, 0)
      cm_temp <- calculate_confusion_matrix(actual, pred)
      tpr[i] <- cm_temp$TP / (cm_temp$TP + cm_temp$FN)  # 真正率
      fpr[i] <- cm_temp$FP / (cm_temp$FP + cm_temp$TN)  # 假正率
    }
    
    roc_data <- data.frame(FPR = fpr, TPR = tpr)
    
    ggplot(roc_data, aes(x = FPR, y = TPR)) +
      geom_line(color = "blue", size = 1) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
      labs(title = "ROC曲线",
           subtitle = paste("AUC =", round(auc_score, 4)),
           x = "假正率 (FPR)", y = "真正率 (TPR)") +
      theme_minimal() +
      coord_equal()
  }
  
  roc_plot <- plot_roc_curve(true_labels, pred_prob)
  print(roc_plot)
  
  return(list(
    accuracy = accuracy,
    precision = precision,
    recall = recall,
    f1_score = f1_score,
    auc = auc_score,
    confusion_matrix = cm
  ))
}

# 运行分类指标演示
classification_metrics <- demonstrate_classification_metrics()
```

### 1.4.3 ROC曲线与AUC曲线

ROC曲线的绘制： 1. 计算不同分类阈值下的TPR和FPR 2. 以FPR为横轴，TPR为纵轴绘制曲线 3. 曲线越靠近左上角，性能越好

AUC的概率解释： AUC等于随机选取的正样本得分高于随机选取的负样本得分的概率。

AUC的优势： - 与分类阈值无关 - 反映模型整体排序能力 - 适用于不平衡数据

AUC的局限性： - 只关注排序，不关注具体概率值 - 在某些情况下可能过于乐观

精确率-召回率曲线： 在不平衡数据中通常比ROC曲线更有信息量。

## 1.5 模型选择原则

### 1.5.1 奥卡姆剃刀原理的统计基础

简约性原则： 在同样能够解释数据的模型中，选择最简单的模型。

数学形式化： 选择使以下目标函数最小的模型： $$
\text{Objective} = \text{拟合优度} + \lambda \times \text{模型复杂度}
$$

模型复杂度的度量： - 参数个数 - VC维 - 有效参数个数

### 1.5.2 信息准则的详细推导

AIC的推导： 基于Kullback-Leibler散度，目标是选择最接近真实分布的模型。 $$
AIC = 2k - 2\ln(\hat{L})
$$ 其中： - $k$：模型参数个数 - $\hat{L}$：最大似然值

BIC的推导： 基于贝叶斯因子，在样本量较大时的一致性选择。 $$
BIC = \ln(n)k - 2\ln(\hat{L})
$$

AICc： 小样本修正的AIC： $$
AICc = AIC + \frac{2k(k+1)}{n-k-1}
$$

信息准则的比较：

| 准则 | 目标         | 一致性 | 效率 |
|------|--------------|--------|------|
| AIC  | 预测精度     | 否     | 是   |
| BIC  | 选择真实模型 | 是     | 否   |
| AICc | 小样本预测   | 否     | 是   |

### 1.5.3 实际选择策略

多准则综合评估：

-   计算多个信息准则

-   分析学习曲线

-   考虑业务约束

-   评估计算成本

领域知识的作用：

-   理解数据的生成机制

-   考虑特征的物理意义

-   评估模型的可解释性

## 1.6 软件使用

本书主要使用开源软件R、Python。

### 16.1 R语言

R+Rstudio，使用到的包(package)包括knir、tidyverse、ggplot2等，文件格式为.rmd，可以混编显示文本、代码块（chunk）、代码运行结果等各种格式内容，进行交互式的分析，可以直接生成html、doc、PDF、PPT等格式，撰写实验报告、论文、书籍等。

**典型R包结构**

```         
a_r_package/
├── DESCRIPTION                    # 📋 包的"身份证"
│   - Package: my_r_package        # 包名
│   - Version: 0.1.0               # 版本号
│   - Title: 包的功能描述          # 标题
│   - Author: 作者信息             # 作者
│   - Description: 详细描述        # 详细描述
│   - License: MIT                 # 许可证
│   - Imports: dplyr, ggplot2      # 依赖包
│   - Suggests: testthat           # 建议依赖
│
├── NAMESPACE                      # 🚪 函数的"门卫"
│   - export(hello_world)         # 导出函数供用户使用
│   - import(dplyr)               # 导入依赖包的函数
│   - importFrom(ggplot2, aes)    # 导入特定函数
│
├── R/                            # 💻 核心代码目录
│   ├── hello.R                   # 函数定义文件1
│   │   # 函数定义
│   │   hello_world <- function() {
│   │     print("Hello from R package!")
│   │   }
│   │
│   ├── data_processing.R         # 函数定义文件2
│   │   clean_data <- function(df) {
│   │     dplyr::filter(df, !is.na(value))
│   │   }
│   │
│   └── utils.R                   # 工具函数（内部使用）
│       internal_func <- function() {
│         # 不导出，仅内部使用
│       }
│
├── man/                          # 📚 文档目录（.Rd文件）
│   ├── hello_world.Rd            # 函数的帮助文档
│   │   \name{hello_world}
│   │   \title{打招呼函数}
│   │   \description{详细描述}
│   │   \usage{hello_world()}
│   │   \examples{hello_world()}
│   │
│   └── my_r_package-package.Rd   # 包的总体文档
│
├── tests/                        # 🧪 测试目录
│   ├── testthat/                 # testthat测试框架
│   │   ├── test-hello.R          # 测试文件
│   │   │   test_that("hello works", {
│   │   │     expect_output(hello_world(), "Hello")
│   │   │   })
│   │   └── test-data.R
│   └── testthat.R                # 测试运行器
│
├── vignettes/                    # 📖 长篇教程/案例
│   └── introduction.Rmd          # 包的使用教程
│
├── data/                         # 📊 包内置数据集
│   ├── sample_data.rda           # R数据文件
│   └── internal_data.rda         # 内部数据
│
├── inst/                         # 🎁 安装时包含的文件
│   ├── CITATION                  # 引用信息
│   ├── extdata/                  # 外部数据示例
│   └── templates/                # 模板文件
│
└── .Rbuildignore                 # ❌ 构建时忽略的文件
```

**R数据分析典型项目结构**

```         
data_analysis_project/          # 📈 数据分析项目
├── data/                       # 📊 数据管理
│   ├── raw/                    # 原始数据（只读）
│   ├── processed/              # 处理后的数据
│   └── external/               # 外部数据源
│
├── R/                          # 💻 R代码
│   ├── 01_data_cleaning.R      # 数据清洗
│   ├── 02_exploratory.R        # 探索性分析
│   ├── 03_modeling.R           # 建模
│   ├── 04_visualization.R      # 可视化
│   └── functions/              # 自定义函数
│       ├── utils.R
│       └── plotting_functions.R
│
├── analysis/                   # 📖 分析文档
│   ├── report.Rmd              # R Markdown报告
│   ├── presentation.Rmd        # 演示文稿
│   └── dashboard/              # Shiny应用
│
├── outputs/                    # 🎨 输出结果
│   ├── figures/                # 生成的图表
│   ├── tables/                 # 生成的表格
│   └── models/                 # 保存的模型
│
├── tests/                      # 🧪 测试
├── references/                 # 📚 参考文献/文档
├── .Rprofile                   # 🔧 R启动配置
├── .Renviron                   # 🌍 环境变量
└── data_analysis_project.Rproj # 🏠 RStudio项目文件
```

### 16.2 Python

依托Anaconda平台，该平台打包了python和重要的模块，包括环境的设置，自带IDE包括jupyter notebook、jupyterlab、pycharm等，使用到的库（library）包括pandas、numpy、sklearn，由jupyter notebook编译文件格式为.ipynb，可以实现文本、代码块（cell）、代码运行结果、结果分析等混编，进行交互式的分析，可以直接生成html、doc、PDF等格式。

**Python包结构**

```         
a_python_package/
├── pyproject.toml                    # 🎯 现代构建配置（替代setup.py）
│   [build-system]
│   requires = ["setuptools", "wheel"]
│   
│   [project]
│   name = "my_python_package"
│   version = "0.1.0"
│   dependencies = [
│     "numpy>=1.20",
│     "pandas>=1.3"
│   ]
│
├── src/                              # 📁 源代码目录（推荐结构）
│   └── my_python_package/           # 包的主目录
│       ├── __init__.py              # 🚪 包的入口点
│       │   """包的主模块"""
│       │   __version__ = "0.1.0"
│       │   __author__ = "Your Name"
│       │   
│       │   # 导入关键函数，方便用户访问
│       │   from .core import (
│       │       normalize_data,
│       │       process_dataframe
│       │   )
│       │   
│       │   # 也可以使用 __all__ 控制导入
│       │   __all__ = ["normalize_data", "process_dataframe"]
│       │
│       ├── core.py                   # 💼 核心模块
│       │   """核心功能实现"""
│       │   import numpy as np
│       │   import pandas as pd
│       │   
│       │   def normalize_data(x):
│       │       """标准化数据"""
│       │       if not isinstance(x, (np.ndarray, list)):
│       │           raise TypeError("输入必须是数组或列表")
│       │       x = np.array(x)
│       │       return (x - np.mean(x)) / np.std(x)
│       │   
│       │   def _internal_helper():
│       │       """内部函数（以下划线开头）"""
│       │       return "internal"
│       │
│       ├── utils/                    # 🧰 子包/工具模块目录
│       │   ├── __init__.py
│       │   ├── file_utils.py
│       │   └── math_utils.py
│       │
│       ├── data/                     # 📊 数据管理
│       │   ├── __init__.py
│       │   ├── datasets.py          # 数据集加载函数
│       │   └── constants.py         # 常量定义
│       │
│       └── tests/                    # 🧪 测试目录（可选放这里）
│           ├── __init__.py
│           ├── test_core.py
│           └── test_utils/
│
├── tests/                           # 🧪 测试目录（或放外面）
│   ├── test_core.py
│   │   def test_normalize():
│   │       from src.my_python_package.core import normalize_data
│   │       result = normalize_data([1, 2, 3])
│   │       assert np.allclose(result.mean(), 0)
│   │
│   └── conftest.py                  # pytest配置
│
├── docs/                            # 📚 文档
│   ├── conf.py                      # Sphinx配置
│   ├── index.rst                    # 文档首页
│   └── api.rst                      # API文档
│
├── examples/                        # 🚀 使用示例
│   ├── basic_usage.ipynb            # Jupyter示例
│   └── advanced_demo.py
│
├── .github/                         # 🤖 GitHub配置
│   ├── workflows/
│   │   └── ci.yml                   # 持续集成
│   └── ISSUE_TEMPLATE/              # Issue模板
│
├── README.md                        # 📖 项目说明
├── LICENSE                          # ⚖️ 许可证
├── requirements.txt                 # 📦 依赖列表（可选）
└── setup.cfg                        # ⚙️ 传统配置（兼容性）
```

**Python数据分析项目结构**

```         
my_project/                     # 🤖 机器学习项目
├── src/                        # 💻 源代码
│   ├── data/                   # 数据模块
│   │   ├── __init__.py
│   │   ├── make_dataset.py     # 数据准备
│   │   └── preprocessing.py    # 预处理
│   │
│   ├── features/               # 特征工程
│   │   ├── __init__.py
│   │   ├── build_features.py
│   │   └── selection.py
│   │
│   ├── models/                 # 模型
│   │   ├── __init__.py
│   │   ├── train_model.py
│   │   └── predict_model.py
│   │
│   └── visualization/          # 可视化
│       ├── __init__.py
│       └── plot_results.py
│
├── notebooks/                  # 📓 Jupyter笔记本
│   ├── 01_exploratory.ipynb    # 探索性分析
│   ├── 02_feature_engineering.ipynb
│   └── 03_model_training.ipynb
│
├── data/                       # 📊 数据
│   ├── raw/                    # 原始数据
│   ├── interim/                # 中间数据
│   └── processed/              # 处理后的数据
│
├── models/                     # 💾 模型存储
│   ├── trained_models/
│   └── model_metrics.json
│
├── reports/                    # 📄 报告
│   ├── figures/                # 图表
│   └── final_report.md
│
├── tests/                      # 🧪 测试
├── configs/                    # ⚙️ 配置文件
│   ├── data_config.yaml
│   └── model_config.yaml
│
├── requirements.txt            # 📦 依赖
├── setup.py                    # 🏗️ 安装配置
├── pyproject.toml              # 🎯 现代配置
├── Dockerfile                  # 🐳 容器化
└── README.md                   # 📖 说明文档
```

### 1.6.3 学习工具平台搭建

统计学专业的同学，可以考虑R+Rtools+Rstudio，使用Rstudio作为分析平台，文件格式为RMD，如果想混合Python使用，可以加载包reticulate，连接调用python使用。

面向机器学习的同学，应该以Python为主，学习、笔记、报告、作业等考虑Anaconda里面的IDE工具jupyter notebook，文件格式为ipynb，或者考虑使用jupyterlab。

面向工程开发、项目管理的同学，考虑使用VScode，如果工作偏向于数据科学，可以使用Positren，是一个类似vscode的数据科学定制版，可以交叉调用R、Python、Julia等语言进行混合编程，集成git进行版本控制和发布，本书即使用Positren编写。

## 1.7 综合案例

### 1.7.1 mtcars数据集分析：R语言实现

```{r}
analyze_mtcars_dataset <- function() {
  # 加载数据
  data(mtcars)
  cat("mtcars数据集基本信息:\n")
  cat("样本数:", nrow(mtcars), "\n")
  cat("变量数:", ncol(mtcars), "\n")
  cat("\n变量名称:\n")
  print(names(mtcars))
  
  # 数据概览
  cat("\n数据概览:\n")
  print(summary(mtcars))
  
  # 探索性数据分析
  library(ggplot2)
  library(patchwork)
  
  # 目标变量：mpg（每加仑行驶英里数）
  p1 <- ggplot(mtcars, aes(x = mpg)) +
    geom_histogram(bins = 15, fill = "steelblue", alpha = 0.5) +
    labs(title = "MPG分布", x = "MPG", y = "频数") +
    theme_minimal()
  
  p2 <- ggplot(mtcars, aes(x = wt, y = mpg)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE, color = "red") +
    labs(title = "车重与MPG关系", x = "重量", y = "MPG") +
    theme_minimal()
  
  p3 <- ggplot(mtcars, aes(x = factor(cyl), y = mpg)) +
    geom_boxplot(fill = "lightgreen", alpha = 0.7) +
    labs(title = "气缸数与MPG关系", x = "气缸数", y = "MPG") +
    theme_minimal()
  
  # 组合图形
  combined_plot <- (p1 | p2 | p3)
  print(combined_plot)
  
  # 数据划分
  set.seed(123)
  train_indices <- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))
  test_indices <- setdiff(1:nrow(mtcars), train_indices)
  
  cat("\n数据划分结果:\n")
  cat("训练集大小:", length(train_indices), "\n")
  cat("测试集大小:", length(test_indices), "\n")
  
  # 训练不同复杂度的模型
  models <- list()
  
  # 简单模型
  models[["simple"]] <- lm(mpg ~ wt, data = mtcars[train_indices, ])
  
  # 中等复杂度模型
  models[["medium"]] <- lm(mpg ~ wt + cyl + hp, data = mtcars[train_indices, ])
  
  # 复杂模型
  models[["complex"]] <- lm(mpg ~ wt + cyl + hp + disp + drat + qsec, 
                           data = mtcars[train_indices, ])
  
  # 评估模型性能
  evaluate_model <- function(model, test_data) {
    predictions <- predict(model, newdata = test_data)
    actual <- test_data$mpg
    
    mse <- mean((actual - predictions)^2)
    rmse <- sqrt(mse)
    mae <- mean(abs(actual - predictions))
    r2 <- 1 - sum((actual - predictions)^2) / sum((actual - mean(actual))^2)
    
    return(list(MSE = mse, RMSE = rmse, MAE = mae, R2 = r2))
  }
  
  # 比较所有模型
  test_data <- mtcars[test_indices, ]
  performance <- data.frame()
  
  for (model_name in names(models)) {
    model <- models[[model_name]]
    perf <- evaluate_model(model, test_data)
    
    performance <- rbind(performance, data.frame(
      Model = model_name,
      Parameters = length(coef(model)),
      MSE = perf$MSE,
      RMSE = perf$RMSE,
      MAE = perf$MAE,
      R2 = perf$R2
    ))
  }
  
  cat("\n模型性能比较:\n")
  print(performance)
  
  # 交叉验证比较
  library(mlr3)
  library(mlr3verse)
  
  # 创建任务
  mtcars_task <- as_task_regr(mtcars[, c("mpg", "wt", "cyl", "hp", "disp", "drat", "qsec")], 
                             target = "mpg", id = "mtcars")
  
  # 定义学习器
  learners <- list(
    lrn("regr.lm", id = "simple_lm"),
    lrn("regr.rpart", id = "tree"),
    lrn("regr.kknn", id = "knn")
  )
  
  # 交叉验证
  resampling <- rsmp("cv", folds = 5)
  
  cv_results <- data.frame()
  for (learner in learners) {
    rr <- resample(mtcars_task, learner, resampling)
    cv_results <- rbind(cv_results, data.frame(
      Model = learner$id,
      CV_RMSE = sqrt(rr$aggregate(msr("regr.mse"))),
      CV_MAE = rr$aggregate(msr("regr.mae")),
      CV_R2 = rr$aggregate(msr("regr.rsq"))
    ))
  }
  
  cat("\n交叉验证结果:\n")
  print(cv_results)
  
  # 过拟合分析
  analyze_overfitting <- function() {
    train_errors <- numeric(3)
    test_errors <- numeric(3)
    model_names <- c("simple", "medium", "complex")
    
    for (i in 1:3) {
      model <- models[[model_names[i]]]
      
      # 训练误差
      train_pred <- predict(model, newdata = mtcars[train_indices, ])
      train_errors[i] <- mean((mtcars$mpg[train_indices] - train_pred)^2)
      
      # 测试误差
      test_pred <- predict(model, newdata = test_data)
      test_errors[i] <- mean((test_data$mpg - test_pred)^2)
    }
    
    overfitting_data <- data.frame(
      Model = model_names,
      Train_MSE = train_errors,
      Test_MSE = test_errors,
      Overfitting_Gap = test_errors - train_errors
    )
    
    cat("\n过拟合分析:\n")
    print(overfitting_data)
    
    # 可视化过拟合现象
    p <- ggplot(overfitting_data, aes(x = Model)) +
      geom_line(aes(y = Train_MSE, color = "训练误差", group = 1), size = 1) +
      geom_line(aes(y = Test_MSE, color = "测试误差", group = 1), size = 1) +
      geom_point(aes(y = Train_MSE, color = "训练误差"), size = 3) +
      geom_point(aes(y = Test_MSE, color = "测试误差"), size = 3) +
      labs(title = "过拟合分析：训练误差 vs 测试误差",
           x = "模型复杂度", y = "均方误差 (MSE)",
           color = "误差类型") +
      theme_minimal() +
      scale_color_manual(values = c("训练误差" = "blue", "测试误差" = "red"))
    
    print(p)
    
    return(overfitting_data)
  }
  
  overfitting_analysis <- analyze_overfitting()
  
  return(list(
    performance = performance,
    cv_results = cv_results,
    overfitting_analysis = overfitting_analysis,
    models = models
  ))
}

# 运行综合案例分析
mtcars_analysis <- analyze_mtcars_dataset()
```

### 1.7.2 mtcars数据集分析：Python语言实现

```{Python}
# mtcars数据集分析 - Python版本
def analyze_mtcars_python():
    import pandas as pd
    import numpy as np
    import matplotlib
    matplotlib.rc("font",family="Microsoft YaHei")
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.linear_model import LinearRegression
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.neighbors import KNeighborsRegressor
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.preprocessing import StandardScaler
    
    # 加载mtcars数据集
    try:
        # 尝试从在线源加载
        url = "https://raw.githubusercontent.com/plotly/datasets/master/mtcars.csv"
        mtcars = pd.read_csv(url)
    except:
        # 如果网络不可用，使用内置数据集或创建模拟数据
        print("网络数据加载失败，使用模拟数据")
        np.random.seed(42)
        n = 32
        mtcars = pd.DataFrame({
            'mpg': np.random.normal(20, 6, n),
            'cyl': np.random.choice([4, 6, 8], n),
            'disp': np.random.normal(200, 100, n),
            'hp': np.random.normal(150, 50, n),
            'wt': np.random.normal(3, 1, n),
            'qsec': np.random.normal(18, 2, n)
        })
    
    print("mtcars数据集基本信息:")
    print(f"样本数: {mtcars.shape[0]}")
    print(f"变量数: {mtcars.shape[1]}")
    print("\n数据概览:")
    print(mtcars.describe())
    
    # 数据可视化
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # MPG分布
    axes[0,0].hist(mtcars['mpg'], bins=10, alpha=0.7, color='steelblue')
    axes[0,0].set_title('MPG分布')
    axes[0,0].set_xlabel('MPG')
    axes[0,0].set_ylabel('频数')
    
    # 车重与MPG关系
    axes[0,1].scatter(mtcars['wt'], mtcars['mpg'], alpha=0.7)
    z = np.polyfit(mtcars['wt'], mtcars['mpg'], 1)
    p = np.poly1d(z)
    axes[0,1].plot(mtcars['wt'], p(mtcars['wt']), "r--", alpha=0.8)
    axes[0,1].set_title('车重与MPG关系')
    axes[0,1].set_xlabel('重量')
    axes[0,1].set_ylabel('MPG')
    
    # 马力与MPG关系
    axes[1,0].scatter(mtcars['hp'], mtcars['mpg'], alpha=0.7)
    z = np.polyfit(mtcars['hp'], mtcars['mpg'], 1)
    p = np.poly1d(z)
    axes[1,0].plot(mtcars['hp'], p(mtcars['hp']), "r--", alpha=0.8)
    axes[1,0].set_title('马力与MPG关系')
    axes[1,0].set_xlabel('马力')
    axes[1,0].set_ylabel('MPG')
    
    # 气缸数与MPG关系
    mtcars.boxplot(column='mpg', by='cyl', ax=axes[1,1])
    axes[1,1].set_title('气缸数与MPG关系')
    axes[1,1].set_xlabel('气缸数')
    
    plt.tight_layout()
    plt.show()
    
    # 准备数据
    X = mtcars[['wt', 'cyl', 'hp', 'disp', 'qsec']]
    y = mtcars['mpg']
    
    # 数据划分
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    print(f"\n数据划分结果:")
    print(f"训练集大小: {X_train.shape[0]}")
    print(f"测试集大小: {X_test.shape[0]}")
    
    # 训练不同模型
    models = {
        'Linear Regression': LinearRegression(),
        'Decision Tree': DecisionTreeRegressor(random_state=42),
        'K-Neighbors': KNeighborsRegressor()
    }
    
    # 评估函数
    def evaluate_model(model, X_train, X_test, y_train, y_test):
        model.fit(X_train, y_train)
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        metrics = {
            'Train_MSE': mean_squared_error(y_train, y_pred_train),
            'Test_MSE': mean_squared_error(y_test, y_pred_test),
            'Train_R2': r2_score(y_train, y_pred_train),
            'Test_R2': r2_score(y_test, y_pred_test),
            'Overfitting_Gap': mean_squared_error(y_test, y_pred_test) - mean_squared_error(y_train, y_pred_train)
        }
        return metrics
    
    # 比较模型性能
    results = []
    for name, model in models.items():
        metrics = evaluate_model(model, X_train, X_test, y_train, y_test)
        results.append({
            'Model': name,
            **metrics
        })
    
    results_df = pd.DataFrame(results)
    print("\n模型性能比较:")
    print(results_df)
    
    # 交叉验证
    print("\n交叉验证结果 (5折):")
    cv_results = []
    for name, model in models.items():
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
        cv_rmse = np.sqrt(-cv_scores)
        cv_results.append({
            'Model': name,
            'CV_RMSE_mean': cv_rmse.mean(),
            'CV_RMSE_std': cv_rmse.std()
        })
    
    cv_df = pd.DataFrame(cv_results)
    print(cv_df)
    
    # 可视化结果
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # 过拟合分析
    x_pos = np.arange(len(models))
    width = 0.35
    
    train_mse = results_df['Train_MSE'].values
    test_mse = results_df['Test_MSE'].values
    
    ax1.bar(x_pos - width/2, train_mse, width, label='训练MSE', alpha=0.7)
    ax1.bar(x_pos + width/2, test_mse, width, label='测试MSE', alpha=0.7)
    ax1.set_xlabel('模型')
    ax1.set_ylabel('均方误差 (MSE)')
    ax1.set_title('过拟合分析')
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels(results_df['Model'])
    ax1.legend()
    
    # R²比较
    train_r2 = results_df['Train_R2'].values
    test_r2 = results_df['Test_R2'].values
    
    ax2.bar(x_pos - width/2, train_r2, width, label='训练R²', alpha=0.7)
    ax2.bar(x_pos + width/2, test_r2, width, label='测试R²', alpha=0.7)
    ax2.set_xlabel('模型')
    ax2.set_ylabel('R²')
    ax2.set_title('拟合优度比较')
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(results_df['Model'])
    ax2.legend()
    
    plt.tight_layout()
    plt.show()
    
    return {
        'performance': results_df,
        'cv_results': cv_df,
        'data': mtcars
    }

# 运行Python分析
mtcars_python_analysis = analyze_mtcars_python()
```

### 1.7.3 案例总结与最佳实践

关键发现总结

-   过拟合验证：在mtcars数据集中，复杂模型在训练集上表现更好，但在测试集上可能表现更差
-   交叉验证价值：相比单一划分，交叉验证提供更稳定的性能估计
-   模型选择：不同评估指标可能选择不同的最优模型
-   数据质量：真实数据集通常包含复杂的变量关系和数据问题

最佳实践建议

-   始终使用交叉验证：特别是对于小数据集
-   监控过拟合：比较训练和测试性能的差异
-   多指标评估：使用多个评估指标全面评价模型
-   理解数据：进行充分的探索性数据分析

## 本章总结

核心概念回顾

-   预测建模类型：回归分析预测连续值，分类分析预测离散类别
-   过拟合现象：模型在训练数据上表现过好，但在新数据上表现差
-   偏差-方差权衡：模型复杂度需要在偏差和方差之间取得平衡
-   数据划分：训练集用于参数估计，验证集用于模型选择，测试集用于最终评估
-   交叉验证：k折交叉验证提供更稳定的误差估计
-   评估指标：回归问题用MSE、RMSE、$R^2$，分类问题用准确率、精确率、召回率、AUC等
-   模型选择：基于信息准则和业务需求选择合适模型

数据划分最佳实践：

-   在数据分析开始前划分测试集

-   使用随机种子确保结果可重现

-   对于时间序列数据，按时间顺序划分

-   对于不平衡数据，使用分层抽样

交叉验证实施要点：

1\. 选择合适的k值（通常5或10）

2\. 使用分层抽样保持类别比例

3\. 多次运行取平均以减少随机性

4\. 记录每次交叉验证的结果和标准差

模型评估综合策略：

-   使用多个评估指标全面评估

-   考虑业务场景选择重点指标

-   分析错误案例理解模型局限

-   比较基准模型确认改进效果

重要数学公式总结

1.  偏差-方差分解：$E[(Y-\hat{f})^2] = \text{Bias}^2 + \text{Var} + \sigma_\varepsilon^2$
2.  k折交叉验证：$CV(k) = \frac{1}{k}\sum_{i=1}^k \text{Err}(D_{\text{test}}^{(i)})$
3.  回归评估：
    -   $MSE = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$
    -   $R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$
4.  分类评估：
    -   $\text{Precision} = \frac{TP}{TP+FP}$
    -   $\text{Recall} = \frac{TP}{TP+FN}$
    -   $F_1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$
5.  信息准则：
    -   $AIC = 2k - 2\ln(L)$
    -   $BIC = \ln(n)k - 2\ln(L)$

## 与后续章节的联系

本章建立的评估框架将贯穿整个教材：

-   \- 第2-4章：线性模型的评估与选择，重点关注$R^2$、MSE等指标

-   \- 第5-7章：复杂模型的过拟合控制，应用交叉验证和正则化

-   \- 第8章：集成学习的偏差-方差分析，比较不同集成策略

-   \- 第9-10章：支持向量机和神经网络的调优策略，使用验证集选择超参数

理解本章内容是学习后续所有预测模型的基础，良好的评估习惯是构建有效预测模型的关键。在实际应用中，应该根据具体问题选择合适的评估指标和方法，并始终关注模型的泛化能力。