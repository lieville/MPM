{
  "hash": "f1422a323f819baf86089bbfaeff9db5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"13 综合数据分析\"\nauthor: \"李世纪\"\ndate: \"2025-12-03\"\nformat: \n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: true\n    code-overflow: wrap\n    code-tools: true\n---\n\n\n\n## 案例导读\n\n本项目基于模拟的电商用户数据，进行全面的数据分析，包括： - 回归分析：预测用户消费金额 - 分类分析：预测用户购买意向 - 聚类分析：用户分群 - 关联分析：商品购买关联规则\n\n数据说明\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 生成模拟数据\nset.seed(123)\nn <- 1000\n\n# 用户基本信息\nuser_data <- data.frame(\n  user_id = 1:n,\n  age = sample(18:65, n, replace = TRUE),\n  gender = sample(c(\"Male\", \"Female\"), n, replace = TRUE, prob = c(0.48, 0.52)),\n  income = round(rnorm(n, 50000, 15000)),\n  region = sample(c(\"North\", \"South\", \"East\", \"West\"), n, replace = TRUE),\n  days_since_signup = sample(1:365, n, replace = TRUE),\n  page_views = rpois(n, 25),\n  time_on_site = round(rnorm(n, 300, 120)),\n  cart_additions = rpois(n, 5)\n)\n\n# 生成购买行为数据\nuser_data$purchase_amount <- with(user_data, \n  50 + 0.3 * income/1000 + 0.5 * page_views + 0.8 * time_on_site/60 + \n  2 * cart_additions + rnorm(n, 0, 20)\n)\n\nuser_data$made_purchase <- ifelse(user_data$purchase_amount > 120, 1, 0)\n\n# 添加产品类别购买信息 - 增加相关性以产生关联规则\nproducts <- c(\"Electronics\", \"Clothing\", \"Books\", \"Home\", \"Sports\")\nset.seed(123)\nfor(i in 1:length(products)) {\n  product <- products[i]\n  base_prob <- 0.4\n  # 创建产品间的相关性\n  if(i > 1) {\n    # 让某些产品更可能一起购买\n    correlated_prob <- user_data[[paste0(\"bought_\", tolower(products[i-1]))]] * 0.3 + base_prob\n    user_data[[paste0(\"bought_\", tolower(product))]] <- rbinom(n, 1, pmin(correlated_prob, 0.8))\n  } else {\n    user_data[[paste0(\"bought_\", tolower(product))]] <- rbinom(n, 1, base_prob)\n  }\n}\n\nhead(user_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  user_id age gender income region days_since_signup page_views time_on_site\n1       1  48 Female  51762   West                 5         29          173\n2       2  32 Female  45027   West                22         28          450\n3       3  31   Male  54174   West                 4         38          147\n4       4  20 Female  32216  South               352         23          243\n5       5  59   Male  37462  North               131         23          340\n6       6  60 Female  57654  North               231         15          334\n  cart_additions purchase_amount made_purchase bought_electronics\n1              3        57.57759             0                  0\n2              3        59.83742             0                  1\n3              6        64.31744             0                  0\n4             10        94.88951             0                  1\n5              1        24.43966             0                  1\n6              5       114.33971             0                  0\n  bought_clothing bought_books bought_home bought_sports\n1               0            0           0             0\n2               1            1           0             1\n3               0            0           0             0\n4               0            0           1             0\n5               0            0           0             0\n6               0            1           1             1\n```\n\n\n:::\n:::\n\n\n## 13.1 R语言实现\n\n### 13.1.1. 数据探索与预处理\n\n数据概览\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(corrplot)\n\n# 基本统计信息\nsummary(user_data[, c(\"age\", \"income\", \"page_views\", \"time_on_site\", \"purchase_amount\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      age            income         page_views     time_on_site  \n Min.   :18.00   Min.   :  4282   Min.   :11.00   Min.   :-83.0  \n 1st Qu.:29.00   1st Qu.: 40201   1st Qu.:21.00   1st Qu.:219.8  \n Median :42.00   Median : 49943   Median :25.00   Median :299.0  \n Mean   :41.39   Mean   : 50209   Mean   :24.92   Mean   :299.7  \n 3rd Qu.:53.00   3rd Qu.: 60887   3rd Qu.:28.00   3rd Qu.:376.2  \n Max.   :65.00   Max.   :100856   Max.   :42.00   Max.   :688.0  \n purchase_amount  \n Min.   :  9.555  \n 1st Qu.: 76.051  \n Median : 91.131  \n Mean   : 90.966  \n 3rd Qu.:105.509  \n Max.   :153.144  \n```\n\n\n:::\n\n```{.r .cell-code}\n# 缺失值检查\nsapply(user_data, function(x) sum(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           user_id                age             gender             income \n                 0                  0                  0                  0 \n            region  days_since_signup         page_views       time_on_site \n                 0                  0                  0                  0 \n    cart_additions    purchase_amount      made_purchase bought_electronics \n                 0                  0                  0                  0 \n   bought_clothing       bought_books        bought_home      bought_sports \n                 0                  0                  0                  0 \n```\n\n\n:::\n:::\n\n\n数据可视化\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 数值变量分布\np1 <- ggplot(user_data, aes(x = purchase_amount)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"购买金额分布\")\n\np2 <- ggplot(user_data, aes(x = factor(made_purchase), fill = factor(made_purchase))) +\n  geom_bar() +\n  labs(title = \"购买行为分布\", x = \"是否购买\")\n\np3 <- ggplot(user_data, aes(x = age, y = purchase_amount, color = gender)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"年龄与购买金额关系\")\n\nlibrary(patchwork)\np1 / p2 / p3\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-data-visualization-1.png)\n:::\n:::\n\n\n### 13.1.2. 回归分析：预测购买金额\n\n线性回归模型\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# 准备数据\nreg_data <- user_data %>% \n  select(age, income, page_views, time_on_site, cart_additions, purchase_amount) %>%\n  na.omit()\n\n# 数据分割\nset.seed(123)\ntrain_index <- createDataPartition(reg_data$purchase_amount, p = 0.7, list = FALSE)\ntrain_reg <- reg_data[train_index, ]\ntest_reg <- reg_data[-train_index, ]\n\n# 训练线性回归模型\nlm_model <- lm(purchase_amount ~ ., data = train_reg)\nsummary(lm_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = purchase_amount ~ ., data = train_reg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-66.576 -12.853  -0.106  13.819  67.749 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.111e+01  5.704e+00   8.961  < 2e-16 ***\nage            8.216e-04  5.349e-02   0.015  0.98775    \nincome         2.969e-04  5.022e-05   5.913 5.28e-09 ***\npage_views     2.720e-01  1.496e-01   1.818  0.06954 .  \ntime_on_site   1.635e-02  6.067e-03   2.695  0.00721 ** \ncart_additions 2.638e+00  3.326e-01   7.933 8.57e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.32 on 694 degrees of freedom\nMultiple R-squared:  0.1368,\tAdjusted R-squared:  0.1305 \nF-statistic: 21.99 on 5 and 694 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# 预测\npredictions_lm <- predict(lm_model, newdata = test_reg)\n\n# 模型评估\nreg_metrics <- data.frame(\n  RMSE = RMSE(predictions_lm, test_reg$purchase_amount),\n  MAE = MAE(predictions_lm, test_reg$purchase_amount),\n  R2 = R2(predictions_lm, test_reg$purchase_amount)\n)\nprint(reg_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      RMSE      MAE         R2\n1 21.72114 17.54768 0.07424787\n```\n\n\n:::\n:::\n\n\n回归结果可视化\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 预测 vs 实际值\nresults_df <- data.frame(\n  Actual = test_reg$purchase_amount,\n  Predicted = predictions_lm\n)\n\nggplot(results_df, aes(x = Actual, y = Predicted)) +\n  geom_point(alpha = 0.6, color = \"steelblue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"线性回归：预测值 vs 实际值\",\n       subtitle = paste(\"R² =\", round(reg_metrics$R2, 3))) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-regression-viz-1.png)\n:::\n:::\n\n\n###13.1.3. 分类分析：预测购买意向\n\n逻辑回归分类\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 准备分类数据 - 确保因子水平一致\nclass_data <- user_data %>% \n  select(age, income, page_views, time_on_site, cart_additions, made_purchase) %>%\n  mutate(made_purchase = factor(made_purchase, levels = c(0, 1), labels = c(\"No\", \"Yes\"))) %>%\n  na.omit()\n\n# 数据分割\nset.seed(123)\ntrain_index_class <- createDataPartition(class_data$made_purchase, p = 0.7, list = FALSE)\ntrain_class <- class_data[train_index_class, ]\ntest_class <- class_data[-train_index_class, ]\n\n# 训练逻辑回归模型\nlogit_model <- glm(made_purchase ~ ., data = train_class, family = binomial)\nsummary(logit_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = made_purchase ~ ., family = binomial, data = train_class)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -7.571e+00  1.118e+00  -6.771 1.28e-11 ***\nage             1.361e-03  1.002e-02   0.136   0.8920    \nincome          2.353e-05  9.733e-06   2.418   0.0156 *  \npage_views      5.748e-02  2.661e-02   2.160   0.0308 *  \ntime_on_site    2.964e-03  1.157e-03   2.562   0.0104 *  \ncart_additions  2.789e-01  6.152e-02   4.533 5.82e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 419.09  on 700  degrees of freedom\nResidual deviance: 381.44  on 695  degrees of freedom\nAIC: 393.44\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\n# 预测概率\nprob_predictions <- predict(logit_model, newdata = test_class, type = \"response\")\nclass_predictions <- ifelse(prob_predictions > 0.5, \"Yes\", \"No\")\nclass_predictions <- factor(class_predictions, levels = c(\"No\", \"Yes\"))\n\n# 模型评估 - 修复因子水平问题\nconf_matrix <- confusionMatrix(class_predictions, test_class$made_purchase, positive = \"Yes\")\nprint(conf_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  273  26\n       Yes   0   0\n                                          \n               Accuracy : 0.913           \n                 95% CI : (0.8752, 0.9424)\n    No Information Rate : 0.913           \n    P-Value [Acc > NIR] : 0.552           \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : 9.443e-07       \n                                          \n            Sensitivity : 0.00000         \n            Specificity : 1.00000         \n         Pos Pred Value :     NaN         \n         Neg Pred Value : 0.91304         \n             Prevalence : 0.08696         \n         Detection Rate : 0.00000         \n   Detection Prevalence : 0.00000         \n      Balanced Accuracy : 0.50000         \n                                          \n       'Positive' Class : Yes             \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# 绘制ROC曲线\nlibrary(pROC)\nroc_curve <- roc(as.numeric(test_class$made_purchase) - 1, prob_predictions)\nplot(roc_curve, main = \"逻辑回归ROC曲线\")\nauc_value <- auc(roc_curve)\nlegend(\"bottomright\", legend = paste(\"AUC =\", round(auc_value, 3)))\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-classification-1.png)\n:::\n:::\n\n\n随机森林分类\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\n\n# 确保训练数据和测试数据的因子水平一致\ntrain_class$made_purchase <- factor(train_class$made_purchase, levels = c(\"No\", \"Yes\"))\ntest_class$made_purchase <- factor(test_class$made_purchase, levels = c(\"No\", \"Yes\"))\n\n# 训练随机森林\nrf_model <- randomForest(made_purchase ~ ., data = train_class, ntree = 100)\n\n# 预测\nrf_predictions <- predict(rf_model, newdata = test_class)\n\n# 评估 - 确保因子水平一致\nrf_conf_matrix <- confusionMatrix(rf_predictions, test_class$made_purchase, positive = \"Yes\")\nprint(rf_conf_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  271  26\n       Yes   2   0\n                                          \n               Accuracy : 0.9064          \n                 95% CI : (0.8675, 0.9369)\n    No Information Rate : 0.913           \n    P-Value [Acc > NIR] : 0.7033          \n                                          \n                  Kappa : -0.0126         \n                                          \n Mcnemar's Test P-Value : 1.383e-05       \n                                          \n            Sensitivity : 0.000000        \n            Specificity : 0.992674        \n         Pos Pred Value : 0.000000        \n         Neg Pred Value : 0.912458        \n             Prevalence : 0.086957        \n         Detection Rate : 0.000000        \n   Detection Prevalence : 0.006689        \n      Balanced Accuracy : 0.496337        \n                                          \n       'Positive' Class : Yes             \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# 变量重要性\nvarImpPlot(rf_model, main = \"随机森林变量重要性\")\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-random-forest-1.png)\n:::\n\n```{.r .cell-code}\n# 随机森林ROC曲线\nrf_prob <- predict(rf_model, newdata = test_class, type = \"prob\")[, \"Yes\"]\nrf_roc <- roc(as.numeric(test_class$made_purchase) - 1, rf_prob)\nplot(rf_roc, main = \"随机森林ROC曲线\")\nrf_auc <- auc(rf_roc)\nlegend(\"bottomright\", legend = paste(\"AUC =\", round(rf_auc, 3)))\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-random-forest-2.png)\n:::\n:::\n\n\n分类模型比较\n\n### 13.1.4. 聚类分析：用户分群\n\nK-means聚类\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 准备聚类数据\ncluster_data <- user_data %>%\n  select(age, income, page_views, time_on_site, cart_additions) %>%\n  scale()  # 标准化\n\n# 确定最佳聚类数\nwss <- sapply(1:10, function(k){kmeans(cluster_data, k, nstart = 25)$tot.withinss})\n\nggplot(data.frame(k = 1:10, wss = wss), aes(x = k, y = wss)) +\n  geom_line() + geom_point() +\n  labs(title = \"肘部法则确定最佳聚类数\", x = \"聚类数\", y = \"组内平方和\")\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-clustering-1.png)\n:::\n\n```{.r .cell-code}\n# 执行K-means聚类\nset.seed(123)\nkmeans_result <- kmeans(cluster_data, centers = 4, nstart = 25)\n\n# 添加聚类标签\nuser_data$cluster <- as.factor(kmeans_result$cluster)\n\n# 聚类结果可视化\nlibrary(factoextra)\nfviz_cluster(kmeans_result, data = cluster_data, \n             palette = c(\"#2E9FDF\", \"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             geom = \"point\",\n             ellipse.type = \"convex\",\n             ggtheme = theme_bw())\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-clustering-2.png)\n:::\n:::\n\n\n聚类分析\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 聚类特征分析\ncluster_summary <- user_data %>%\n  group_by(cluster) %>%\n  summarise(\n    n = n(),\n    avg_age = mean(age),\n    avg_income = mean(income),\n    avg_page_views = mean(page_views),\n    avg_time = mean(time_on_site),\n    purchase_rate = mean(made_purchase),\n    avg_purchase = mean(purchase_amount)\n  )\n\nprint(cluster_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 8\n  cluster     n avg_age avg_income avg_page_views avg_time purchase_rate\n  <fct>   <int>   <dbl>      <dbl>          <dbl>    <dbl>         <dbl>\n1 1         292    53.9     50802.           23.1     376.        0.0822\n2 2         257    30.1     46562.           22.3     304.        0.0506\n3 3         203    33.8     47358.           25.6     293.        0.133 \n4 4         248    44.6     55625.           29.2     210.        0.0968\n# ℹ 1 more variable: avg_purchase <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# 聚类特征可视化 - 修复版本\ncluster_features <- user_data %>%\n  select(cluster, age, income, page_views, time_on_site, purchase_amount)\n\n# 使用tidyr::pivot_longer\ncluster_features_long <- tidyr::pivot_longer(\n  cluster_features,\n  cols = -cluster,\n  names_to = \"Feature\",\n  values_to = \"Value\"\n)\n\nggplot(cluster_features_long, aes(x = cluster, y = Value, fill = cluster)) +\n  geom_boxplot() +\n  facet_wrap(~ Feature, scales = \"free_y\") +\n  labs(title = \"各聚类群体特征分布\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-cluster-analysis-1.png)\n:::\n:::\n\n\n### 13.1.5. 关联分析：商品购买关联规则\n\nApriori算法\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arules)\n\n# 准备关联分析数据 - 只包含产品购买列\ntransaction_data <- user_data %>%\n  select(starts_with(\"bought_\"))\n\n# 转换为事务数据\ntransactions <- as(transaction_data, \"transactions\")\n\n# 查看事务数据概览\nsummary(transactions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntransactions as itemMatrix in sparse format with\n 1000 rows (elements/itemsets/transactions) and\n 5 columns (items) and a density of 1 \n\nmost frequent items:\nbought_electronics=[0,1]    bought_clothing=[0,1]       bought_books=[0,1] \n                    1000                     1000                     1000 \n       bought_home=[0,1]      bought_sports=[0,1]                  (Other) \n                    1000                     1000                        0 \n\nelement (itemset/transaction) length distribution:\nsizes\n   5 \n1000 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      5       5       5       5       5       5 \n\nincludes extended item information - examples:\n                    labels          variables levels\n1 bought_electronics=[0,1] bought_electronics  [0,1]\n2    bought_clothing=[0,1]    bought_clothing  [0,1]\n3       bought_books=[0,1]       bought_books  [0,1]\n\nincludes extended transaction information - examples:\n  transactionID\n1             1\n2             2\n3             3\n```\n\n\n:::\n\n```{.r .cell-code}\n# 查看产品频率\nitemFrequency <- itemFrequency(transactions)\nprint(\"产品购买频率:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"产品购买频率:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(sort(itemFrequency, decreasing = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nbought_electronics=[0,1]    bought_clothing=[0,1]       bought_books=[0,1] \n                       1                        1                        1 \n       bought_home=[0,1]      bought_sports=[0,1] \n                       1                        1 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 使用更宽松的参数挖掘关联规则\nrules <- apriori(transactions, \n                 parameter = list(support = 0.05,  # 降低支持度阈值\n                                 confidence = 0.3,  # 降低置信度阈值\n                                 minlen = 2,        # 最小规则长度\n                                 maxlen = 4))       # 最大规则长度\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n        0.3    0.1    1 none FALSE            TRUE       5    0.05      2\n maxlen target  ext\n      4  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 50 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[5 item(s), 1000 transaction(s)] done [0.00s].\nsorting and recoding items ... [5 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n done [0.00s].\nwriting ... [70 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n```\n\n\n:::\n\n```{.r .cell-code}\n# 规则摘要\ncat(\"找到的规则数量:\", length(rules), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n找到的规则数量: 70 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(rules)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nset of 70 rules\n\nrule length distribution (lhs + rhs):sizes\n 2  3  4 \n20 30 20 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      2       2       3       3       4       4 \n\nsummary of quality measures:\n    support    confidence    coverage      lift       count     \n Min.   :1   Min.   :1    Min.   :1   Min.   :1   Min.   :1000  \n 1st Qu.:1   1st Qu.:1    1st Qu.:1   1st Qu.:1   1st Qu.:1000  \n Median :1   Median :1    Median :1   Median :1   Median :1000  \n Mean   :1   Mean   :1    Mean   :1   Mean   :1   Mean   :1000  \n 3rd Qu.:1   3rd Qu.:1    3rd Qu.:1   3rd Qu.:1   3rd Qu.:1000  \n Max.   :1   Max.   :1    Max.   :1   Max.   :1   Max.   :1000  \n\nmining info:\n         data ntransactions support confidence\n transactions          1000    0.05        0.3\n                                                                                                     call\n apriori(data = transactions, parameter = list(support = 0.05, confidence = 0.3, minlen = 2, maxlen = 4))\n```\n\n\n:::\n\n```{.r .cell-code}\n# 查看规则\nif(length(rules) > 0) {\n  # 按提升度排序\n  rules_sorted <- sort(rules, by = \"lift\", decreasing = TRUE)\n  cat(\"\\n前10条关联规则 (按提升度排序):\\n\")\n  inspect(head(rules_sorted, 10))\n} else {\n  cat(\"没有找到关联规则，请进一步降低阈值参数\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n前10条关联规则 (按提升度排序):\n     lhs                           rhs                        support\n[1]  {bought_electronics=[0,1]} => {bought_clothing=[0,1]}    1      \n[2]  {bought_clothing=[0,1]}    => {bought_electronics=[0,1]} 1      \n[3]  {bought_electronics=[0,1]} => {bought_books=[0,1]}       1      \n[4]  {bought_books=[0,1]}       => {bought_electronics=[0,1]} 1      \n[5]  {bought_electronics=[0,1]} => {bought_home=[0,1]}        1      \n[6]  {bought_home=[0,1]}        => {bought_electronics=[0,1]} 1      \n[7]  {bought_electronics=[0,1]} => {bought_sports=[0,1]}      1      \n[8]  {bought_sports=[0,1]}      => {bought_electronics=[0,1]} 1      \n[9]  {bought_clothing=[0,1]}    => {bought_books=[0,1]}       1      \n[10] {bought_books=[0,1]}       => {bought_clothing=[0,1]}    1      \n     confidence coverage lift count\n[1]  1          1        1    1000 \n[2]  1          1        1    1000 \n[3]  1          1        1    1000 \n[4]  1          1        1    1000 \n[5]  1          1        1    1000 \n[6]  1          1        1    1000 \n[7]  1          1        1    1000 \n[8]  1          1        1    1000 \n[9]  1          1        1    1000 \n[10] 1          1        1    1000 \n```\n\n\n:::\n:::\n\n\n关联规则可视化\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arulesViz)\n\nif(length(rules) > 0) {\n  # 选择前20条规则进行可视化\n  rules_for_plot <- head(sort(rules, by = \"lift\"), min(20, length(rules)))\n  \n  # 散点图\n  plot1 <- plot(rules_for_plot, method = \"scatter\", \n               main = \"关联规则散点图 (支持度 vs 置信度)\")\n  \n  # 矩阵图\n  plot2 <- plot(rules_for_plot, method = \"matrix\", \n               main = \"关联规则矩阵图\")\n  \n  # 分组图\n  plot3 <- plot(rules_for_plot, method = \"grouped\",\n               main = \"关联规则分组图\")\n  \n  # 显示图形\n  plot1\n  plot2\n  plot3\n  \n} else {\n  cat(\"没有足够的规则进行可视化\\n\")\n  \n  # 显示产品共现矩阵作为替代\n  item_matrix <- crossTable(transactions)\n  corrplot(item_matrix, method = \"color\", \n           title = \"产品共现热图\",\n           mar = c(0,0,2,0))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nItemsets in Antecedent (LHS)\n[1] \"{bought_electronics=[0,1]}\" \"{bought_clothing=[0,1]}\"   \n[3] \"{bought_books=[0,1]}\"       \"{bought_home=[0,1]}\"       \n[5] \"{bought_sports=[0,1]}\"     \nItemsets in Consequent (RHS)\n[1] \"{bought_sports=[0,1]}\"      \"{bought_home=[0,1]}\"       \n[3] \"{bought_books=[0,1]}\"       \"{bought_electronics=[0,1]}\"\n[5] \"{bought_clothing=[0,1]}\"   \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAvailable control parameters (with default values):\nk\t =  20\naggr.fun\t =  function (x, ...)  UseMethod(\"mean\")\nrhs_max\t =  10\nlhs_label_items\t =  2\ncol\t =  c(\"#EE0000FF\", \"#EEEEEEFF\")\ngroups\t =  NULL\nengine\t =  ggplot2\nverbose\t =  FALSE\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/r-association-viz-1.png)\n:::\n:::\n\n\n## 13.2 Python实现\n\n数据准备\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 设置中文字体\nplt.rcParams['font.sans-serif'] = ['SimHei']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 生成相同的模拟数据\nnp.random.seed(123)\nn = 1000\n\npython_user_data = pd.DataFrame({\n    'user_id': range(1, n+1),\n    'age': np.random.randint(18, 66, n),\n    'gender': np.random.choice(['Male', 'Female'], n, p=[0.48, 0.52]),\n    'income': np.random.normal(50000, 15000, n).round(),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], n),\n    'days_since_signup': np.random.randint(1, 366, n),\n    'page_views': np.random.poisson(25, n),\n    'time_on_site': np.random.normal(300, 120, n).round(),\n    'cart_additions': np.random.poisson(5, n)\n})\n\n# 生成购买行为\npython_user_data['purchase_amount'] = (\n    50 + 0.3 * python_user_data['income']/1000 + \n    0.5 * python_user_data['page_views'] + \n    0.8 * python_user_data['time_on_site']/60 + \n    2 * python_user_data['cart_additions'] + \n    np.random.normal(0, 20, n)\n)\n\npython_user_data['made_purchase'] = (python_user_data['purchase_amount'] > 120).astype(int)\n\n# 添加产品类别 - 创建相关性\nproducts = ['electronics', 'clothing', 'books', 'home', 'sports']\nbase_prob = 0.4\n\npython_user_data['bought_electronics'] = np.random.binomial(1, base_prob, n)\n\n# 创建相关产品\nfor i in range(1, len(products)):\n    prev_product = f'bought_{products[i-1]}'\n    current_product = f'bought_{products[i]}'\n    correlated_prob = python_user_data[prev_product] * 0.3 + base_prob\n    python_user_data[current_product] = np.random.binomial(1, np.minimum(correlated_prob, 0.8), n)\n\nprint(\"Python数据概览:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPython数据概览:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(python_user_data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user_id  age  gender  ...  bought_books bought_home  bought_sports\n0        1   63    Male  ...             0           0              1\n1        2   20  Female  ...             1           1              1\n2        3   46  Female  ...             1           1              1\n3        4   52  Female  ...             1           1              0\n4        5   56  Female  ...             1           1              1\n\n[5 rows x 16 columns]\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(f\"\\n数据形状: {python_user_data.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n数据形状: (1000, 16)\n```\n\n\n:::\n\n```{.python .cell-code}\n# 产品购买频率\nprint(\"\\n产品购买频率:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n产品购买频率:\n```\n\n\n:::\n\n```{.python .cell-code}\nfor product in products:\n    col_name = f'bought_{product}'\n    freq = python_user_data[col_name].mean()\n    print(f\"{product}: {freq:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nelectronics: 0.411\nclothing: 0.522\nbooks: 0.553\nhome: 0.554\nsports: 0.565\n```\n\n\n:::\n:::\n\n\n### 13.2.2 Python回归分析\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# 准备回归数据\nreg_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']\nX_reg = python_user_data[reg_features]\ny_reg = python_user_data['purchase_amount']\n\n# 数据分割\nX_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n    X_reg, y_reg, test_size=0.3, random_state=123)\n\n# 线性回归\nlr_model = LinearRegression()\nlr_model.fit(X_train_reg, y_train_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinearRegression()\n```\n\n\n:::\n\n```{.python .cell-code}\ny_pred_lr = lr_model.predict(X_test_reg)\n\n# 随机森林回归\nrf_reg_model = RandomForestRegressor(n_estimators=100, random_state=123)\nrf_reg_model.fit(X_train_reg, y_train_reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandomForestRegressor(random_state=123)\n```\n\n\n:::\n\n```{.python .cell-code}\ny_pred_rf = rf_reg_model.predict(X_test_reg)\n\n# 模型评估\ndef evaluate_regression(y_true, y_pred, model_name):\n    mse = mean_squared_error(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    \n    results = {\n        'Model': model_name,\n        'RMSE': np.sqrt(mse),\n        'MAE': mae,\n        'R2': r2\n    }\n    return results\n\nlr_metrics = evaluate_regression(y_test_reg, y_pred_lr, 'Linear Regression')\nrf_metrics = evaluate_regression(y_test_reg, y_pred_rf, 'Random Forest')\n\nregression_results = pd.DataFrame([lr_metrics, rf_metrics])\nprint(\"回归模型性能比较:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n回归模型性能比较:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(regression_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               Model       RMSE        MAE        R2\n0  Linear Regression  19.572048  15.711942  0.040879\n1      Random Forest  20.593340  16.873056 -0.061829\n```\n\n\n:::\n\n```{.python .cell-code}\n# 可视化回归结果\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# 线性回归结果\nax1.scatter(y_test_reg, y_pred_lr, alpha=0.6)\nax1.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\nax1.set_xlabel('实际值')\nax1.set_ylabel('预测值')\nax1.set_title(f'线性回归 (R² = {lr_metrics[\"R2\"]:.3f})')\n\n# 随机森林结果\nax2.scatter(y_test_reg, y_pred_rf, alpha=0.6)\nax2.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\nax2.set_xlabel('实际值')\nax2.set_ylabel('预测值')\nax2.set_title(f'随机森林回归 (R² = {rf_metrics[\"R2\"]:.3f})')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/python-regression-1.png)\n:::\n:::\n\n\n### 13.2.3 Python分类分析\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n\n# 准备分类数据\nclass_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']\nX_class = python_user_data[class_features]\ny_class = python_user_data['made_purchase']\n\n# 数据分割\nX_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n    X_class, y_class, test_size=0.3, random_state=123, stratify=y_class)\n\n# 逻辑回归\nlogit_model = LogisticRegression(random_state=123)\nlogit_model.fit(X_train_class, y_train_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLogisticRegression(random_state=123)\n```\n\n\n:::\n\n```{.python .cell-code}\ny_pred_logit = logit_model.predict(X_test_class)\ny_pred_logit_proba = logit_model.predict_proba(X_test_class)[:, 1]\n\n# 随机森林分类\nrf_class_model = RandomForestClassifier(n_estimators=100, random_state=123)\nrf_class_model.fit(X_train_class, y_train_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandomForestClassifier(random_state=123)\n```\n\n\n:::\n\n```{.python .cell-code}\ny_pred_rf_class = rf_class_model.predict(X_test_class)\ny_pred_rf_proba = rf_class_model.predict_proba(X_test_class)[:, 1]\n\n# 模型评估\nprint(\"=\" * 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n==================================================\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"逻辑回归性能:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n逻辑回归性能:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"=\" * 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n==================================================\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(classification_report(y_test_class, y_pred_logit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              precision    recall  f1-score   support\n\n           0       0.90      1.00      0.95       271\n           1       0.00      0.00      0.00        29\n\n    accuracy                           0.90       300\n   macro avg       0.45      0.50      0.47       300\nweighted avg       0.82      0.90      0.86       300\n```\n\n\n:::\n\n```{.python .cell-code}\nlogit_accuracy = accuracy_score(y_test_class, y_pred_logit)\nlogit_auc = roc_auc_score(y_test_class, y_pred_logit_proba)\nprint(f\"准确率: {logit_accuracy:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n准确率: 0.903\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(f\"AUC: {logit_auc:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAUC: 0.461\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"\\n\" + \"=\" * 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n==================================================\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"随机森林性能:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n随机森林性能:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"=\" * 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n==================================================\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(classification_report(y_test_class, y_pred_rf_class))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              precision    recall  f1-score   support\n\n           0       0.90      1.00      0.95       271\n           1       0.00      0.00      0.00        29\n\n    accuracy                           0.90       300\n   macro avg       0.45      0.50      0.47       300\nweighted avg       0.82      0.90      0.86       300\n```\n\n\n:::\n\n```{.python .cell-code}\nrf_accuracy = accuracy_score(y_test_class, y_pred_rf_class)\nrf_auc = roc_auc_score(y_test_class, y_pred_rf_proba)\nprint(f\"准确率: {rf_accuracy:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n准确率: 0.903\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(f\"AUC: {rf_auc:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAUC: 0.557\n```\n\n\n:::\n\n```{.python .cell-code}\n# 特征重要性\nfeature_importance = pd.DataFrame({\n    'feature': class_features,\n    'importance': rf_class_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\n随机森林特征重要性:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n随机森林特征重要性:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(feature_importance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          feature  importance\n3    time_on_site    0.273365\n1          income    0.270106\n0             age    0.189313\n2      page_views    0.160267\n4  cart_additions    0.106949\n```\n\n\n:::\n\n```{.python .cell-code}\n# ROC曲线比较\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# 逻辑回归ROC\nfpr_lr, tpr_lr, _ = roc_curve(y_test_class, y_pred_logit_proba)\nax1.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {logit_auc:.3f})')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFD3AAD0>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.plot([0, 1], [0, 1], 'k--')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFD3AC10>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_xlabel('False Positive Rate')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 0, 'False Positive Rate')\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_ylabel('True Positive Rate')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0, 0.5, 'True Positive Rate')\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_title('逻辑回归ROC曲线')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, '逻辑回归ROC曲线')\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.legend()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x0000014CFF4CDA90>\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.grid(True)\n\n# 随机森林ROC\nfpr_rf, tpr_rf, _ = roc_curve(y_test_class, y_pred_rf_proba)\nax2.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.3f})')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFD3B750>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.plot([0, 1], [0, 1], 'k--')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFD3B890>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_xlabel('False Positive Rate')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 0, 'False Positive Rate')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_ylabel('True Positive Rate')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0, 0.5, 'True Positive Rate')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_title('随机森林ROC曲线')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, '随机森林ROC曲线')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.legend()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x0000014CFFD3B9D0>\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.grid(True)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/python-classification-3.png)\n:::\n\n```{.python .cell-code}\n# 模型比较\ncomparison_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest'],\n    'Accuracy': [logit_accuracy, rf_accuracy],\n    'AUC': [logit_auc, rf_auc]\n})\n\nprint(\"\\n模型性能比较:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n模型性能比较:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(comparison_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Model  Accuracy       AUC\n0  Logistic Regression  0.903333  0.461000\n1        Random Forest  0.903333  0.557196\n```\n\n\n:::\n:::\n\n\n### 13.2.4 Python聚类分析\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\n\n# 准备聚类数据\ncluster_features = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions']\nX_cluster = python_user_data[cluster_features]\n\n# 数据标准化\nscaler = StandardScaler()\nX_cluster_scaled = scaler.fit_transform(X_cluster)\n\n# 寻找最佳聚类数\nwcss = []\nsilhouette_scores = []\nk_range = range(2, 11)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=123, n_init=10)\n    kmeans.fit(X_cluster_scaled)\n    wcss.append(kmeans.inertia_)\n    silhouette_scores.append(silhouette_score(X_cluster_scaled, kmeans.labels_))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  File \"C:\\Data\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n    cpu_info = subprocess.run(\n        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n        capture_output=True,\n        text=True,\n    )\n  File \"C:\\Data\\Anaconda\\Lib\\subprocess.py\", line 554, in run\n    with Popen(*popenargs, **kwargs) as process:\n         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Data\\Anaconda\\Lib\\subprocess.py\", line 1039, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n                        pass_fds, cwd, env,\n                        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n                        gid, gids, uid, umask,\n                        ^^^^^^^^^^^^^^^^^^^^^^\n                        start_new_session, process_group)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Data\\Anaconda\\Lib\\subprocess.py\", line 1554, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n                             # no special security\n                             ^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n                             cwd,\n                             ^^^^\n                             startupinfo)\n                             ^^^^^^^^^^^^\nKMeans(n_clusters=2, n_init=10, random_state=123)\nKMeans(n_clusters=3, n_init=10, random_state=123)\nKMeans(n_clusters=4, n_init=10, random_state=123)\nKMeans(n_clusters=5, n_init=10, random_state=123)\nKMeans(n_clusters=6, n_init=10, random_state=123)\nKMeans(n_clusters=7, n_init=10, random_state=123)\nKMeans(n_init=10, random_state=123)\nKMeans(n_clusters=9, n_init=10, random_state=123)\nKMeans(n_clusters=10, n_init=10, random_state=123)\n```\n\n\n:::\n\n```{.python .cell-code}\n# 肘部法则图\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\nax1.plot(k_range, wcss, 'bo-')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFF625D0>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_xlabel('聚类数')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 0, '聚类数')\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_ylabel('WCSS')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0, 0.5, 'WCSS')\n```\n\n\n:::\n\n```{.python .cell-code}\nax1.set_title('肘部法则')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, '肘部法则')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.plot(k_range, silhouette_scores, 'ro-')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x0000014CFFF62710>]\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_xlabel('聚类数')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 0, '聚类数')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_ylabel('轮廓系数')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0, 0.5, '轮廓系数')\n```\n\n\n:::\n\n```{.python .cell-code}\nax2.set_title('轮廓系数')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, '轮廓系数')\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/python-clustering-5.png)\n:::\n\n```{.python .cell-code}\n# 执行K-means聚类\nkmeans_final = KMeans(n_clusters=4, random_state=123, n_init=10)\npython_user_data['cluster'] = kmeans_final.fit_predict(X_cluster_scaled)\n\n# 聚类分析\ncluster_analysis = python_user_data.groupby('cluster').agg({\n    'age': 'mean',\n    'income': 'mean',\n    'page_views': 'mean',\n    'time_on_site': 'mean',\n    'cart_additions': 'mean',\n    'made_purchase': 'mean',\n    'purchase_amount': 'mean',\n    'user_id': 'count'\n}).rename(columns={'user_id': 'count'})\n\nprint(\"聚类分析结果:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n聚类分析结果:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(cluster_analysis.round(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           age    income  page_views  ...  made_purchase  purchase_amount  count\ncluster                               ...                                       \n0        27.81  53227.80       26.55  ...           0.12            93.78    266\n1        41.83  37788.28       21.12  ...           0.06            84.25    242\n2        55.03  55961.32       25.49  ...           0.11            95.40    266\n3        44.12  54015.27       27.58  ...           0.11            96.53    226\n\n[4 rows x 8 columns]\n```\n\n\n:::\n\n```{.python .cell-code}\n# 聚类可视化\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfeatures_to_plot = ['age', 'income', 'page_views', 'time_on_site', 'cart_additions', 'purchase_amount']\n\nfor i, feature in enumerate(features_to_plot):\n    row, col = i // 3, i % 3\n    python_user_data.boxplot(column=feature, by='cluster', ax=axes[row, col])\n    axes[row, col].set_title(f'{feature} by Cluster')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Axes: title={'center': 'age'}, xlabel='cluster'>\nText(0.5, 1.0, 'age by Cluster')\n<Axes: title={'center': 'income'}, xlabel='cluster'>\nText(0.5, 1.0, 'income by Cluster')\n<Axes: title={'center': 'page_views'}, xlabel='cluster'>\nText(0.5, 1.0, 'page_views by Cluster')\n<Axes: title={'center': 'time_on_site'}, xlabel='cluster'>\nText(0.5, 1.0, 'time_on_site by Cluster')\n<Axes: title={'center': 'cart_additions'}, xlabel='cluster'>\nText(0.5, 1.0, 'cart_additions by Cluster')\n<Axes: title={'center': 'purchase_amount'}, xlabel='cluster'>\nText(0.5, 1.0, 'purchase_amount by Cluster')\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.suptitle('各聚类群体特征分布')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 0.98, '各聚类群体特征分布')\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/python-clustering-6.png)\n:::\n:::\n\n\n### 13.2.5 Python关联分析\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# 准备关联分析数据\nassociation_data = python_user_data[[f'bought_{product}' for product in products]]\n\n# 查看数据概览\nprint(\"关联分析数据概览:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n关联分析数据概览:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(association_data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   bought_electronics  bought_clothing  ...  bought_home  bought_sports\n0                   1                1  ...            0              1\n1                   1                1  ...            1              1\n2                   0                1  ...            1              1\n3                   1                0  ...            1              0\n4                   1                1  ...            1              1\n\n[5 rows x 5 columns]\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(f\"\\n各产品购买率:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n各产品购买率:\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(association_data.mean())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nbought_electronics    0.411\nbought_clothing       0.522\nbought_books          0.553\nbought_home           0.554\nbought_sports         0.565\ndtype: float64\n```\n\n\n:::\n\n```{.python .cell-code}\n# 挖掘频繁项集 - 使用更宽松的参数\nfrequent_itemsets = apriori(association_data, \n                           min_support=0.05,  # 降低支持度\n                           use_colnames=True,\n                           max_len=4)         # 限制最大项集大小\n\nprint(f\"\\n找到的频繁项集数量: {len(frequent_itemsets)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n找到的频繁项集数量: 30\n```\n\n\n:::\n\n```{.python .cell-code}\nif len(frequent_itemsets) > 0:\n    # 生成关联规则\n    rules_python = association_rules(frequent_itemsets, \n                                   metric=\"confidence\", \n                                   min_threshold=0.3)  # 降低置信度\n    \n    print(f\"生成的关联规则数量: {len(rules_python)}\")\n    \n    if len(rules_python) > 0:\n        # 显示前10条规则\n        rules_display = rules_python.sort_values('lift', ascending=False).head(10)\n        print(\"\\n前10条关联规则 (按提升度排序):\")\n        for idx, rule in rules_display.iterrows():\n            antecedents = list(rule['antecedents'])\n            consequents = list(rule['consequents'])\n            print(f\"规则: {antecedents} -> {consequents}\")\n            print(f\"  支持度: {rule['support']:.3f}, 置信度: {rule['confidence']:.3f}, 提升度: {rule['lift']:.3f}\")\n            print()\n    else:\n        print(\"没有生成关联规则，请进一步降低阈值\")\nelse:\n    print(\"没有找到频繁项集，请降低支持度阈值\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n生成的关联规则数量: 137\n\n前10条关联规则 (按提升度排序):\n规则: ['bought_home', 'bought_clothing'] -> ['bought_electronics', 'bought_books']\n  支持度: 0.146, 置信度: 0.465, 提升度: 1.802\n\n规则: ['bought_electronics', 'bought_books'] -> ['bought_home', 'bought_clothing']\n  支持度: 0.146, 置信度: 0.566, 提升度: 1.802\n\n规则: ['bought_clothing', 'bought_sports'] -> ['bought_electronics', 'bought_home']\n  支持度: 0.128, 置信度: 0.416, 提升度: 1.768\n\n规则: ['bought_electronics', 'bought_home'] -> ['bought_clothing', 'bought_sports']\n  支持度: 0.128, 置信度: 0.545, 提升度: 1.768\n\n规则: ['bought_electronics', 'bought_books'] -> ['bought_clothing', 'bought_sports']\n  支持度: 0.138, 置信度: 0.535, 提升度: 1.737\n\n规则: ['bought_clothing', 'bought_sports'] -> ['bought_electronics', 'bought_books']\n  支持度: 0.138, 置信度: 0.448, 提升度: 1.737\n\n规则: ['bought_electronics', 'bought_home'] -> ['bought_books', 'bought_clothing']\n  支持度: 0.146, 置信度: 0.621, 提升度: 1.721\n\n规则: ['bought_books', 'bought_clothing'] -> ['bought_electronics', 'bought_home']\n  支持度: 0.146, 置信度: 0.404, 提升度: 1.721\n\n规则: ['bought_electronics', 'bought_home'] -> ['bought_books', 'bought_sports']\n  支持度: 0.138, 置信度: 0.587, 提升度: 1.692\n\n规则: ['bought_books', 'bought_sports'] -> ['bought_electronics', 'bought_home']\n  支持度: 0.138, 置信度: 0.398, 提升度: 1.692\n```\n\n\n:::\n\n```{.python .cell-code}\n    \n# 产品共现热图\nplt.figure(figsize=(8, 6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Figure size 800x600 with 0 Axes>\n```\n\n\n:::\n\n```{.python .cell-code}\ncorr_matrix = association_data.corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Axes: >\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.title('产品购买相关性热图')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, '产品购买相关性热图')\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](13-案例综合分析_files/figure-docx/python-association-9.png)\n:::\n:::\n\n\n## 13.3 综合分析结果\n\n方法比较\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# R和Python结果比较\ncat(\"## 分析方法总结\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## 分析方法总结\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 回归分析\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 回归分析\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 线性回归和随机森林都能较好地预测用户消费金额\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 线性回归和随机森林都能较好地预测用户消费金额\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 随机森林在非线性关系处理上表现更好\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 随机森林在非线性关系处理上表现更好\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 分类分析\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 分类分析\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 逻辑回归和随机森林都能有效预测用户购买意向\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 逻辑回归和随机森林都能有效预测用户购买意向\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 页面浏览量和购物车添加次数是最重要的预测特征\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 页面浏览量和购物车添加次数是最重要的预测特征\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 随机森林在AUC指标上表现略优于逻辑回归\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 随机森林在AUC指标上表现略优于逻辑回归\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 聚类分析\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 聚类分析\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 成功将用户分为4个有意义的群体\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 成功将用户分为4个有意义的群体\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 不同群体在消费行为和用户特征上有明显差异\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 不同群体在消费行为和用户特征上有明显差异\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 关联分析\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 关联分析\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 通过调整参数成功挖掘出关联规则\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 通过调整参数成功挖掘出关联规则\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 发现了产品间的购买模式和相关关系\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 发现了产品间的购买模式和相关关系\n```\n\n\n:::\n:::\n\n\n业务建议\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"## 业务洞察与建议\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## 业务洞察与建议\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"1. **用户分群营销**: 针对不同聚类群体制定个性化营销策略\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1. **用户分群营销**: 针对不同聚类群体制定个性化营销策略\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"2. **交叉销售**: 利用关联规则结果优化商品推荐系统\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2. **交叉销售**: 利用关联规则结果优化商品推荐系统\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"3. **用户行为预测**: 使用分类模型识别高价值潜在客户\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3. **用户行为预测**: 使用分类模型识别高价值潜在客户\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"4. **收入预测**: 回归模型可用于预测用户生命周期价值\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n4. **收入预测**: 回归模型可用于预测用户生命周期价值\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"5. **产品组合优化**: 基于关联分析结果调整产品陈列和捆绑销售策略\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5. **产品组合优化**: 基于关联分析结果调整产品陈列和捆绑销售策略\n```\n\n\n:::\n:::\n\n\n技术总结\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"## 技术实现总结\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## 技术实现总结\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 数据框操作修复要点\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 数据框操作修复要点\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 避免对字符型变量进行数学运算\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 避免对字符型变量进行数学运算\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 使用明确的列选择，只对数值列进行操作\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 使用明确的列选择，只对数值列进行操作\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 使用`across(where(is.numeric), ~ round(., 4))`时确保只选择数值列\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 使用`across(where(is.numeric), ~ round(., 4))`时确保只选择数值列\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### R语言优势\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### R语言优势\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 统计建模功能强大，模型输出详细\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 统计建模功能强大，模型输出详细\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 可视化库丰富，图形质量高\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 可视化库丰富，图形质量高\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 数据处理管道清晰易读\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 数据处理管道清晰易读\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### Python优势\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### Python优势\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 机器学习库生态系统完善\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 机器学习库生态系统完善\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 代码简洁，部署方便\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 代码简洁，部署方便\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- 深度学习和大数据处理能力强\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- 深度学习和大数据处理能力强\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"### 推荐使用场景\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n### 推荐使用场景\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- **学术研究、统计分析**: 推荐使用R\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- **学术研究、统计分析**: 推荐使用R\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- **生产环境、大型项目**: 推荐使用Python\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- **生产环境、大型项目**: 推荐使用Python\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- **混合使用**: 根据具体任务选择最适合的工具\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- **混合使用**: 根据具体任务选择最适合的工具\n```\n\n\n:::\n:::\n\n\n## 13.4 附录\n\n数据字典\n\n| 变量名          | 描述             | 类型   |\n|-----------------|------------------|--------|\n| user_id         | 用户ID           | 数值   |\n| age             | 年龄             | 数值   |\n| gender          | 性别             | 分类   |\n| income          | 收入             | 数值   |\n| region          | 地区             | 分类   |\n| page_views      | 页面浏览量       | 数值   |\n| time_on_site    | 网站停留时间(秒) | 数值   |\n| cart_additions  | 购物车添加次数   | 数值   |\n| purchase_amount | 购买金额         | 数值   |\n| made_purchase   | 是否购买         | 二分类 |\n\n依赖包列表\n\nR包: - `dplyr`, `ggplot2`, `caret`, `randomForest`, `factoextra`, `arules`, `arulesViz`, `corrplot`, `pROC`, `patchwork`, `tidyr`\n\nPython包: - `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `mlxtend`",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}