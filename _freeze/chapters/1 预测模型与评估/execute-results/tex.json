{
  "hash": "cc628061c5927736d3ace44a0eab2b13",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"1 预测模型与评估\"\nformat: html\neditor: source\n---\n\n\n\n## 本章导读\n\n预测建模是现代数据分析的核心任务，无论是预测连续数值（回归）还是预测类别标签（分类），都需要建立系统的分析和评估框架。本章将介绍预测建模的基本概念，重点讨论过拟合现象及其危害，并建立完整的模型评估体系，，补充了工具软件R、Python的相关使用说明，为后续学习各种预测模型奠定基础。\n\n## 1.1 预测建模的基本概念\n\n### 1.1.1 回归与分类任务\n\n回归分析： 回归任务旨在预测连续型数值变量。例如： - 预测房屋价格（连续金额） - 预测股票收益率（连续百分比） - 预测气温变化（连续温度值） - 预测销售额（连续数量）\n\n数学上，回归模型试图建立从特征变量 $X$ 到连续响应变量 $Y$ 的映射： $$\nY = f(X) + \\varepsilon\n$$ 其中 $\\varepsilon$ 是随机误差项，代表模型无法解释的部分。\n\n分类分析： 分类任务旨在预测离散型类别变量。\n\n例如：\n\n-   判断邮件是否为垃圾邮件（二分类：是/否）\n\n-   诊断患者是否患病（二分类：健康/患病）\n\n-   识别图像中的物体类别（多分类：猫/狗/车等）\n\n-   信用风险评估（多分类：低风险/中风险/高风险）\n\n分类模型建立从特征变量 $X$ 到类别标签 $Y$ 的映射： $$\nY = g(X), \\quad Y \\in \\{C_1, C_2, \\ldots, C_K\\}\n$$\n\n### 1.1.2 特征变量与响应变量\n\n特征变量（自变量）： 用于预测的输入变量\n\n-   可以是数值型、分类型或顺序型\n\n-   表示为 $X = (X_1, X_2, \\ldots, X_p)$\n\n特征工程：从原始数据中提取有意义的特征\n\n响应变量（因变量）：\n\n-   需要预测的目标变量\n\n-   回归问题中为连续数值\n\n-   分类问题中为离散类别\n\n-   应该与业务目标紧密相关\n\n示例分析： 以房价预测为例：\n\n-   特征变量：房屋面积、卧室数量、地理位置、房龄等\n\n-   响应变量：房屋价格（连续值）\n\n-   问题类型：回归问题\n\n以垃圾邮件检测为例：\n\n-   特征变量：邮件关键词频率、发件人信誉、邮件长度等\n\n-   响应变量：邮件类型（垃圾邮件/正常邮件）\n\n-   问题类型：二分类问题\n\n### 1.1.3 预测建模的流程\n\n完整工作流：\n\n1.  问题定义：\n    -   明确业务目标\n    -   确定预测任务类型（回归/分类）\n    -   制定成功标准\n2.  数据准备：\n    -   数据收集与整合\n    -   数据清洗与预处理\n    -   探索性数据分析\n3.  特征工程：\n    -   特征选择\n    -   特征变换\n    -   特征创建\n4.  模型选择：\n    -   根据问题特点选择算法家族\n    -   考虑数据规模和特征类型\n    -   评估模型假设的合理性\n5.  模型训练：\n    -   参数估计\n    -   超参数调优\n    -   模型验证\n6.  模型评估：\n    -   性能指标计算\n    -   模型比较\n    -   误差分析\n7.  模型部署：\n    -   生产环境集成\n    -   性能监控\n    -   模型更新\n\n## 1.2 过拟合与模型复杂度\n\n### 1.2.1 过拟合的概念与机制\n\n过拟合的本质： 模型过度适应训练数据中的特定模式（包括噪声），导致在新数据上泛化能力下降。\n\n过拟合的数学描述： 设 $f$ 为真实函数，$\\hat{f}$ 为估计函数，则：\n\n-   训练误差：$\\text{Err}_{\\text{train}} = E[L(Y, \\hat{f}(X)) | \\text{train}]$\n\n-   测试误差：$\\text{Err}_{\\text{test}} = E[L(Y, \\hat{f}(X)) | \\text{test}]$\n\n当 $\\text{Err}_{\\text{train}} \\ll \\text{Err}_{\\text{test}}$ 时，发生过拟合。\n\n过拟合的视觉示例： 考虑多项式回归： - 适当阶数：平滑曲线，很好拟合真实趋势 - 过高阶数：曲线剧烈波动，拟合每个数据点（包括噪声）\n\n欠拟合： 与过拟合相对，模型过于简单，无法捕捉数据中的基本模式： - $\\text{Err}_{\\text{train}}$ 很大 - $\\text{Err}_{\\text{test}}$ 也很大 - 模型能力不足\n\n**编程演示：过拟合现象**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 过拟合现象演示 - 生成数据\n# 生成理想的过拟合演示数据\ngenerate_overfitting_demo_data <- function(n = 100) {\n  set.seed(123)\n  x <- seq(0, 4 * pi, length.out = n)\n  # 真实关系：正弦函数 + 噪声\n  y_true <- sin(x) + 0.5 * sin(2*x)\n  y_observed <- y_true + rnorm(n, 0, 0.2)\n  return(data.frame(x = x, y_true = y_true, y_observed = y_observed))\n}\n\n# 生成数据\ndemo_data <- generate_overfitting_demo_data(100)\n\n# 拟合不同复杂度的多项式模型\nlibrary(ggplot2)\nfit_polynomial_models <- function(data, max_degree = 6) {\n  models <- list()\n  predictions <- data.frame(x = data$x)\n  \n  for (degree in 1:max_degree) {\n    model <- lm(y_observed ~ poly(x, degree), data = data)\n    models[[paste0(\"degree_\", degree)]] <- model\n    predictions[[paste0(\"pred_\", degree)]] <- predict(model, newdata = data)\n  }\n  \n  return(list(models = models, predictions = predictions))\n}\n\n# 拟合模型\nresults <- fit_polynomial_models(demo_data)\n\n# 可视化过拟合现象\nplot_overfitting_demo <- function(data, predictions) {\n  plot_data <- cbind(data, predictions)\n  plot_data_long <- reshape2::melt(plot_data, id.vars = c(\"x\", \"y_true\", \"y_observed\"), \n                                  variable.name = \"model\", value.name = \"prediction\")\n  \n  ggplot(plot_data_long, aes(x = x)) +\n    geom_point(aes(y = y_observed), alpha = 0.6, size = 1) +\n    geom_line(aes(y = y_true, color = \"真实关系\"), size = 1) +\n    geom_line(aes(y = prediction, color = model), size = 0.7) +\n    facet_wrap(~ model, ncol = 3) +\n    labs(title = \"过拟合现象演示：不同阶数多项式回归\",\n         x = \"X\", y = \"Y\",\n         color = \"曲线类型\") +\n    theme_minimal() +\n    scale_color_manual(values = c(\"真实关系\" = \"black\", \n                                 \"pred_1\" = \"red\", \"pred_2\" = \"blue\", \n                                 \"pred_3\" = \"green\", \"pred_4\" = \"orange\",\n                                 \"pred_5\" = \"purple\", \"pred_6\" = \"brown\")) +\n    theme(legend.position = \"bottom\")\n}\n\n# 显示图形\nplot_overfitting_demo(demo_data, results$predictions)\n```\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 1.2.2 偏差-方差权衡的深入分析\n\n回忆《数理统计》里参数估计的评价标准： 无偏性：估计量的期望等于被估计参数。 有效性：在所有无偏估计量中，方差最小。 一致性：随着样本量增加，估计量趋近于被估计参数。 在预测建模中，我们关注的是预测误差的来源。偏差-方差权衡（Bias-Variance Tradeoff）是理解模型复杂度与预测性能关系的关键概念。\n\n期望预测误差的严格分解：\n\n对于回归问题，在平方损失下： $$\n\\begin{aligned}\nE[(Y - \\hat{f}(X))^2] &= E[(Y - E[Y|X] + E[Y|X] - \\hat{f}(X))^2] \\\\\n&= E[(Y - E[Y|X])^2] + E[(E[Y|X] - \\hat{f}(X))^2] \\\\\n&= \\text{Var}(Y|X) + \\text{Bias}^2(\\hat{f}(X)) + \\text{Var}(\\hat{f}(X))\n\\end{aligned}\n$$\n\n偏差： - $\\text{Bias}(\\hat{f}(X)) = E[\\hat{f}(X)] - f(X)$ - 系统性错误，模型与真实关系的差距 - 高偏差原因：模型过于简单，假设太强\n\n方差： - $\\text{Var}(\\hat{f}(X)) = E[(\\hat{f}(X) - E[\\hat{f}(X)])^2]$ - 模型对训练数据变化的敏感性 - 高方差原因：模型过于复杂，对噪声敏感\n\n不可约误差： - $\\sigma_\\varepsilon^2 = \\text{Var}(Y|X)$ - 数据内在的随机性 - 无法通过改进模型减少\n\n**编程演示：偏差-方差权衡**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.2.2 偏差-方差权衡演示\ndemonstrate_bias_variance <- function() {\n  set.seed(123)\n  n_simulations <- 100\n  x <- seq(0, 1, length.out = 50)\n  true_function <- function(x) sin(2 * pi * x)\n  \n  # 生成多个训练集\n  generate_training_set <- function() {\n    x_train <- runif(20, 0, 1)\n    y_train <- true_function(x_train) + rnorm(20, 0, 0.3)\n    return(data.frame(x = x_train, y = y_train))\n  }\n  \n  # 拟合不同复杂度的模型\n  fit_models <- function(data, degree) {\n    if (degree == 1) {\n      lm(y ~ x, data = data)\n    } else {\n      lm(y ~ poly(x, degree), data = data)\n    }\n  }\n  \n  # 计算偏差和方差\n  results <- list()\n  degrees <- c(1, 3, 10)  # 低、中、高复杂度\n  \n  for (degree in degrees) {\n    predictions <- matrix(0, nrow = length(x), ncol = n_simulations)\n    \n    for (i in 1:n_simulations) {\n      train_data <- generate_training_set()\n      model <- fit_models(train_data, degree)\n      pred <- predict(model, newdata = data.frame(x = x))\n      predictions[, i] <- pred\n    }\n    \n    # 计算偏差和方差\n    mean_pred <- rowMeans(predictions)\n    bias_sq <- mean((mean_pred - true_function(x))^2)\n    variance <- mean(apply(predictions, 1, var))\n    \n    results[[as.character(degree)]] <- list(\n      bias_sq = bias_sq,\n      variance = variance,\n      total_error = bias_sq + variance + 0.3^2,  # 加上噪声方差\n      predictions = predictions,\n      mean_pred = mean_pred\n    )\n  }\n  \n  return(results)\n}\n\n# 运行演示\nbias_variance_results <- demonstrate_bias_variance()\n\n# 可视化结果\nplot_bias_variance <- function(results, x) {\n  true_y <- sin(2 * pi * x)\n  \n  par(mfrow = c(1, 3))\n  for (i in 1:3) {\n    degree <- c(1, 3, 10)[i]\n    res <- results[[as.character(degree)]]\n    \n    plot(x, true_y, type = \"l\", lwd = 3, col = \"black\", \n         ylim = c(-1.5, 1.5), main = paste(\"多项式阶数:\", degree),\n         xlab = \"X\", ylab = \"Y\")\n    \n    # 绘制多个拟合曲线\n    for (j in 1:20) {\n      lines(x, res$predictions[, j], col = rgb(0.7, 0.7, 0.7, 0.3))\n    }\n    \n    # 绘制平均预测和真实函数\n    lines(x, res$mean_pred, col = \"red\", lwd = 2)\n    lines(x, true_y, col = \"black\", lwd = 2)\n    \n    # 添加图例\n    legend(\"topright\", \n           legend = c(\"真实函数\", \"平均预测\", \"单个拟合\"),\n           col = c(\"black\", \"red\", \"gray\"), lwd = c(2, 2, 1), bty = \"n\")\n  }\n  par(mfrow = c(1, 1))\n}\n\n# 创建x值用于绘图\nx_plot <- seq(0, 1, length.out = 50)\nplot_bias_variance(bias_variance_results, x_plot)\n```\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n# 打印偏差-方差分解结果\ncat(\"偏差-方差分解结果:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n偏差-方差分解结果:\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (degree in c(1, 3, 10)) {\n  res <- bias_variance_results[[as.character(degree)]]\n  cat(sprintf(\"阶数 %d: 偏差²=%.4f, 方差=%.4f, 总误差=%.4f\\n\", \n              degree, res$bias_sq, res$variance, res$total_error))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n阶数 1: 偏差²=0.2124, 方差=0.0309, 总误差=0.3333\n阶数 3: 偏差²=0.0068, 方差=0.0269, 总误差=0.1236\n阶数 10: 偏差²=479112.8409, 方差=48825232.2140, 总误差=49304345.1449\n```\n\n\n:::\n:::\n\n\n### 1.2.3 模型复杂度的影响分析\n\n复杂度与误差的关系：\n\n| 复杂度状态 | 训练误差 | 测试误差 | 偏差 | 方差 |\n|------------|----------|----------|------|------|\n| 低复杂度   | 高       | 高       | 高   | 低   |\n| 最优复杂度 | 中等     | 最低     | 中等 | 中等 |\n| 高复杂度   | 很低     | 高       | 低   | 高   |\n\n学习曲线分析： 绘制训练集大小与误差的关系： - 训练误差：随样本增加而增加（趋于稳定） - 测试误差：随样本增加而减少（趋于稳定） - 两者差距：反映方差大小\n\n实际指导意义： - 高偏差：增加模型复杂度，增加特征 - 高方差：减少模型复杂度，增加数据，正则化\n\n## 1.3 模型评估框架\n\n### 1.3.1 数据划分的详细策略\n\n为什么需要数据划分： - 评估模型泛化能力 - 避免对训练数据的过度优化 - 提供无偏的性能估计\n\n训练集： - 用于模型参数估计 - 应该足够大以学习数据模式 - 通常占60-80%\n\n验证集： - 用于模型选择和超参数调优 - 提供模型比较的基础 - 通常占10-20%\n\n测试集： - 用于最终模型评估 - 在整个建模过程中只能使用一次 - 通常占10-20%\n\n数学表达： 将数据集 $D$ 划分为： $$\nD = D_{\\text{train}} \\cup D_{\\text{val}} \\cup D_{\\text{test}}\n$$ 其中：\n\n-   $D_{\\text{train}} \\cap D_{\\text{val}} = \\emptyset$\n\n-   $D_{\\text{train}} \\cap D_{\\text{test}} = \\emptyset$\n\n-   $D_{\\text{val}} \\cap D_{\\text{test}} = \\emptyset$\n\n特殊情况的处理：\n\n-   \\- 小样本：使用交叉验证\n\n-   \\- 时间序列：按时间顺序划分\n\n-   \\- 不平衡数据：分层抽样\n\n**编程演示：数据划分策略**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.3.1 数据划分策略演示\ndemonstrate_data_splitting <- function() {\n  set.seed(123)\n  n <- 1000\n  # 生成回归数据\n  x1 <- rnorm(n)\n  x2 <- rnorm(n)\n  y <- 2*x1 + 3*x2 + rnorm(n, 0, 1)\n  data <- data.frame(x1 = x1, x2 = x2, y = y)\n  \n  # 简单划分（70%训练，30%测试）\n  train_idx_simple <- sample(1:n, size = 0.7 * n)\n  test_idx_simple <- setdiff(1:n, train_idx_simple)\n  \n  cat(\"简单划分结果:\\n\")\n  cat(\"训练集大小:\", length(train_idx_simple), \"\\n\")\n  cat(\"测试集大小:\", length(test_idx_simple), \"\\n\")\n  \n  # 检查分布是否相似\n  cat(\"\\n训练集和测试集分布比较:\\n\")\n  cat(\"训练集y均值:\", mean(data$y[train_idx_simple]), \"\\n\")\n  cat(\"测试集y均值:\", mean(data$y[test_idx_simple]), \"\\n\")\n  \n  return(list(\n    data = data,\n    train_idx = train_idx_simple,\n    test_idx = test_idx_simple\n  ))\n}\n\n# 运行演示\nsplit_results <- demonstrate_data_splitting()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n简单划分结果:\n训练集大小: 700 \n测试集大小: 300 \n\n训练集和测试集分布比较:\n训练集y均值: 0.1586161 \n测试集y均值: 0.09502576 \n```\n\n\n:::\n:::\n\n\n### 1.3.2 交叉验证方法\n\nk折交叉验证的完整流程：\n\n1.  数据准备：\n    -   随机打乱数据\n    -   将数据分为k个大小相等的子集 $D_1, D_2, \\ldots, D_k$\n2.  交叉验证循环： For $i = 1$ to $k$:\n    -   训练集：$D_{\\text{train}}^{(i)} = D \\setminus D_i$\n    -   验证集：$D_{\\text{val}}^{(i)} = D_i$\n    -   在 $D_{\\text{train}}^{(i)}$ 上训练模型\n    -   在 $D_{\\text{val}}^{(i)}$ 上计算验证误差 $\\text{Err}^{(i)}$\n3.  结果汇总：\n    -   平均验证误差：$CV(k) = \\frac{1}{k} \\sum_{i=1}^k \\text{Err}^{(i)}$\n    -   误差标准差：$SE_{CV} = \\sqrt{\\frac{1}{k-1} \\sum_{i=1}^k (\\text{Err}^{(i)} - CV(k))^2}$\n\nk值选择：\n\n-   \\- $k=5$ 或 $k=10$：常用选择\n\n-   \\- $k=n$（留一法）：计算量大，方差可能较高\n\n-   \\- 小k值：偏差较小，方差较大 - 大k值：偏差较大，方差较小\n\n分层k折交叉验证： 对于分类问题，保持每个折中类别比例与整体一致。\n\n时间序列交叉验证： 对于时间相关数据，确保验证集时间在训练集之后。\n\n## 1.4 评估指标\n\n### 1.4.1 回归问题评估指标\n\n均方误差： $$\nMSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n$$ - 优点：数学性质好，便于优化\n\n\\- 缺点：对异常值敏感，量纲与原始数据不同\n\n均方根误差： $$\nRMSE = \\sqrt{MSE}\n$$ - 优点：量纲与原始数据相同\n\n-   缺点：仍然对异常值敏感\n\n平均绝对误差： $$\nMAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n$$ - 优点：对异常值不敏感\n\n\\- 缺点：数学性质较差，优化困难\n\n平均绝对百分比误差： $$\nMAPE = \\frac{100\\%}{n} \\sum_{i=1}^n \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|\n$$ - 优点：相对误差，易于解释\n\n\\- 缺点：$y_i=0$时无法计算，对负值处理困难\n\n决定系数 $R^2$： $$\nR^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n$$ - 优点：标准化，易于比较\n\n\\- 缺点：随特征增加而增加，可能误导\n\n调整$R^2$： $$\nR^2_{\\text{adj}} = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\n$$ 其中 $p$ 是特征数，惩罚特征过多的模型。\n\n\\*\\* 演示：回归评估指标\\*\\*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.4.1 回归评估指标演示\ndemonstrate_regression_metrics <- function() {\n  set.seed(123)\n  n <- 100\n  # 生成数据\n  x <- rnorm(n)\n  y_true <- 2*x + 1\n  y_pred <- y_true + rnorm(n, 0, 0.5)  # 预测值（带有误差）\n  y_actual <- y_true + rnorm(n, 0, 0.3)  # 实际观测值（带有噪声）\n  \n  # 计算各种评估指标\n  calculate_regression_metrics <- function(actual, predicted) {\n    n <- length(actual)\n    residuals <- actual - predicted\n    \n    mse <- mean(residuals^2)\n    rmse <- sqrt(mse)\n    mae <- mean(abs(residuals))\n    \n    # R-squared\n    ss_residual <- sum(residuals^2)\n    ss_total <- sum((actual - mean(actual))^2)\n    r_squared <- 1 - (ss_residual / ss_total)\n    \n    # 调整R-squared\n    p <- 1  # 特征数\n    r_squared_adj <- 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n    \n    return(list(\n      MSE = mse,\n      RMSE = rmse,\n      MAE = mae,\n      R2 = r_squared,\n      R2_adj = r_squared_adj\n    ))\n  }\n  \n  metrics <- calculate_regression_metrics(y_actual, y_pred)\n  \n  cat(\"回归评估指标:\\n\")\n  cat(\"MSE (均方误差):\", round(metrics$MSE, 4), \"\\n\")\n  cat(\"RMSE (均方根误差):\", round(metrics$RMSE, 4), \"\\n\")\n  cat(\"MAE (平均绝对误差):\", round(metrics$MAE, 4), \"\\n\")\n  cat(\"R² (决定系数):\", round(metrics$R2, 4), \"\\n\")\n  cat(\"调整R²:\", round(metrics$R2_adj, 4), \"\\n\")\n  \n  # 可视化预测效果\n  plot_data <- data.frame(\n    Actual = y_actual,\n    Predicted = y_pred,\n    Perfect = y_actual  # 完美预测线\n  )\n  \n  library(ggplot2)\n  p <- ggplot(plot_data, aes(x = Actual, y = Predicted)) +\n    geom_point(alpha = 0.6) +\n    geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n    labs(title = \"预测值 vs 实际值\",\n         subtitle = paste(\"R² =\", round(metrics$R2, 4)),\n         x = \"实际值\", y = \"预测值\") +\n    theme_minimal()\n  \n  print(p)\n  \n  return(metrics)\n}\n\n# 运行回归指标演示\nregression_metrics <- demonstrate_regression_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n回归评估指标:\nMSE (均方误差): 0.3116 \nRMSE (均方根误差): 0.5582 \nMAE (平均绝对误差): 0.4523 \nR² (决定系数): 0.904 \n调整R²: 0.9031 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 1.4.2 分类问题评估指标\n\n混淆矩阵的扩展： 对于多分类问题，混淆矩阵是 $K \\times K$ 的表格。\n\n准确率的局限性： - 在不平衡数据中可能误导 - 例：99%负例，全预测负类仍有99%准确率\n\n精确率与召回率的权衡： - 精确率：预测为正的样本中实际为正的比例 - 召回率：实际为正的样本中被预测为正的比例 - 通常存在trade-off关系\n\nFβ分数： $$\nF_\\beta = (1+\\beta^2) \\times \\frac{\\text{Precision} \\times \\text{Recall}}{(\\beta^2 \\times \\text{Precision}) + \\text{Recall}}\n$$ - $\\beta > 1$：更重视召回率 - $\\beta < 1$：更重视精确率 - $\\beta = 1$：平衡（F1分数）\n\n马修斯相关系数： $$\nMCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\n$$ 适用于不平衡数据的综合指标。\n\n-   编程演示：分类评估指标\\*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.4.2 分类评估指标演示\ndemonstrate_classification_metrics <- function() {\n  set.seed(123)\n  n <- 1000\n  # 生成二分类数据\n  feature1 <- rnorm(n)\n  feature2 <- rnorm(n)\n  \n  # 生成真实概率\n  true_prob <- plogis(0.5 + 1.2 * feature1 - 0.8 * feature2)\n  true_labels <- rbinom(n, 1, true_prob)\n  \n  # 生成预测概率（带有一些误差）\n  pred_prob <- true_prob + rnorm(n, 0, 0.1)\n  pred_prob <- pmin(pmax(pred_prob, 0), 1)  # 限制在[0,1]范围内\n  pred_labels <- ifelse(pred_prob > 0.5, 1, 0)\n  \n  # 计算混淆矩阵\n  calculate_confusion_matrix <- function(actual, predicted) {\n    tp <- sum(actual == 1 & predicted == 1)\n    tn <- sum(actual == 0 & predicted == 0)\n    fp <- sum(actual == 0 & predicted == 1)\n    fn <- sum(actual == 1 & predicted == 0)\n    \n    return(list(TP = tp, TN = tn, FP = fp, FN = fn))\n  }\n  \n  cm <- calculate_confusion_matrix(true_labels, pred_labels)\n  \n  # 计算各种指标\n  accuracy <- (cm$TP + cm$TN) / n\n  precision <- cm$TP / (cm$TP + cm$FP)\n  recall <- cm$TP / (cm$TP + cm$FN)\n  f1_score <- 2 * (precision * recall) / (precision + recall)\n  \n  # 计算AUC\n  calculate_auc <- function(actual, prob) {\n    # 简单实现AUC计算\n    positive_probs <- prob[actual == 1]\n    negative_probs <- prob[actual == 0]\n    \n    comparisons <- 0\n    correct <- 0\n    \n    # 抽样计算以加快速度\n    n_sample <- min(100, length(positive_probs), length(negative_probs))\n    pos_sample <- sample(positive_probs, n_sample)\n    neg_sample <- sample(negative_probs, n_sample)\n    \n    for (p in pos_sample) {\n      for (n in neg_sample) {\n        comparisons <- comparisons + 1\n        if (p > n) correct <- correct + 1\n        else if (p == n) correct <- correct + 0.5\n      }\n    }\n    \n    return(correct / comparisons)\n  }\n  \n  auc_score <- calculate_auc(true_labels, pred_prob)\n  \n  cat(\"分类评估指标:\\n\")\n  cat(\"准确率:\", round(accuracy, 4), \"\\n\")\n  cat(\"精确率:\", round(precision, 4), \"\\n\")\n  cat(\"召回率:\", round(recall, 4), \"\\n\")\n  cat(\"F1分数:\", round(f1_score, 4), \"\\n\")\n  cat(\"AUC:\", round(auc_score, 4), \"\\n\")\n  \n  # 打印混淆矩阵\n  cat(\"\\n混淆矩阵:\\n\")\n  confusion_df <- data.frame(\n    Actual_0 = c(cm$TN, cm$FN),\n    Actual_1 = c(cm$FP, cm$TP)\n  )\n  rownames(confusion_df) <- c(\"Predicted_0\", \"Predicted_1\")\n  print(confusion_df)\n  \n  # 可视化ROC曲线\n  plot_roc_curve <- function(actual, prob) {\n    thresholds <- seq(0, 1, 0.01)\n    tpr <- numeric(length(thresholds))\n    fpr <- numeric(length(thresholds))\n    \n    for (i in 1:length(thresholds)) {\n      pred <- ifelse(prob > thresholds[i], 1, 0)\n      cm_temp <- calculate_confusion_matrix(actual, pred)\n      tpr[i] <- cm_temp$TP / (cm_temp$TP + cm_temp$FN)  # 真正率\n      fpr[i] <- cm_temp$FP / (cm_temp$FP + cm_temp$TN)  # 假正率\n    }\n    \n    roc_data <- data.frame(FPR = fpr, TPR = tpr)\n    \n    ggplot(roc_data, aes(x = FPR, y = TPR)) +\n      geom_line(color = \"blue\", size = 1) +\n      geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n      labs(title = \"ROC曲线\",\n           subtitle = paste(\"AUC =\", round(auc_score, 4)),\n           x = \"假正率 (FPR)\", y = \"真正率 (TPR)\") +\n      theme_minimal() +\n      coord_equal()\n  }\n  \n  roc_plot <- plot_roc_curve(true_labels, pred_prob)\n  print(roc_plot)\n  \n  return(list(\n    accuracy = accuracy,\n    precision = precision,\n    recall = recall,\n    f1_score = f1_score,\n    auc = auc_score,\n    confusion_matrix = cm\n  ))\n}\n\n# 运行分类指标演示\nclassification_metrics <- demonstrate_classification_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n分类评估指标:\n准确率: 0.748 \n精确率: 0.779 \n召回率: 0.8126 \nF1分数: 0.7955 \nAUC: 0.77 \n\n混淆矩阵:\n            Actual_0 Actual_1\nPredicted_0      258      139\nPredicted_1      113      490\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 1.4.3 ROC曲线与AUC曲线\n\nROC曲线的绘制： 1. 计算不同分类阈值下的TPR和FPR 2. 以FPR为横轴，TPR为纵轴绘制曲线 3. 曲线越靠近左上角，性能越好\n\nAUC的概率解释： AUC等于随机选取的正样本得分高于随机选取的负样本得分的概率。\n\nAUC的优势： - 与分类阈值无关 - 反映模型整体排序能力 - 适用于不平衡数据\n\nAUC的局限性： - 只关注排序，不关注具体概率值 - 在某些情况下可能过于乐观\n\n精确率-召回率曲线： 在不平衡数据中通常比ROC曲线更有信息量。\n\n## 1.5 模型选择原则\n\n### 1.5.1 奥卡姆剃刀原理的统计基础\n\n简约性原则： 在同样能够解释数据的模型中，选择最简单的模型。\n\n数学形式化： 选择使以下目标函数最小的模型： $$\n\\text{Objective} = \\text{拟合优度} + \\lambda \\times \\text{模型复杂度}\n$$\n\n模型复杂度的度量： - 参数个数 - VC维 - 有效参数个数\n\n### 1.5.2 信息准则的详细推导\n\nAIC的推导： 基于Kullback-Leibler散度，目标是选择最接近真实分布的模型。 $$\nAIC = 2k - 2\\ln(\\hat{L})\n$$ 其中： - $k$：模型参数个数 - $\\hat{L}$：最大似然值\n\nBIC的推导： 基于贝叶斯因子，在样本量较大时的一致性选择。 $$\nBIC = \\ln(n)k - 2\\ln(\\hat{L})\n$$\n\nAICc： 小样本修正的AIC： $$\nAICc = AIC + \\frac{2k(k+1)}{n-k-1}\n$$\n\n信息准则的比较：\n\n| 准则 | 目标         | 一致性 | 效率 |\n|------|--------------|--------|------|\n| AIC  | 预测精度     | 否     | 是   |\n| BIC  | 选择真实模型 | 是     | 否   |\n| AICc | 小样本预测   | 否     | 是   |\n\n### 1.5.3 实际选择策略\n\n多准则综合评估：\n\n-   计算多个信息准则\n\n-   分析学习曲线\n\n-   考虑业务约束\n\n-   评估计算成本\n\n领域知识的作用：\n\n-   理解数据的生成机制\n\n-   考虑特征的物理意义\n\n-   评估模型的可解释性\n\n## 1.6 软件使用\n\n本书主要使用开源软件R、Python。\n\n### 16.1 R语言\n\nR+Rstudio，使用到的包(package)包括knir、tidyverse、ggplot2等，文件格式为.rmd，可以混编显示文本、代码块（chunk）、代码运行结果等各种格式内容，进行交互式的分析，可以直接生成html、doc、PDF、PPT等格式，撰写实验报告、论文、书籍等。\n\n**典型R包结构**\n\n```         \na_r_package/\n├── DESCRIPTION                    # 📋 包的\"身份证\"\n│   - Package: my_r_package        # 包名\n│   - Version: 0.1.0               # 版本号\n│   - Title: 包的功能描述          # 标题\n│   - Author: 作者信息             # 作者\n│   - Description: 详细描述        # 详细描述\n│   - License: MIT                 # 许可证\n│   - Imports: dplyr, ggplot2      # 依赖包\n│   - Suggests: testthat           # 建议依赖\n│\n├── NAMESPACE                      # 🚪 函数的\"门卫\"\n│   - export(hello_world)         # 导出函数供用户使用\n│   - import(dplyr)               # 导入依赖包的函数\n│   - importFrom(ggplot2, aes)    # 导入特定函数\n│\n├── R/                            # 💻 核心代码目录\n│   ├── hello.R                   # 函数定义文件1\n│   │   # 函数定义\n│   │   hello_world <- function() {\n│   │     print(\"Hello from R package!\")\n│   │   }\n│   │\n│   ├── data_processing.R         # 函数定义文件2\n│   │   clean_data <- function(df) {\n│   │     dplyr::filter(df, !is.na(value))\n│   │   }\n│   │\n│   └── utils.R                   # 工具函数（内部使用）\n│       internal_func <- function() {\n│         # 不导出，仅内部使用\n│       }\n│\n├── man/                          # 📚 文档目录（.Rd文件）\n│   ├── hello_world.Rd            # 函数的帮助文档\n│   │   \\name{hello_world}\n│   │   \\title{打招呼函数}\n│   │   \\description{详细描述}\n│   │   \\usage{hello_world()}\n│   │   \\examples{hello_world()}\n│   │\n│   └── my_r_package-package.Rd   # 包的总体文档\n│\n├── tests/                        # 🧪 测试目录\n│   ├── testthat/                 # testthat测试框架\n│   │   ├── test-hello.R          # 测试文件\n│   │   │   test_that(\"hello works\", {\n│   │   │     expect_output(hello_world(), \"Hello\")\n│   │   │   })\n│   │   └── test-data.R\n│   └── testthat.R                # 测试运行器\n│\n├── vignettes/                    # 📖 长篇教程/案例\n│   └── introduction.Rmd          # 包的使用教程\n│\n├── data/                         # 📊 包内置数据集\n│   ├── sample_data.rda           # R数据文件\n│   └── internal_data.rda         # 内部数据\n│\n├── inst/                         # 🎁 安装时包含的文件\n│   ├── CITATION                  # 引用信息\n│   ├── extdata/                  # 外部数据示例\n│   └── templates/                # 模板文件\n│\n└── .Rbuildignore                 # ❌ 构建时忽略的文件\n```\n\n**R数据分析典型项目结构**\n\n```         \ndata_analysis_project/          # 📈 数据分析项目\n├── data/                       # 📊 数据管理\n│   ├── raw/                    # 原始数据（只读）\n│   ├── processed/              # 处理后的数据\n│   └── external/               # 外部数据源\n│\n├── R/                          # 💻 R代码\n│   ├── 01_data_cleaning.R      # 数据清洗\n│   ├── 02_exploratory.R        # 探索性分析\n│   ├── 03_modeling.R           # 建模\n│   ├── 04_visualization.R      # 可视化\n│   └── functions/              # 自定义函数\n│       ├── utils.R\n│       └── plotting_functions.R\n│\n├── analysis/                   # 📖 分析文档\n│   ├── report.Rmd              # R Markdown报告\n│   ├── presentation.Rmd        # 演示文稿\n│   └── dashboard/              # Shiny应用\n│\n├── outputs/                    # 🎨 输出结果\n│   ├── figures/                # 生成的图表\n│   ├── tables/                 # 生成的表格\n│   └── models/                 # 保存的模型\n│\n├── tests/                      # 🧪 测试\n├── references/                 # 📚 参考文献/文档\n├── .Rprofile                   # 🔧 R启动配置\n├── .Renviron                   # 🌍 环境变量\n└── data_analysis_project.Rproj # 🏠 RStudio项目文件\n```\n\n### 16.2 Python\n\n依托Anaconda平台，该平台打包了python和重要的模块，包括环境的设置，自带IDE包括jupyter notebook、jupyterlab、pycharm等，使用到的库（library）包括pandas、numpy、sklearn，由jupyter notebook编译文件格式为.ipynb，可以实现文本、代码块（cell）、代码运行结果、结果分析等混编，进行交互式的分析，可以直接生成html、doc、PDF等格式。\n\n**Python包结构**\n\n```         \na_python_package/\n├── pyproject.toml                    # 🎯 现代构建配置（替代setup.py）\n│   [build-system]\n│   requires = [\"setuptools\", \"wheel\"]\n│   \n│   [project]\n│   name = \"my_python_package\"\n│   version = \"0.1.0\"\n│   dependencies = [\n│     \"numpy>=1.20\",\n│     \"pandas>=1.3\"\n│   ]\n│\n├── src/                              # 📁 源代码目录（推荐结构）\n│   └── my_python_package/           # 包的主目录\n│       ├── __init__.py              # 🚪 包的入口点\n│       │   \"\"\"包的主模块\"\"\"\n│       │   __version__ = \"0.1.0\"\n│       │   __author__ = \"Your Name\"\n│       │   \n│       │   # 导入关键函数，方便用户访问\n│       │   from .core import (\n│       │       normalize_data,\n│       │       process_dataframe\n│       │   )\n│       │   \n│       │   # 也可以使用 __all__ 控制导入\n│       │   __all__ = [\"normalize_data\", \"process_dataframe\"]\n│       │\n│       ├── core.py                   # 💼 核心模块\n│       │   \"\"\"核心功能实现\"\"\"\n│       │   import numpy as np\n│       │   import pandas as pd\n│       │   \n│       │   def normalize_data(x):\n│       │       \"\"\"标准化数据\"\"\"\n│       │       if not isinstance(x, (np.ndarray, list)):\n│       │           raise TypeError(\"输入必须是数组或列表\")\n│       │       x = np.array(x)\n│       │       return (x - np.mean(x)) / np.std(x)\n│       │   \n│       │   def _internal_helper():\n│       │       \"\"\"内部函数（以下划线开头）\"\"\"\n│       │       return \"internal\"\n│       │\n│       ├── utils/                    # 🧰 子包/工具模块目录\n│       │   ├── __init__.py\n│       │   ├── file_utils.py\n│       │   └── math_utils.py\n│       │\n│       ├── data/                     # 📊 数据管理\n│       │   ├── __init__.py\n│       │   ├── datasets.py          # 数据集加载函数\n│       │   └── constants.py         # 常量定义\n│       │\n│       └── tests/                    # 🧪 测试目录（可选放这里）\n│           ├── __init__.py\n│           ├── test_core.py\n│           └── test_utils/\n│\n├── tests/                           # 🧪 测试目录（或放外面）\n│   ├── test_core.py\n│   │   def test_normalize():\n│   │       from src.my_python_package.core import normalize_data\n│   │       result = normalize_data([1, 2, 3])\n│   │       assert np.allclose(result.mean(), 0)\n│   │\n│   └── conftest.py                  # pytest配置\n│\n├── docs/                            # 📚 文档\n│   ├── conf.py                      # Sphinx配置\n│   ├── index.rst                    # 文档首页\n│   └── api.rst                      # API文档\n│\n├── examples/                        # 🚀 使用示例\n│   ├── basic_usage.ipynb            # Jupyter示例\n│   └── advanced_demo.py\n│\n├── .github/                         # 🤖 GitHub配置\n│   ├── workflows/\n│   │   └── ci.yml                   # 持续集成\n│   └── ISSUE_TEMPLATE/              # Issue模板\n│\n├── README.md                        # 📖 项目说明\n├── LICENSE                          # ⚖️ 许可证\n├── requirements.txt                 # 📦 依赖列表（可选）\n└── setup.cfg                        # ⚙️ 传统配置（兼容性）\n```\n\n**Python数据分析项目结构**\n\n```         \nmy_project/                     # 🤖 机器学习项目\n├── src/                        # 💻 源代码\n│   ├── data/                   # 数据模块\n│   │   ├── __init__.py\n│   │   ├── make_dataset.py     # 数据准备\n│   │   └── preprocessing.py    # 预处理\n│   │\n│   ├── features/               # 特征工程\n│   │   ├── __init__.py\n│   │   ├── build_features.py\n│   │   └── selection.py\n│   │\n│   ├── models/                 # 模型\n│   │   ├── __init__.py\n│   │   ├── train_model.py\n│   │   └── predict_model.py\n│   │\n│   └── visualization/          # 可视化\n│       ├── __init__.py\n│       └── plot_results.py\n│\n├── notebooks/                  # 📓 Jupyter笔记本\n│   ├── 01_exploratory.ipynb    # 探索性分析\n│   ├── 02_feature_engineering.ipynb\n│   └── 03_model_training.ipynb\n│\n├── data/                       # 📊 数据\n│   ├── raw/                    # 原始数据\n│   ├── interim/                # 中间数据\n│   └── processed/              # 处理后的数据\n│\n├── models/                     # 💾 模型存储\n│   ├── trained_models/\n│   └── model_metrics.json\n│\n├── reports/                    # 📄 报告\n│   ├── figures/                # 图表\n│   └── final_report.md\n│\n├── tests/                      # 🧪 测试\n├── configs/                    # ⚙️ 配置文件\n│   ├── data_config.yaml\n│   └── model_config.yaml\n│\n├── requirements.txt            # 📦 依赖\n├── setup.py                    # 🏗️ 安装配置\n├── pyproject.toml              # 🎯 现代配置\n├── Dockerfile                  # 🐳 容器化\n└── README.md                   # 📖 说明文档\n```\n\n### 1.6.3 学习工具平台搭建\n\n统计学专业的同学，可以考虑R+Rtools+Rstudio，使用Rstudio作为分析平台，文件格式为RMD，如果想混合Python使用，可以加载包reticulate，连接调用python使用。\n\n面向机器学习的同学，应该以Python为主，学习、笔记、报告、作业等考虑Anaconda里面的IDE工具jupyter notebook，文件格式为ipynb，或者考虑使用jupyterlab。\n\n面向工程开发、项目管理的同学，考虑使用VScode，如果工作偏向于数据科学，可以使用Positren，是一个类似vscode的数据科学定制版，可以交叉调用R、Python、Julia等语言进行混合编程，集成git进行版本控制和发布，本书即使用Positren编写。\n\n## 1.7 综合案例\n\n### 1.7.1 mtcars数据集分析：R语言实现\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_mtcars_dataset <- function() {\n  # 加载数据\n  data(mtcars)\n  cat(\"mtcars数据集基本信息:\\n\")\n  cat(\"样本数:\", nrow(mtcars), \"\\n\")\n  cat(\"变量数:\", ncol(mtcars), \"\\n\")\n  cat(\"\\n变量名称:\\n\")\n  print(names(mtcars))\n  \n  # 数据概览\n  cat(\"\\n数据概览:\\n\")\n  print(summary(mtcars))\n  \n  # 探索性数据分析\n  library(ggplot2)\n  library(patchwork)\n  \n  # 目标变量：mpg（每加仑行驶英里数）\n  p1 <- ggplot(mtcars, aes(x = mpg)) +\n    geom_histogram(bins = 15, fill = \"steelblue\", alpha = 0.5) +\n    labs(title = \"MPG分布\", x = \"MPG\", y = \"频数\") +\n    theme_minimal()\n  \n  p2 <- ggplot(mtcars, aes(x = wt, y = mpg)) +\n    geom_point(alpha = 0.7) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n    labs(title = \"车重与MPG关系\", x = \"重量\", y = \"MPG\") +\n    theme_minimal()\n  \n  p3 <- ggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n    geom_boxplot(fill = \"lightgreen\", alpha = 0.7) +\n    labs(title = \"气缸数与MPG关系\", x = \"气缸数\", y = \"MPG\") +\n    theme_minimal()\n  \n  # 组合图形\n  combined_plot <- (p1 | p2 | p3)\n  print(combined_plot)\n  \n  # 数据划分\n  set.seed(123)\n  train_indices <- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))\n  test_indices <- setdiff(1:nrow(mtcars), train_indices)\n  \n  cat(\"\\n数据划分结果:\\n\")\n  cat(\"训练集大小:\", length(train_indices), \"\\n\")\n  cat(\"测试集大小:\", length(test_indices), \"\\n\")\n  \n  # 训练不同复杂度的模型\n  models <- list()\n  \n  # 简单模型\n  models[[\"simple\"]] <- lm(mpg ~ wt, data = mtcars[train_indices, ])\n  \n  # 中等复杂度模型\n  models[[\"medium\"]] <- lm(mpg ~ wt + cyl + hp, data = mtcars[train_indices, ])\n  \n  # 复杂模型\n  models[[\"complex\"]] <- lm(mpg ~ wt + cyl + hp + disp + drat + qsec, \n                           data = mtcars[train_indices, ])\n  \n  # 评估模型性能\n  evaluate_model <- function(model, test_data) {\n    predictions <- predict(model, newdata = test_data)\n    actual <- test_data$mpg\n    \n    mse <- mean((actual - predictions)^2)\n    rmse <- sqrt(mse)\n    mae <- mean(abs(actual - predictions))\n    r2 <- 1 - sum((actual - predictions)^2) / sum((actual - mean(actual))^2)\n    \n    return(list(MSE = mse, RMSE = rmse, MAE = mae, R2 = r2))\n  }\n  \n  # 比较所有模型\n  test_data <- mtcars[test_indices, ]\n  performance <- data.frame()\n  \n  for (model_name in names(models)) {\n    model <- models[[model_name]]\n    perf <- evaluate_model(model, test_data)\n    \n    performance <- rbind(performance, data.frame(\n      Model = model_name,\n      Parameters = length(coef(model)),\n      MSE = perf$MSE,\n      RMSE = perf$RMSE,\n      MAE = perf$MAE,\n      R2 = perf$R2\n    ))\n  }\n  \n  cat(\"\\n模型性能比较:\\n\")\n  print(performance)\n  \n  # 交叉验证比较\n  library(mlr3)\n  library(mlr3verse)\n  \n  # 创建任务\n  mtcars_task <- as_task_regr(mtcars[, c(\"mpg\", \"wt\", \"cyl\", \"hp\", \"disp\", \"drat\", \"qsec\")], \n                             target = \"mpg\", id = \"mtcars\")\n  \n  # 定义学习器\n  learners <- list(\n    lrn(\"regr.lm\", id = \"simple_lm\"),\n    lrn(\"regr.rpart\", id = \"tree\"),\n    lrn(\"regr.kknn\", id = \"knn\")\n  )\n  \n  # 交叉验证\n  resampling <- rsmp(\"cv\", folds = 5)\n  \n  cv_results <- data.frame()\n  for (learner in learners) {\n    rr <- resample(mtcars_task, learner, resampling)\n    cv_results <- rbind(cv_results, data.frame(\n      Model = learner$id,\n      CV_RMSE = sqrt(rr$aggregate(msr(\"regr.mse\"))),\n      CV_MAE = rr$aggregate(msr(\"regr.mae\")),\n      CV_R2 = rr$aggregate(msr(\"regr.rsq\"))\n    ))\n  }\n  \n  cat(\"\\n交叉验证结果:\\n\")\n  print(cv_results)\n  \n  # 过拟合分析\n  analyze_overfitting <- function() {\n    train_errors <- numeric(3)\n    test_errors <- numeric(3)\n    model_names <- c(\"simple\", \"medium\", \"complex\")\n    \n    for (i in 1:3) {\n      model <- models[[model_names[i]]]\n      \n      # 训练误差\n      train_pred <- predict(model, newdata = mtcars[train_indices, ])\n      train_errors[i] <- mean((mtcars$mpg[train_indices] - train_pred)^2)\n      \n      # 测试误差\n      test_pred <- predict(model, newdata = test_data)\n      test_errors[i] <- mean((test_data$mpg - test_pred)^2)\n    }\n    \n    overfitting_data <- data.frame(\n      Model = model_names,\n      Train_MSE = train_errors,\n      Test_MSE = test_errors,\n      Overfitting_Gap = test_errors - train_errors\n    )\n    \n    cat(\"\\n过拟合分析:\\n\")\n    print(overfitting_data)\n    \n    # 可视化过拟合现象\n    p <- ggplot(overfitting_data, aes(x = Model)) +\n      geom_line(aes(y = Train_MSE, color = \"训练误差\", group = 1), size = 1) +\n      geom_line(aes(y = Test_MSE, color = \"测试误差\", group = 1), size = 1) +\n      geom_point(aes(y = Train_MSE, color = \"训练误差\"), size = 3) +\n      geom_point(aes(y = Test_MSE, color = \"测试误差\"), size = 3) +\n      labs(title = \"过拟合分析：训练误差 vs 测试误差\",\n           x = \"模型复杂度\", y = \"均方误差 (MSE)\",\n           color = \"误差类型\") +\n      theme_minimal() +\n      scale_color_manual(values = c(\"训练误差\" = \"blue\", \"测试误差\" = \"red\"))\n    \n    print(p)\n    \n    return(overfitting_data)\n  }\n  \n  overfitting_analysis <- analyze_overfitting()\n  \n  return(list(\n    performance = performance,\n    cv_results = cv_results,\n    overfitting_analysis = overfitting_analysis,\n    models = models\n  ))\n}\n\n# 运行综合案例分析\nmtcars_analysis <- analyze_mtcars_dataset()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmtcars数据集基本信息:\n样本数: 32 \n变量数: 11 \n\n变量名称:\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\n数据概览:\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n数据划分结果:\n训练集大小: 22 \n测试集大小: 10 \n\n模型性能比较:\n    Model Parameters      MSE     RMSE      MAE        R2\n1  simple          2 4.567618 2.137199 1.845953 0.6379045\n2  medium          4 5.152415 2.269893 1.877027 0.5915450\n3 complex          7 5.345615 2.312059 1.765717 0.5762291\n\n交叉验证结果:\n              Model  CV_RMSE   CV_MAE      CV_R2\nregr.mse  simple_lm 2.871556 2.279431  0.7249341\nregr.mse1      tree 4.899379 3.895609 -0.2874332\nregr.mse2       knn 2.723761 2.179108  0.6664141\n\n过拟合分析:\n    Model Train_MSE Test_MSE Overfitting_Gap\n1  simple 10.762613 4.567618     -6.19499560\n2  medium  5.962236 5.152415     -0.80982161\n3 complex  5.436092 5.345615     -0.09047663\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1-预测模型与评估_files/figure-pdf/unnamed-chunk-6-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 1.7.2 mtcars数据集分析：Python语言实现\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# mtcars数据集分析 - Python版本\ndef analyze_mtcars_python():\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    matplotlib.rc(\"font\",family=\"Microsoft YaHei\")\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.model_selection import train_test_split, cross_val_score\n    from sklearn.linear_model import LinearRegression\n    from sklearn.tree import DecisionTreeRegressor\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n    from sklearn.preprocessing import StandardScaler\n    \n    # 加载mtcars数据集\n    try:\n        # 尝试从在线源加载\n        url = \"https://raw.githubusercontent.com/plotly/datasets/master/mtcars.csv\"\n        mtcars = pd.read_csv(url)\n    except:\n        # 如果网络不可用，使用内置数据集或创建模拟数据\n        print(\"网络数据加载失败，使用模拟数据\")\n        np.random.seed(42)\n        n = 32\n        mtcars = pd.DataFrame({\n            'mpg': np.random.normal(20, 6, n),\n            'cyl': np.random.choice([4, 6, 8], n),\n            'disp': np.random.normal(200, 100, n),\n            'hp': np.random.normal(150, 50, n),\n            'wt': np.random.normal(3, 1, n),\n            'qsec': np.random.normal(18, 2, n)\n        })\n    \n    print(\"mtcars数据集基本信息:\")\n    print(f\"样本数: {mtcars.shape[0]}\")\n    print(f\"变量数: {mtcars.shape[1]}\")\n    print(\"\\n数据概览:\")\n    print(mtcars.describe())\n    \n    # 数据可视化\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n    \n    # MPG分布\n    axes[0,0].hist(mtcars['mpg'], bins=10, alpha=0.7, color='steelblue')\n    axes[0,0].set_title('MPG分布')\n    axes[0,0].set_xlabel('MPG')\n    axes[0,0].set_ylabel('频数')\n    \n    # 车重与MPG关系\n    axes[0,1].scatter(mtcars['wt'], mtcars['mpg'], alpha=0.7)\n    z = np.polyfit(mtcars['wt'], mtcars['mpg'], 1)\n    p = np.poly1d(z)\n    axes[0,1].plot(mtcars['wt'], p(mtcars['wt']), \"r--\", alpha=0.8)\n    axes[0,1].set_title('车重与MPG关系')\n    axes[0,1].set_xlabel('重量')\n    axes[0,1].set_ylabel('MPG')\n    \n    # 马力与MPG关系\n    axes[1,0].scatter(mtcars['hp'], mtcars['mpg'], alpha=0.7)\n    z = np.polyfit(mtcars['hp'], mtcars['mpg'], 1)\n    p = np.poly1d(z)\n    axes[1,0].plot(mtcars['hp'], p(mtcars['hp']), \"r--\", alpha=0.8)\n    axes[1,0].set_title('马力与MPG关系')\n    axes[1,0].set_xlabel('马力')\n    axes[1,0].set_ylabel('MPG')\n    \n    # 气缸数与MPG关系\n    mtcars.boxplot(column='mpg', by='cyl', ax=axes[1,1])\n    axes[1,1].set_title('气缸数与MPG关系')\n    axes[1,1].set_xlabel('气缸数')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # 准备数据\n    X = mtcars[['wt', 'cyl', 'hp', 'disp', 'qsec']]\n    y = mtcars['mpg']\n    \n    # 数据划分\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    print(f\"\\n数据划分结果:\")\n    print(f\"训练集大小: {X_train.shape[0]}\")\n    print(f\"测试集大小: {X_test.shape[0]}\")\n    \n    # 训练不同模型\n    models = {\n        'Linear Regression': LinearRegression(),\n        'Decision Tree': DecisionTreeRegressor(random_state=42),\n        'K-Neighbors': KNeighborsRegressor()\n    }\n    \n    # 评估函数\n    def evaluate_model(model, X_train, X_test, y_train, y_test):\n        model.fit(X_train, y_train)\n        y_pred_train = model.predict(X_train)\n        y_pred_test = model.predict(X_test)\n        \n        metrics = {\n            'Train_MSE': mean_squared_error(y_train, y_pred_train),\n            'Test_MSE': mean_squared_error(y_test, y_pred_test),\n            'Train_R2': r2_score(y_train, y_pred_train),\n            'Test_R2': r2_score(y_test, y_pred_test),\n            'Overfitting_Gap': mean_squared_error(y_test, y_pred_test) - mean_squared_error(y_train, y_pred_train)\n        }\n        return metrics\n    \n    # 比较模型性能\n    results = []\n    for name, model in models.items():\n        metrics = evaluate_model(model, X_train, X_test, y_train, y_test)\n        results.append({\n            'Model': name,\n            **metrics\n        })\n    \n    results_df = pd.DataFrame(results)\n    print(\"\\n模型性能比较:\")\n    print(results_df)\n    \n    # 交叉验证\n    print(\"\\n交叉验证结果 (5折):\")\n    cv_results = []\n    for name, model in models.items():\n        cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n        cv_rmse = np.sqrt(-cv_scores)\n        cv_results.append({\n            'Model': name,\n            'CV_RMSE_mean': cv_rmse.mean(),\n            'CV_RMSE_std': cv_rmse.std()\n        })\n    \n    cv_df = pd.DataFrame(cv_results)\n    print(cv_df)\n    \n    # 可视化结果\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # 过拟合分析\n    x_pos = np.arange(len(models))\n    width = 0.35\n    \n    train_mse = results_df['Train_MSE'].values\n    test_mse = results_df['Test_MSE'].values\n    \n    ax1.bar(x_pos - width/2, train_mse, width, label='训练MSE', alpha=0.7)\n    ax1.bar(x_pos + width/2, test_mse, width, label='测试MSE', alpha=0.7)\n    ax1.set_xlabel('模型')\n    ax1.set_ylabel('均方误差 (MSE)')\n    ax1.set_title('过拟合分析')\n    ax1.set_xticks(x_pos)\n    ax1.set_xticklabels(results_df['Model'])\n    ax1.legend()\n    \n    # R²比较\n    train_r2 = results_df['Train_R2'].values\n    test_r2 = results_df['Test_R2'].values\n    \n    ax2.bar(x_pos - width/2, train_r2, width, label='训练R²', alpha=0.7)\n    ax2.bar(x_pos + width/2, test_r2, width, label='测试R²', alpha=0.7)\n    ax2.set_xlabel('模型')\n    ax2.set_ylabel('R²')\n    ax2.set_title('拟合优度比较')\n    ax2.set_xticks(x_pos)\n    ax2.set_xticklabels(results_df['Model'])\n    ax2.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return {\n        'performance': results_df,\n        'cv_results': cv_df,\n        'data': mtcars\n    }\n\n# 运行Python分析\nmtcars_python_analysis = analyze_mtcars_python()\n```\n:::\n\n\n### 1.7.3 案例总结与最佳实践\n\n关键发现总结\n\n-   过拟合验证：在mtcars数据集中，复杂模型在训练集上表现更好，但在测试集上可能表现更差\n-   交叉验证价值：相比单一划分，交叉验证提供更稳定的性能估计\n-   模型选择：不同评估指标可能选择不同的最优模型\n-   数据质量：真实数据集通常包含复杂的变量关系和数据问题\n\n最佳实践建议\n\n-   始终使用交叉验证：特别是对于小数据集\n-   监控过拟合：比较训练和测试性能的差异\n-   多指标评估：使用多个评估指标全面评价模型\n-   理解数据：进行充分的探索性数据分析\n\n## 本章总结\n\n核心概念回顾\n\n-   预测建模类型：回归分析预测连续值，分类分析预测离散类别\n-   过拟合现象：模型在训练数据上表现过好，但在新数据上表现差\n-   偏差-方差权衡：模型复杂度需要在偏差和方差之间取得平衡\n-   数据划分：训练集用于参数估计，验证集用于模型选择，测试集用于最终评估\n-   交叉验证：k折交叉验证提供更稳定的误差估计\n-   评估指标：回归问题用MSE、RMSE、$R^2$，分类问题用准确率、精确率、召回率、AUC等\n-   模型选择：基于信息准则和业务需求选择合适模型\n\n数据划分最佳实践：\n\n-   在数据分析开始前划分测试集\n\n-   使用随机种子确保结果可重现\n\n-   对于时间序列数据，按时间顺序划分\n\n-   对于不平衡数据，使用分层抽样\n\n交叉验证实施要点：\n\n1\\. 选择合适的k值（通常5或10）\n\n2\\. 使用分层抽样保持类别比例\n\n3\\. 多次运行取平均以减少随机性\n\n4\\. 记录每次交叉验证的结果和标准差\n\n模型评估综合策略：\n\n-   使用多个评估指标全面评估\n\n-   考虑业务场景选择重点指标\n\n-   分析错误案例理解模型局限\n\n-   比较基准模型确认改进效果\n\n重要数学公式总结\n\n1.  偏差-方差分解：$E[(Y-\\hat{f})^2] = \\text{Bias}^2 + \\text{Var} + \\sigma_\\varepsilon^2$\n2.  k折交叉验证：$CV(k) = \\frac{1}{k}\\sum_{i=1}^k \\text{Err}(D_{\\text{test}}^{(i)})$\n3.  回归评估：\n    -   $MSE = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$\n    -   $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$\n4.  分类评估：\n    -   $\\text{Precision} = \\frac{TP}{TP+FP}$\n    -   $\\text{Recall} = \\frac{TP}{TP+FN}$\n    -   $F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n5.  信息准则：\n    -   $AIC = 2k - 2\\ln(L)$\n    -   $BIC = \\ln(n)k - 2\\ln(L)$\n\n## 与后续章节的联系\n\n本章建立的评估框架将贯穿整个教材：\n\n-   \\- 第2-4章：线性模型的评估与选择，重点关注$R^2$、MSE等指标\n\n-   \\- 第5-7章：复杂模型的过拟合控制，应用交叉验证和正则化\n\n-   \\- 第8章：集成学习的偏差-方差分析，比较不同集成策略\n\n-   \\- 第9-10章：支持向量机和神经网络的调优策略，使用验证集选择超参数\n\n理解本章内容是学习后续所有预测模型的基础，良好的评估习惯是构建有效预测模型的关键。在实际应用中，应该根据具体问题选择合适的评估指标和方法，并始终关注模型的泛化能力。",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}